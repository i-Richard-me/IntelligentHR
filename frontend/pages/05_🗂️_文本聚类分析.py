import streamlit as st
import pandas as pd
import sys
import os
import uuid

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(project_root)

from backend.text_processing.clustering.clustering_workflow import (
    generate_categories,
    classify_texts,
)
from frontend.ui_components import show_sidebar, show_footer, apply_common_styles

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½HRåŠ©æ‰‹ - æ–‡æœ¬èšç±»åˆ†æ",
    page_icon="ğŸ”¬",
)

# åº”ç”¨è‡ªå®šä¹‰æ ·å¼
apply_common_styles()

# æ˜¾ç¤ºä¾§è¾¹æ 
show_sidebar()


def initialize_session_state():
    """
    åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡
    """
    session_vars = [
        "df_preprocessed",
        "categories",
        "df_result",
        "text_column",
        "text_topic",
        "session_id",
        "clustering_params",
    ]
    for var in session_vars:
        if var not in st.session_state:
            st.session_state[var] = None

    # ç¡®ä¿session_idæ€»æ˜¯æœ‰å€¼
    if st.session_state.session_id is None:
        st.session_state.session_id = str(uuid.uuid4())

    # åˆå§‹åŒ– clustering_params
    if st.session_state.clustering_params is None:
        st.session_state.clustering_params = {
            "min_categories": 10,
            "max_categories": 15,
            "batch_size": 100,
            "classification_batch_size": 20,
        }


def main():
    """
    ä¸»å‡½æ•°ï¼Œæ§åˆ¶é¡µé¢æµç¨‹å’Œå¸ƒå±€
    """
    initialize_session_state()

    st.title("ğŸ”¬ æ–‡æœ¬èšç±»åˆ†æ")
    st.markdown("---")

    display_info_message()
    display_workflow_introduction()

    handle_data_input_and_clustering()
    review_clustering_results()
    display_classification_results()

    show_footer()


def display_info_message():
    """
    æ˜¾ç¤ºè¡¨æ ¼å¤„ç†åŠ©æ‰‹çš„ä¿¡æ¯æ¶ˆæ¯ã€‚
    """
    st.info(
        """
        **ğŸ”¬ æ–‡æœ¬èšç±»åˆ†æå·¥å…·**

        æ–‡æœ¬èšç±»åˆ†æå·¥å…·åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œè‡ªåŠ¨åŒ–åœ°ä»å¤§é‡æ–‡æœ¬ä¸­è¯†åˆ«å’Œå½’ç±»ä¸»è¦ä¸»é¢˜ã€‚

        å·¥å…·é‡‡ç”¨åˆ†æ‰¹å¤„ç†å’Œå¤šé˜¶æ®µèšç±»ç­–ç•¥ï¼Œèƒ½å¤Ÿé«˜æ•ˆå¤„ç†å¤§è§„æ¨¡æ–‡æœ¬æ•°æ®ã€‚æ”¯æŒè‡ªå®šä¹‰ç±»åˆ«æ•°é‡èŒƒå›´ï¼Œå¹¶æä¾›äº¤äº’å¼çš„ç±»åˆ«å®¡æ ¸å’Œç¼–è¾‘åŠŸèƒ½ï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿæ ¹æ®å…·ä½“éœ€æ±‚ä¼˜åŒ–èšç±»ç»“æœã€‚
        
        é€‚ç”¨äºå„ç±»æ–‡æœ¬å†…å®¹åˆ†æåœºæ™¯ï¼Œå¦‚ç”¨æˆ·åé¦ˆå½’ç±»ã€è¯é¢˜è¶‹åŠ¿åˆ†æç­‰ã€‚
        """
    )


def display_workflow_introduction():
    with st.expander("ğŸ“‹ æŸ¥çœ‹æ–‡æœ¬èšç±»åˆ†æå·¥ä½œæµç¨‹", expanded=False):
        with st.container(border=True):
            st.markdown(
                """
            1. **æ•°æ®å‡†å¤‡ä¸å‚æ•°è®¾ç½®**

                ä¸Šä¼ CSVæ–‡ä»¶ï¼Œé€‰æ‹©æ–‡æœ¬åˆ—ï¼Œè¾“å…¥ä¸»é¢˜èƒŒæ™¯ï¼Œå¹¶è®¾ç½®èšç±»å‚æ•°ã€‚

            2. **åˆå§‹èšç±»ä¸ç±»åˆ«ä¼˜åŒ–**

                ç³»ç»Ÿä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œåˆå§‹æ–‡æœ¬åˆ†ç±»ï¼Œç„¶ååˆå¹¶å’Œä¼˜åŒ–ç±»åˆ«ã€‚

            3. **äººå·¥å®¡æ ¸ä¸è°ƒæ•´**

                å±•ç¤ºå¹¶å…è®¸ç¼–è¾‘ç”Ÿæˆçš„ç±»åˆ«åˆ—è¡¨ï¼Œä¼˜åŒ–ç±»åˆ«åç§°å’Œæè¿°ã€‚

            4. **æ–‡æœ¬åˆ†ç±»ä¸ç»“æœç”Ÿæˆ**

                åŸºäºç¡®è®¤çš„ç±»åˆ«å¯¹æ‰€æœ‰æ–‡æœ¬è¿›è¡Œåˆ†ç±»ï¼Œç”Ÿæˆå¹¶å±•ç¤ºæœ€ç»ˆç»“æœã€‚

            5. **ç»“æœå¯¼å‡º**

                æä¾›åˆ†ç±»ç»“æœçš„CSVæ ¼å¼ä¸‹è½½é€‰é¡¹ã€‚
            """
            )


def handle_data_input_and_clustering():
    """
    å¤„ç†æ•°æ®è¾“å…¥å’Œåˆå§‹èšç±»è¿‡ç¨‹
    """
    st.markdown("## æ•°æ®è¾“å…¥å’Œåˆå§‹èšç±»")

    with st.container(border=True):
        st.session_state.text_topic = st.text_input(
            "è¯·è¾“å…¥æ–‡æœ¬ä¸»é¢˜æˆ–èƒŒæ™¯",
            value=st.session_state.text_topic if st.session_state.text_topic else "",
            placeholder="ä¾‹å¦‚ï¼šå‘˜å·¥åé¦ˆã€äº§å“è¯„è®ºã€å®¢æˆ·æ„è§ç­‰",
        )

        uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type="csv")
        if uploaded_file is not None:
            df = pd.read_csv(uploaded_file)
            st.write("é¢„è§ˆä¸Šä¼ çš„æ•°æ®ï¼š")
            st.write(df.head())
            st.session_state.text_column = st.selectbox("é€‰æ‹©åŒ…å«æ–‡æœ¬çš„åˆ—", df.columns)

            st.session_state.clustering_params = get_clustering_parameters()

            if st.button("å¼€å§‹åˆå§‹èšç±»"):
                with st.spinner("æ­£åœ¨è¿›è¡Œåˆå§‹èšç±»..."):
                    result = generate_categories(
                        df=df,
                        text_column=st.session_state.text_column,
                        text_topic=st.session_state.text_topic,
                        initial_category_count=st.session_state.clustering_params[
                            "max_categories"
                        ],
                        min_categories=st.session_state.clustering_params[
                            "min_categories"
                        ],
                        max_categories=st.session_state.clustering_params[
                            "max_categories"
                        ],
                        batch_size=st.session_state.clustering_params["batch_size"],
                        session_id=st.session_state.session_id,
                    )

                st.success("åˆå§‹èšç±»å®Œæˆï¼")

                # ä¿å­˜ç»“æœåˆ° session state
                st.session_state.df_preprocessed = result["preprocessed_df"]
                st.session_state.categories = result["categories"]["categories"]

        else:
            st.warning("è¯·ä¸Šä¼ CSVæ–‡ä»¶")


def get_clustering_parameters():
    """
    è·å–èšç±»å‚æ•°è®¾ç½®

    Returns:
        dict: åŒ…å«èšç±»å‚æ•°çš„å­—å…¸
    """
    with st.expander("èšç±»å‚æ•°è®¾ç½®"):
        min_categories = st.slider(
            "æœ€å°ç±»åˆ«æ•°é‡",
            5,
            15,
            st.session_state.clustering_params["min_categories"],
            key="min_categories_slider",
        )
        max_categories = st.slider(
            "æœ€å¤§ç±»åˆ«æ•°é‡",
            min_categories,
            20,
            st.session_state.clustering_params["max_categories"],
            key="max_categories_slider",
        )
        batch_size = st.slider(
            "èšç±»æ‰¹å¤„ç†å¤§å°",
            10,
            1000,
            st.session_state.clustering_params["batch_size"],
            key="batch_size_slider",
        )
        classification_batch_size = st.slider(
            "åˆ†ç±»æ‰¹å¤„ç†å¤§å°",
            10,
            100,
            st.session_state.clustering_params["classification_batch_size"],
            key="classification_batch_size_slider",
        )

    return {
        "min_categories": min_categories,
        "max_categories": max_categories,
        "batch_size": batch_size,
        "classification_batch_size": classification_batch_size,
    }


def review_clustering_results():
    """
    å®¡æ ¸èšç±»ç»“æœå¹¶å…è®¸ç”¨æˆ·ä¿®æ”¹
    """
    if st.session_state.categories is not None:
        st.markdown("---")
        st.markdown("## èšç±»ç»“æœå®¡æ ¸")

        with st.container(border=True):
            st.markdown("è¯·å®¡æ ¸å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹ã€æ·»åŠ æˆ–åˆ é™¤ç±»åˆ«ï¼š")

            # å°†ç±»åˆ«åˆ—è¡¨è½¬æ¢ä¸ºDataFrameä»¥ä¾¿ä½¿ç”¨st.data_editor
            categories_df = pd.DataFrame(st.session_state.categories)[
                ["name", "description"]
            ]

            # ä½¿ç”¨st.data_editoræ¥å±•ç¤ºå’Œç¼–è¾‘ç±»åˆ«
            edited_df = st.data_editor(
                categories_df,
                num_rows="dynamic",
                column_config={
                    "name": st.column_config.TextColumn(
                        "ç±»åˆ«åç§°",
                        help="ç®€æ´æ˜äº†çš„ç±»åˆ«æ ‡ç­¾",
                        max_chars=50,
                        required=True,
                    ),
                    "description": st.column_config.TextColumn(
                        "ç±»åˆ«æè¿°",
                        help="è¯¦ç»†æè¿°è¯¥ç±»åˆ«çš„ç‰¹å¾åŠä¸å…¶ä»–ç±»åˆ«çš„åŒºåˆ«",
                        max_chars=200,
                        required=True,
                    ),
                },
            )

            # å°†ç¼–è¾‘åçš„DataFrameè½¬æ¢å›ç±»åˆ«åˆ—è¡¨
            edited_categories = edited_df.to_dict("records")

            if st.button("ç¡®è®¤ç±»åˆ«å¹¶å¼€å§‹æ–‡æœ¬åˆ†ç±»"):
                with st.spinner("æ­£åœ¨è¿›è¡Œæ–‡æœ¬åˆ†ç±»..."):
                    df_result = classify_texts(
                        df=st.session_state.df_preprocessed,
                        text_column=st.session_state.text_column,
                        id_column="unique_id",
                        categories={"categories": edited_categories},
                        text_topic=st.session_state.text_topic,
                        session_id=st.session_state.session_id,
                        classification_batch_size=st.session_state.clustering_params[
                            "classification_batch_size"
                        ],
                    )

                st.session_state.df_result = df_result
                st.success("æ–‡æœ¬åˆ†ç±»å®Œæˆï¼")


def display_classification_results():
    """
    å±•ç¤ºåˆ†ç±»ç»“æœ
    """
    if st.session_state.df_result is not None:
        st.markdown("---")
        st.markdown("## åˆ†ç±»ç»“æœå±•ç¤º")

        with st.container(border=True):
            st.dataframe(st.session_state.df_result)

            # æä¾›ä¸‹è½½é€‰é¡¹
            csv = st.session_state.df_result.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="ä¸‹è½½åˆ†ç±»ç»“æœCSV",
                data=csv,
                file_name="classification_results.csv",
                mime="text/csv",
            )


if __name__ == "__main__":
    main()
