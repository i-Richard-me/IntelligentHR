import streamlit as st
from PIL import Image
import pandas as pd
import sys
import os
from typing import Dict, Any, List, Optional
from uuid import uuid4

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(project_root)

from frontend.ui_components import show_sidebar, show_footer, apply_common_styles
from backend.data_processing.data_cleaning.data_processor import (
    initialize_vector_store,
    get_entity_retriever,
)
from backend.data_processing.data_cleaning.verification_workflow import (
    EntityVerificationWorkflow,
)

# Streamlit é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½HRåŠ©æ‰‹ - è‡ªåŠ¨åŒ–æ•°æ®æ¸…æ´—",
    page_icon="ğŸ¢",
)

# åº”ç”¨è‡ªå®šä¹‰æ ·å¼
apply_common_styles()

# æ˜¾ç¤ºä¾§è¾¹æ 
show_sidebar()

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "batch_results" not in st.session_state:
    st.session_state.batch_results = None
if "processing_complete" not in st.session_state:
    st.session_state.processing_complete = False
if "batch_results_df" not in st.session_state:
    st.session_state.batch_results_df = None

# å®šä¹‰å®ä½“ç±»å‹é€‰é¡¹
ENTITY_TYPES = {
    "å…¬å¸åç§°": {
        "csv_path": "data/datasets/company.csv",
        "collection_name": "company_data",
        "validation_instructions": """
        è¯·ç‰¹åˆ«æ³¨æ„ï¼Œæœ‰æ•ˆçš„å…¬å¸åç§°åº”è¯¥æ˜¯å…·ä½“çš„ã€å¯è¯†åˆ«çš„ä¼ä¸šå®ä½“ã€‚
        ä¾‹å¦‚ï¼Œ"ç§‘æŠ€å…¬å¸"è¿™æ ·çš„æ³›ç§°åº”è¢«è§†ä¸ºæ— æ•ˆï¼Œè€Œ"é˜¿é‡Œå·´å·´"åˆ™æ˜¯æœ‰æ•ˆçš„ã€‚
        """,
        "analysis_instructions": """
        åœ¨åˆ†ææœç´¢ç»“æœæ—¶ï¼Œè¯·ç‰¹åˆ«æ³¨æ„è¯†åˆ«å…¬å¸çš„æ­£å¼åç§°ã€ç®€ç§°ã€æ›¾ç”¨åç­‰ã€‚
        éœ€è¦æ¨æ–­è¯¥å…¬å¸æ˜¯å¦æ˜¯æŸå®¶çŸ¥åå…¬å¸çš„åˆåŒä¸»ä½“å˜ä½“æˆ–å…¶å­å…¬å¸ã€‚
        å¦‚æœæ˜¯ï¼Œæœ€ç»ˆæä¾›çš„åº”è¯¥æ˜¯è¿™å®¶æ›´æ™®éå’ŒçŸ¥åçš„å…¬å¸åç§°ã€‚
        ä¾‹å¦‚ï¼Œå¦‚æœæœç´¢ç»“æœæ˜¾ç¤º"æ·˜å®ï¼ˆä¸­å›½ï¼‰è½¯ä»¶æœ‰é™å…¬å¸"æ˜¯é˜¿é‡Œå·´å·´é›†å›¢çš„å­å…¬å¸ï¼Œ
        é‚£ä¹ˆåº”è¯¥å°†"é˜¿é‡Œå·´å·´"è¯†åˆ«ä¸ºæ ‡å‡†åŒ–çš„å…¬å¸åç§°ã€‚
        """,
        "verification_instructions": """
        åœ¨éªŒè¯è¿‡ç¨‹ä¸­ï¼Œè¯·è€ƒè™‘å…¬å¸çš„å„ç§å¯èƒ½çš„åç§°å½¢å¼ï¼ŒåŒ…æ‹¬å…¨ç§°ã€ç®€ç§°ã€å“ç‰Œåç­‰ã€‚
        å³ä½¿åç§°è¡¨è¿°ä¸åŒï¼Œåªè¦æŒ‡å‘åŒä¸€ä¸ªæ¯å…¬å¸æˆ–é›†å›¢ï¼Œä¹Ÿåº”è§†ä¸ºåŒ¹é…ã€‚
        ä¾‹å¦‚ï¼Œ"é˜¿é‡Œå·´å·´"å’Œ"é˜¿é‡Œå·´å·´é›†å›¢æ§è‚¡æœ‰é™å…¬å¸"åº”è¯¥è¢«è§†ä¸ºåŒ¹é…ã€‚
        """,
    },
    "å­¦æ ¡åç§°": {
        "csv_path": "data/datasets/school.csv",
        "collection_name": "school_data",
        "validation_instructions": """
        æœ‰æ•ˆçš„å­¦æ ¡åç§°åº”è¯¥æ˜¯å…·ä½“çš„æ•™è‚²æœºæ„åç§°ã€‚
        ä¾‹å¦‚ï¼Œ"å¤§å­¦"è¿™æ ·çš„æ³›ç§°åº”è¢«è§†ä¸ºæ— æ•ˆï¼Œè€Œ"åŒ—äº¬å¤§å­¦"åˆ™æ˜¯æœ‰æ•ˆçš„ã€‚
        """,
        "analysis_instructions": """
        åˆ†ææ—¶æ³¨æ„è¯†åˆ«å­¦æ ¡çš„å®˜æ–¹åç§°ã€å¸¸ç”¨ç®€ç§°ç­‰ã€‚
        éœ€è¦è€ƒè™‘å­¦æ ¡å¯èƒ½çš„æ›´åå†å²å’Œåˆ†æ ¡æƒ…å†µã€‚
        ä¾‹å¦‚ï¼Œå¦‚æœæœç´¢ç»“æœæ˜¾ç¤º"æ¸…åå¤§å­¦æ·±åœ³ç ”ç©¶ç”Ÿé™¢"ï¼Œ
        åº”è¯¥å°†"æ¸…åå¤§å­¦"è¯†åˆ«ä¸ºæ ‡å‡†åŒ–çš„å­¦æ ¡åç§°ã€‚
        """,
        "verification_instructions": """
        éªŒè¯æ—¶è€ƒè™‘å­¦æ ¡çš„ä¸åŒç§°å‘¼ï¼ŒåŒ…æ‹¬å…¨ç§°ã€ç®€ç§°ã€ä¿—ç§°ç­‰ã€‚
        åªè¦æŒ‡å‘åŒä¸€æ‰€å­¦æ ¡ï¼Œå³ä½¿è¡¨è¿°ä¸åŒä¹Ÿåº”è§†ä¸ºåŒ¹é…ã€‚
        ä¾‹å¦‚ï¼Œ"åŒ—å¤§"å’Œ"åŒ—äº¬å¤§å­¦"åº”è¯¥è¢«è§†ä¸ºåŒ¹é…ã€‚
        """,
    },
}


def initialize_workflow(
    use_demo: bool,
    entity_type: str,
    skip_validation: bool,
    skip_search: bool,
    skip_retrieval: bool,
) -> EntityVerificationWorkflow:
    """
    åˆå§‹åŒ–å®ä½“éªŒè¯å·¥ä½œæµã€‚

    Args:
        use_demo (bool): æ˜¯å¦ä½¿ç”¨æ¼”ç¤ºæ•°æ®ã€‚
        entity_type (str): å®ä½“ç±»å‹ã€‚
        skip_validation (bool): æ˜¯å¦è·³è¿‡è¾“å…¥éªŒè¯ã€‚
        skip_search (bool): æ˜¯å¦è·³è¿‡ç½‘ç»œæœç´¢å’Œåˆ†æã€‚
        skip_retrieval (bool): æ˜¯å¦è·³è¿‡å‘é‡æ£€ç´¢å’ŒåŒ¹é…ã€‚

    Returns:
        EntityVerificationWorkflow: åˆå§‹åŒ–åçš„å·¥ä½œæµå¯¹è±¡ã€‚
    """
    entity_info = ENTITY_TYPES[entity_type]
    vector_store = initialize_vector_store(
        use_demo, entity_info["csv_path"], entity_info["collection_name"]
    )
    retriever = get_entity_retriever(vector_store)
    return EntityVerificationWorkflow(
        retriever=retriever,
        entity_type=entity_type,
        validation_instructions=entity_info["validation_instructions"],
        analysis_instructions=entity_info["analysis_instructions"],
        verification_instructions=entity_info["verification_instructions"],
        skip_validation=skip_validation,
        skip_search=skip_search,
        skip_retrieval=skip_retrieval,
    )


def main():
    st.title("ğŸ¢ è‡ªåŠ¨åŒ–æ•°æ®æ¸…æ´—")
    st.markdown("---")

    # æ˜¾ç¤ºåŠŸèƒ½ä»‹ç»
    display_info_message()

    # æ˜¾ç¤ºå·¥ä½œæµç¨‹
    display_workflow()

    use_demo = st.checkbox(
        "ä½¿ç”¨æ¼”ç¤ºæ•°æ®",
        value=False,
        help="å‹¾é€‰æ­¤é¡¹å°†ä½¿ç”¨é¢„è®¾çš„æ¼”ç¤ºæ•°æ®ï¼Œå¦åˆ™å°†ä½¿ç”¨å·²å­˜åœ¨çš„æ•°æ®åº“æ•°æ®ã€‚",
    )

    # é€‰æ‹©å®ä½“ç±»å‹
    entity_type = st.selectbox("é€‰æ‹©å®ä½“ç±»å‹", list(ENTITY_TYPES.keys()))

    # æ–°å¢ï¼šå·¥ä½œæµç¨‹é€‰é¡¹
    st.subheader("å·¥ä½œæµç¨‹é€‰é¡¹")
    skip_validation = st.checkbox(
        "è·³è¿‡è¾“å…¥éªŒè¯", value=False, help="å¦‚æœç¡®ä¿¡è¾“å…¥æ•°æ®æœ‰æ•ˆï¼Œå¯ä»¥è·³è¿‡éªŒè¯æ­¥éª¤ã€‚"
    )
    skip_search = st.checkbox(
        "è·³è¿‡ç½‘ç»œæœç´¢",
        value=False,
        help="å¯¹äºçŸ¥åå®ä½“ï¼Œå¯ä»¥ç›´æ¥è¿›è¡Œå‘é‡æ£€ç´¢ï¼Œè·³è¿‡ç½‘ç»œæœç´¢æ­¥éª¤ã€‚",
    )
    skip_retrieval = st.checkbox(
        "è·³è¿‡å‘é‡æ£€ç´¢",
        value=False,
        help="å¦‚æœæ²¡æœ‰å†å²æ•°æ®æˆ–å¤„ç†æ–°å®ä½“ï¼Œå¯ä»¥è·³è¿‡å‘é‡æ£€ç´¢æ­¥éª¤ã€‚",
    )

    # åˆå§‹åŒ–å·¥ä½œæµ
    workflow = initialize_workflow(
        use_demo, entity_type, skip_validation, skip_search, skip_retrieval
    )

    # å•ä¸ªå®ä½“éªŒè¯
    single_entity_verification(workflow, entity_type)

    # æ‰¹é‡å¤„ç†
    batch_processing(workflow, entity_type)

    # é¡µè„š
    show_footer()


def display_info_message():
    """
    æ˜¾ç¤ºè‡ªåŠ¨åŒ–æ•°æ®æ¸…æ´—çš„åŠŸèƒ½ä»‹ç»ã€‚
    """
    st.info(
        """
    è‡ªåŠ¨åŒ–æ•°æ®æ¸…æ´—å·¥å…·é›†æˆäº†å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†å’Œå·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œå®ç°é«˜æ•ˆç²¾å‡†çš„æ•°æ®æ ‡å‡†åŒ–ã€‚

    ç³»ç»Ÿé€šè¿‡å¤šé˜¶æ®µéªŒè¯æµç¨‹ï¼Œæ™ºèƒ½è¯†åˆ«å’ŒéªŒè¯è¾“å…¥çš„å®ä½“åç§°ï¼Œå¹¶åˆ©ç”¨å‘é‡æ£€ç´¢æŠ€æœ¯åœ¨æ•°æ®åº“ä¸­è¿›è¡Œå¿«é€ŸåŒ¹é…ã€‚
    é€‚ç”¨äºéœ€è¦å¤§è§„æ¨¡æ ‡å‡†åŒ–å’ŒéªŒè¯å„ç±»å®ä½“åç§°çš„æ•°æ®å¤„ç†åœºæ™¯ã€‚
    """
    )


def display_workflow():
    """
    æ˜¾ç¤ºè‡ªåŠ¨åŒ–æ•°æ®æ¸…æ´—å·¥å…·çš„å·¥ä½œæµç¨‹ã€‚
    """
    with st.expander("ğŸ¢ æŸ¥çœ‹è‡ªåŠ¨åŒ–æ•°æ®æ¸…æ´—å·¥ä½œæµç¨‹", expanded=False):

        with st.container(border=True):
            col1, col2 = st.columns([1, 1])

            with col1:
                image = Image.open("frontend/assets/data_cleaning_workflow.png")
                st.image(image, caption="è‡ªåŠ¨åŒ–æ•°æ®æ¸…æ´—æµç¨‹å›¾", use_column_width=True)

            with col2:
                st.markdown(
                    """
                    <div class="workflow-container">
                        <div class="workflow-step">
                            <strong>1. æ™ºèƒ½æ•°æ®éªŒè¯</strong>: åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹çš„è‡ªç„¶è¯­è¨€ç†è§£èƒ½åŠ›ï¼Œæ™ºèƒ½è¯†åˆ«å’Œåˆæ­¥éªŒè¯è¾“å…¥çš„å®ä½“åç§°ã€‚
                        </div>
                        <div class="workflow-step">
                            <strong>2. å¤šæºç½‘ç»œæœç´¢</strong>: è°ƒç”¨å¤šä¸ªæœç´¢å¼•æ“APIï¼Œå…¨é¢æ”¶é›†å®ä½“ç›¸å…³ä¿¡æ¯ï¼Œä¸ºåç»­åˆ†ææä¾›ä¸°å¯Œæ•°æ®æ”¯æŒã€‚
                        </div>
                        <div class="workflow-step">
                            <strong>3. å¤§æ¨¡å‹æ¨ç†åˆ†æ</strong>: è¿ç”¨å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä»æœç´¢ç»“æœä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¦‚å®ä½“å…¨ç§°ã€ç®€ç§°ç­‰ã€‚
                        </div>
                        <div class="workflow-step">
                            <strong>4. å‘é‡æ£€ç´¢åŒ¹é…</strong>: å°†å¤„ç†åçš„å®ä½“ä¿¡æ¯è½¬åŒ–ä¸ºå‘é‡ï¼Œåœ¨é¢„æ„å»ºçš„å¤§è§„æ¨¡å®ä½“å‘é‡æ•°æ®åº“ä¸­è¿›è¡Œé«˜æ•ˆã€ç²¾å‡†çš„ç›¸ä¼¼åº¦åŒ¹é…ã€‚
                        </div>
                        <div class="workflow-step">
                            <strong>5. ç»“æœéªŒè¯ä¸è¾“å‡º</strong>: å¤§è¯­è¨€æ¨¡å‹å¯¹å¤šæºä¿¡æ¯å’ŒåŒ¹é…ç»“æœè¿›è¡Œç»¼åˆåˆ†æå’ŒéªŒè¯ï¼Œç”Ÿæˆæœ€ç»ˆçš„æ ‡å‡†åŒ–å®ä½“åç§°ã€‚
                        </div>
                    </div>
                    """,
                    unsafe_allow_html=True,
                )


def single_entity_verification(workflow: EntityVerificationWorkflow, entity_type: str):
    """
    å¤„ç†å•ä¸ªå®ä½“åç§°çš„æ ‡å‡†åŒ–ã€‚

    Args:
        workflow (EntityVerificationWorkflow): å®ä½“åç§°æ ‡å‡†åŒ–çš„å·¥ä½œæµå¯¹è±¡ã€‚
        entity_type (str): å®ä½“ç±»å‹ã€‚
    """
    st.markdown(
        f'<h2 class="section-title">å•ä¸ª{entity_type}æ ‡å‡†åŒ–</h2>',
        unsafe_allow_html=True,
    )
    with st.form(key="single_entity_form"):
        entity_name = st.text_input(
            f"è¾“å…¥{entity_type}",
            placeholder=f"ä¾‹å¦‚ï¼š{'é˜¿é‡Œå·´å·´' if entity_type == 'å…¬å¸åç§°' else 'åŒ—äº¬å¤§å­¦'}",
        )
        submit_button = st.form_submit_button("æ ‡å‡†åŒ–")
        if submit_button and entity_name:
            with st.spinner("æ­£åœ¨æ ‡å‡†åŒ–..."):
                session_id = str(uuid4())
                result = workflow.run(entity_name, session_id=session_id)
            display_single_result(result, entity_type)


def display_single_result(result: Dict[str, Any], entity_type: str):
    """
    æ˜¾ç¤ºå•ä¸ªå®ä½“åç§°æ ‡å‡†åŒ–çš„ç»“æœã€‚

    Args:
        result (Dict[str, Any]): æ ‡å‡†åŒ–ç»“æœå­—å…¸ã€‚
        entity_type (str): å®ä½“ç±»å‹ã€‚
    """
    st.success("æ•°æ®å¤„ç†å®Œæˆï¼")
    col1, col2 = st.columns(2)
    with col1:
        st.metric(f"æœ€ç»ˆ{entity_type}", result["final_entity_name"])
    with col2:
        if not result["is_valid"]:
            status = "æ— æ•ˆè¾“å…¥"
        elif result["verification_status"] != "not_applicable":
            if result["verification_status"] == "verified":
                status = "å·²éªŒè¯"
            elif result["verification_status"] == "unverified":
                status = "æœªéªŒè¯"
            else:
                status = "éªŒè¯å¤±è´¥"
        elif result["recognition_status"] == "known":
            status = "å·²è¯†åˆ«"
        elif result["recognition_status"] == "unknown":
            status = "æœªè¯†åˆ«"
        elif result["recognition_status"] == "skipped":
            status = "è·³è¿‡è¯†åˆ«"
        else:
            status = "æœªçŸ¥"
        st.metric("æ ‡å‡†åŒ–çŠ¶æ€", status)

    with st.expander("æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯"):
        st.json(result)

    if status == "æ— æ•ˆè¾“å…¥":
        st.error("è¾“å…¥è¢«åˆ¤å®šä¸ºæ— æ•ˆï¼Œè¯·æ£€æŸ¥å¹¶é‡æ–°è¾“å…¥ã€‚")
    elif status in ["æœªéªŒè¯", "éªŒè¯å¤±è´¥", "æœªè¯†åˆ«", "æœªçŸ¥"]:
        st.warning("æ­¤ç»“æœå¯èƒ½éœ€è¦è¿›ä¸€æ­¥ç¡®è®¤ã€‚")
    elif status == "è·³è¿‡è¯†åˆ«":
        st.info("ç½‘ç»œæœç´¢æ­¥éª¤è¢«è·³è¿‡ã€‚å¦‚éœ€æ›´é«˜å‡†ç¡®åº¦ï¼Œè¯·è€ƒè™‘å¯ç”¨å®Œæ•´è¯†åˆ«æµç¨‹ã€‚")


def batch_processing(workflow: EntityVerificationWorkflow, entity_type: str):
    """
    å¤„ç†æ‰¹é‡å®ä½“åç§°æ ‡å‡†åŒ–ã€‚

    Args:
        workflow (EntityVerificationWorkflow): å®ä½“åç§°æ ‡å‡†åŒ–å·¥ä½œæµå¯¹è±¡ã€‚
        entity_type (str): å®ä½“ç±»å‹ã€‚
    """
    st.markdown(
        f'<h2 class="section-title">æ‰¹é‡{entity_type}æ ‡å‡†åŒ–</h2>',
        unsafe_allow_html=True,
    )
    with st.container(border=True):
        uploaded_file = st.file_uploader(
            f"ä¸Šä¼ CSVæ–‡ä»¶ï¼ˆåŒ…å«{entity_type}åˆ—ï¼‰", type="csv"
        )
        if uploaded_file is not None:
            df = pd.read_csv(uploaded_file)
            st.write("é¢„è§ˆä¸Šä¼ çš„æ•°æ®ï¼š")
            st.dataframe(df.head())
            if st.button("å¼€å§‹æ‰¹é‡å¤„ç†"):
                process_batch(df, workflow, entity_type)

        # æ˜¾ç¤ºå¤„ç†ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
        if st.session_state.batch_results_df is not None:
            display_batch_results(st.session_state.batch_results_df, entity_type)


def process_batch(
    df: pd.DataFrame, workflow: EntityVerificationWorkflow, entity_type: str
):
    """
    å¤„ç†æ‰¹é‡å®ä½“æ•°æ®ã€‚

    Args:
        df (pd.DataFrame): åŒ…å«å®ä½“åç§°çš„DataFrameã€‚
        workflow (EntityVerificationWorkflow): å®ä½“åç§°æ ‡å‡†åŒ–å·¥ä½œæµå¯¹è±¡ã€‚
        entity_type (str): å®ä½“ç±»å‹ã€‚
    """
    results = []
    progress_bar = st.progress(0)
    for i, entity_name in enumerate(df.iloc[:, 0]):
        with st.spinner(f"æ­£åœ¨å¤„ç†: {entity_name}"):
            session_id = str(uuid4())  # ä¸ºæ¯ä¸ªå®ä½“ç”Ÿæˆæ–°çš„ session_id
            result = workflow.run(entity_name, session_id=session_id)
            results.append(result)
        progress_bar.progress((i + 1) / len(df))

    result_df = pd.DataFrame(results)

    # æ·»åŠ åŸå§‹è¾“å…¥åˆ—
    result_df.insert(0, "åŸå§‹è¾“å…¥", df.iloc[:, 0])

    # æ›´æ–°ä¼šè¯çŠ¶æ€
    st.session_state.batch_results_df = result_df
    st.session_state.processing_complete = True


def display_batch_results(result_df: pd.DataFrame, entity_type: str):
    """
    æ˜¾ç¤ºæ‰¹é‡å¤„ç†ç»“æœã€‚

    Args:
        result_df (pd.DataFrame): åŒ…å«å¤„ç†ç»“æœçš„DataFrameã€‚
        entity_type (str): å®ä½“ç±»å‹ã€‚
    """
    st.success("æ‰¹é‡å¤„ç†å®Œæˆï¼")

    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    total_count = len(result_df)
    verified_count = (result_df["verification_status"] == "verified").sum()
    unverified_count = (result_df["verification_status"] == "unverified").sum()
    identified_count = (
        (result_df["recognition_status"] == "known")
        & (result_df["verification_status"] == "not_applicable")
    ).sum()
    unidentified_count = (
        (result_df["recognition_status"] == "unknown")
        & (result_df["verification_status"] == "not_applicable")
    ).sum()
    skipped_recognition_count = (result_df["recognition_status"] == "skipped").sum()
    invalid_count = (~result_df["is_valid"]).sum()

    # æ˜¾ç¤ºç®€åŒ–çš„ç»“æœç»Ÿè®¡
    st.subheader("å¤„ç†ç»“æœç»Ÿè®¡")
    stats_df = pd.DataFrame(
        {
            "ç±»åˆ«": [
                "æ€»æ•°",
                "å·²éªŒè¯",
                "æœªéªŒè¯",
                "å·²è¯†åˆ«ï¼ˆæœªéªŒè¯ï¼‰",
                "æœªè¯†åˆ«",
                "è·³è¿‡è¯†åˆ«",
                "æ— æ•ˆè¾“å…¥",
            ],
            "æ•°é‡": [
                total_count,
                verified_count,
                unverified_count,
                identified_count,
                unidentified_count,
                skipped_recognition_count,
                invalid_count,
            ],
        }
    )
    st.table(stats_df.set_index("ç±»åˆ«"))

    # æ˜¾ç¤ºç»“æœè¡¨æ ¼
    st.subheader("è¯¦ç»†ç»“æœ")
    st.dataframe(
        result_df[
            [
                "åŸå§‹è¾“å…¥",
                "final_entity_name",
                "recognition_status",
                "verification_status",
                "is_valid",
            ]
        ]
    )

    # æä¾›å»ºè®®
    if unverified_count > 0 or unidentified_count > 0 or invalid_count > 0:
        st.warning(
            f"æœ‰ {unverified_count} ä¸ªå®ä½“æœªéªŒè¯ï¼Œ{unidentified_count} ä¸ªæœªè¯†åˆ«ï¼Œ{invalid_count} ä¸ªæ— æ•ˆè¾“å…¥ã€‚å»ºè®®æ‰‹åŠ¨æ£€æŸ¥è¿™äº›ç»“æœã€‚"
        )
    if skipped_recognition_count > 0:
        st.info(
            f"æœ‰ {skipped_recognition_count} ä¸ªå®ä½“è·³è¿‡äº†è¯†åˆ«æ­¥éª¤ã€‚å¦‚éœ€æ›´é«˜å‡†ç¡®åº¦ï¼Œè¯·è€ƒè™‘å¯ç”¨å®Œæ•´è¯†åˆ«æµç¨‹ã€‚"
        )
    if identified_count > 0:
        st.info(
            f"æœ‰ {identified_count} ä¸ªå®ä½“å·²è¯†åˆ«ä½†æœªç»è¿‡éªŒè¯ã€‚å¦‚éœ€æ›´é«˜å‡†ç¡®åº¦ï¼Œè¯·è€ƒè™‘å¯ç”¨å‘é‡æ£€ç´¢éªŒè¯æ­¥éª¤ã€‚"
        )

    # æä¾›ä¸‹è½½é€‰é¡¹
    csv = result_df.to_csv(index=False)
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½å¤„ç†ç»“æœ",
        data=csv.encode("utf-8-sig"),
        file_name=f"processed_{entity_type.lower().replace(' ', '_')}.csv",
        mime="text/csv",
    )


if __name__ == "__main__":
    main()
