import streamlit as st
from PIL import Image
import pandas as pd
import plotly.graph_objects as go
import sys
import os
import numpy as np
import io
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
import hashlib

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(project_root)

from frontend.ui_components import show_sidebar, show_footer, apply_common_styles
from backend.data_processing.analysis.feature_importance_evaluator import (
    encode_categorical_variables,
    random_forest_analysis,
    shap_analysis,
    linear_regression_analysis,
    filter_dataframe,
    calculate_shap_dependence,
)

# Streamlit é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½HRåŠ©æ‰‹ - å½±å“å› ç´ åˆ†æ",
    page_icon="ğŸ“Š",
)

# åº”ç”¨è‡ªå®šä¹‰æ ·å¼
apply_common_styles()

# æ˜¾ç¤ºä¾§è¾¹æ 
show_sidebar()


# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
def initialize_session_state():
    """
    åˆå§‹åŒ– Streamlit ä¼šè¯çŠ¶æ€ï¼Œè®¾ç½®é»˜è®¤å€¼ã€‚
    """
    default_states = {
        "param_ranges": {
            "n_estimators": (10, 100),
            "max_depth": (5, 20),
            "min_samples_split": (2, 20),
            "min_samples_leaf": (1, 20),
            "max_features": ["sqrt", "log2"],
        },
        "best_params": None,
        "df": None,
        "filtered_df": None,
        "selected_columns": None,
        "filters": [],
        "model": None,
        "feature_importance": None,
        "shap_values": None,
        "model_hash": None,
    }

    for key, value in default_states.items():
        if key not in st.session_state:
            st.session_state[key] = value


initialize_session_state()


def calculate_model_hash(
    analysis_method, use_optuna, param_ranges, target_column, feature_columns, filters
):
    """
    è®¡ç®—æ¨¡å‹çš„å“ˆå¸Œå€¼ï¼Œç”¨äºç¡®å®šæ˜¯å¦éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚

    Args:
        analysis_method (str): åˆ†ææ–¹æ³•ã€‚
        use_optuna (bool): æ˜¯å¦ä½¿ç”¨ Optuna è¿›è¡Œå‚æ•°ä¼˜åŒ–ã€‚
        param_ranges (dict): å‚æ•°èŒƒå›´ã€‚
        target_column (str): ç›®æ ‡åˆ—åã€‚
        feature_columns (list): ç‰¹å¾åˆ—ååˆ—è¡¨ã€‚
        filters (list): åº”ç”¨çš„è¿‡æ»¤å™¨åˆ—è¡¨ã€‚

    Returns:
        str: è®¡ç®—å¾—åˆ°çš„å“ˆå¸Œå€¼ã€‚
    """
    hash_string = f"{analysis_method}_{use_optuna}_{param_ranges}_{target_column}_{feature_columns}_{filters}"
    return hashlib.md5(hash_string.encode()).hexdigest()


def plot_impact(impact, title):
    """
    ç»˜åˆ¶å½±å“å› ç´ çš„æ¡å½¢å›¾ã€‚

    Args:
        impact (pd.Series): åŒ…å«å½±å“åº¦æ•°æ®çš„ Seriesã€‚
        title (str): å›¾è¡¨æ ‡é¢˜ã€‚
    """
    impact_sorted = impact.sort_values(ascending=True)
    fig = go.Figure(
        data=[go.Bar(x=impact_sorted.values, y=impact_sorted.index, orientation="h")]
    )
    fig.update_layout(
        title=title,
        xaxis_title="å½±å“åº¦",
        yaxis_title="å› ç´ ",
        height=max(500, len(impact_sorted) * 20),
        width=800,
        margin=dict(l=200),
    )
    st.plotly_chart(fig)


def create_excel_download(corr_matrix, feature_importance, shap_values=None):
    """
    åˆ›å»ºåŒ…å«åˆ†æç»“æœçš„ Excel æ–‡ä»¶ã€‚

    Args:
        corr_matrix (pd.DataFrame): ç›¸å…³æ€§çŸ©é˜µã€‚
        feature_importance (pd.DataFrame): ç‰¹å¾é‡è¦æ€§æ•°æ®ã€‚
        shap_values (pd.DataFrame, optional): SHAP å€¼æ•°æ®ã€‚

    Returns:
        bytes: Excel æ–‡ä»¶çš„äºŒè¿›åˆ¶æ•°æ®ã€‚
    """
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        corr_matrix.to_excel(writer, sheet_name="ç›¸å…³æ€§çƒ­å›¾")
        feature_importance.reset_index().to_excel(
            writer, sheet_name="ç‰¹å¾é‡è¦æ€§", index=False
        )
        if shap_values is not None:
            shap_values.reset_index().to_excel(writer, sheet_name="SHAPå€¼", index=False)
    output.seek(0)
    return output


def main():
    """
    ä¸»å‡½æ•°ï¼ŒåŒ…å«å½±å“å› ç´ åˆ†æçš„æ•´ä¸ªæµç¨‹ã€‚
    """
    st.title("ğŸ“Š å½±å“å› ç´ åˆ†æ")
    st.markdown("---")

    display_info_message()
    display_workflow()

    uploaded_file = upload_file()
    if uploaded_file is None:
        return

    display_data_filtering()
    display_column_selection_and_preprocessing()
    display_correlation_heatmap()
    display_model_analysis()
    display_feature_importance()
    display_shap_analysis()
    display_download_button()

    show_footer()


def display_info_message():
    """
    æ˜¾ç¤ºå½±å“å› ç´ åˆ†æå·¥å…·çš„ä¿¡æ¯æ¶ˆæ¯ã€‚
    """
    st.info(
        """
    **ğŸ” å½±å“å› ç´ åˆ†æå·¥å…·**

    å½±å“å› ç´ åˆ†æåŠŸèƒ½ç»“åˆç»Ÿè®¡å’Œæœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå¸®åŠ©ç”¨æˆ·è¯†åˆ«å’Œé‡åŒ–å„ç§å› ç´ å¯¹ç‰¹å®šç›®æ ‡å˜é‡çš„å½±å“ç¨‹åº¦ã€‚
    
    æ ¸å¿ƒåˆ†æåŒ…æ‹¬å¤šç§æ¨¡å‹ï¼ˆå¦‚çº¿æ€§å›å½’å’Œéšæœºæ£®æ—ï¼‰ã€SHAPå€¼åˆ†æå’Œä¾èµ–å›¾ã€‚é€šè¿‡äº¤äº’å¼å¯è§†åŒ–ï¼Œ
    å¯ä»¥ç›´è§‚åœ°æ¢ç´¢å’Œè§£é‡Šåˆ†æç»“æœã€‚
    
    è¯¥å·¥å…·è¿˜æ”¯æŒæ¨¡å‹å‚æ•°ä¼˜åŒ–ï¼Œå¹¶æä¾›æ•°æ®ç­›é€‰å’Œå¼‚å¸¸å€¼å¤„ç†ç­‰è¾…åŠ©åŠŸèƒ½ï¼Œ
    é€‚ç”¨äºå„ç§éœ€è¦æ·±å…¥ç†è§£å˜é‡å…³ç³»å’Œå½±å“å› ç´ çš„æ•°æ®åˆ†æåœºæ™¯ã€‚
    """
    )


def display_workflow():
    """
    æ˜¾ç¤ºå½±å“å› ç´ åˆ†æçš„å·¥ä½œæµç¨‹ã€‚
    """
    with st.expander("ğŸ“‹ æŸ¥çœ‹å½±å“å› ç´ åˆ†æå·¥ä½œæµç¨‹", expanded=False):
        st.markdown(
            '<h2 class="section-title">å½±å“å› ç´ åˆ†æå·¥ä½œæµç¨‹</h2>',
            unsafe_allow_html=True,
        )
        with st.container(border=True):
            col1, col2 = st.columns([1, 1])

            with col1:
                image = Image.open(
                    "frontend/assets/feature_importance_evaluator_workflow.png"
                )
                st.image(image, caption="å½±å“å› ç´ åˆ†ææµç¨‹å›¾", use_column_width=True)

            with col2:
                st.markdown(
                    """
                    **1. æ•°æ®å‡†å¤‡**
                    é€‰æ‹©ç›®æ ‡å˜é‡å’Œç›¸å…³ç‰¹å¾ï¼Œå¯¹æ•°æ®è¿›è¡Œå¿…è¦çš„ç­›é€‰å’Œé¢„å¤„ç†ã€‚
                    
                    **2. åˆæ­¥åˆ†æ**
                    ç”Ÿæˆç›¸å…³æ€§çƒ­å›¾ï¼Œç›´è§‚å±•ç¤ºå˜é‡é—´çš„å…³è”å¼ºåº¦ã€‚
        
                    **3. æ¨¡å‹è®­ç»ƒ**
                    è®­ç»ƒçº¿æ€§å›å½’æˆ–éšæœºæ£®æ—æ¨¡å‹ï¼Œå¯é€‰æ‹©ä½¿ç”¨å‚æ•°è‡ªåŠ¨è°ƒä¼˜æ¥ä¼˜åŒ–æ€§èƒ½ã€‚
        
                    **4. ç‰¹å¾é‡è¦æ€§**
                    è®¡ç®—æ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§ï¼Œå¹¶è¿›è¡ŒSHAPå€¼åˆ†æä»¥é‡åŒ–ç‰¹å¾è´¡çŒ®ã€‚
        
                    **5. æ¨¡å‹è§£é‡Š**
                    é€šè¿‡SHAPä¾èµ–å›¾å’Œç‰¹å¾äº¤äº’åˆ†æï¼Œæ·±å…¥è§£é‡Šæ¨¡å‹é¢„æµ‹å’Œç‰¹å¾å½±å“ã€‚
        
                    **6. ç»“æœå¯è§†åŒ–**
                    ä½¿ç”¨é‡è¦æ€§æ’åºå›¾å’Œäº¤äº’å¼SHAPå›¾è¡¨ï¼Œç›´è§‚å‘ˆç°åˆ†æç»“æœã€‚
                """
                )


def upload_file():
    """
    å¤„ç†æ–‡ä»¶ä¸Šä¼ å¹¶åŠ è½½æ•°æ®ã€‚

    Returns:
        pd.DataFrame or None: åŠ è½½çš„æ•°æ®æ¡†ï¼Œå¦‚æœä¸Šä¼ å¤±è´¥åˆ™è¿”å›Noneã€‚
    """
    st.markdown('<h2 class="section-title">æ•°æ®ä¸Šä¼ </h2>', unsafe_allow_html=True)
    with st.container(border=True):
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ CSVæˆ–Excelæ–‡ä»¶", type=["csv", "xlsx", "xls"]
        )

        if uploaded_file is not None:
            try:
                if uploaded_file.name.endswith(".csv"):
                    st.session_state.df = pd.read_csv(uploaded_file)
                elif uploaded_file.name.endswith((".xls", ".xlsx")):
                    st.session_state.df = pd.read_excel(uploaded_file)
                else:
                    st.error("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚è¯·ä¸Šä¼ CSVæˆ–Excelæ–‡ä»¶ã€‚")
                    return None

                st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
                st.write(
                    f"æ•°æ®é›†åŒ…å« {len(st.session_state.df)} è¡Œå’Œ {len(st.session_state.df.columns)} åˆ—"
                )
                st.write(st.session_state.df.head())
                return st.session_state.df

            except Exception as e:
                st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}")
                return None

    return None


def display_data_filtering():
    """
    æ˜¾ç¤ºå¹¶å¤„ç†æ•°æ®ç­›é€‰ç•Œé¢ã€‚
    """
    if st.session_state.df is None:
        return

    st.markdown('<h2 class="section-title">æ•°æ®ç­›é€‰</h2>', unsafe_allow_html=True)
    with st.container(border=True):
        add_filter()
        display_current_filters()
        apply_filters()


def add_filter():
    """
    æ·»åŠ æ–°çš„ç­›é€‰æ¡ä»¶ã€‚
    """
    col1, col2, col3, col4 = st.columns([3, 2, 3, 1])
    with col1:
        filter_column = st.selectbox(
            "é€‰æ‹©ç­›é€‰å­—æ®µ",
            [""] + list(st.session_state.df.columns),
            key="filter_column",
        )

    if filter_column:
        with col2:
            filter_type = get_filter_type(filter_column)
        with col3:
            filter_value = get_filter_value(filter_column, filter_type)
        with col4:
            if st.button("æ·»åŠ ", key="add_filter"):
                st.session_state.filters.append(
                    (filter_column, filter_type, filter_value)
                )
                apply_filter(filter_column, filter_type, filter_value)
                st.rerun()


def get_filter_type(column):
    """
    æ ¹æ®åˆ—çš„æ•°æ®ç±»å‹è·å–é€‚å½“çš„ç­›é€‰ç±»å‹ã€‚

    Args:
        column (str): åˆ—åã€‚

    Returns:
        str: ç­›é€‰ç±»å‹ã€‚
    """
    if st.session_state.df[column].dtype == "object":
        return st.selectbox(
            "ç­›é€‰ç±»å‹", ["åŒ…å«", "ä¸åŒ…å«", "ä¸ºç©º", "éç©º"], key="filter_type"
        )
    else:
        return st.selectbox(
            "ç­›é€‰ç±»å‹",
            [
                "å¤§äº",
                "å¤§äºç­‰äº",
                "å°äº",
                "å°äºç­‰äº",
                "ç­‰äº",
                "ä¸ç­‰äº",
                "ä¹‹é—´",
                "ä¸ºç©º",
                "éç©º",
            ],
            key="filter_type",
        )


def get_filter_value(column, filter_type):
    """
    æ ¹æ®åˆ—å’Œç­›é€‰ç±»å‹è·å–ç­›é€‰å€¼ã€‚

    Args:
        column (str): åˆ—åã€‚
        filter_type (str): ç­›é€‰ç±»å‹ã€‚

    Returns:
        ä»»æ„: ç­›é€‰å€¼ã€‚
    """
    if st.session_state.df[column].dtype == "object":
        if filter_type in ["åŒ…å«", "ä¸åŒ…å«"]:
            return st.multiselect(
                "é€‰æ‹©å€¼", st.session_state.df[column].unique(), key="filter_value"
            )
        else:  # "ä¸ºç©º" æˆ– "éç©º"
            return None
    elif filter_type == "ä¹‹é—´":
        return st.slider(
            "é€‰æ‹©èŒƒå›´",
            float(st.session_state.df[column].min()),
            float(st.session_state.df[column].max()),
            (
                float(st.session_state.df[column].min()),
                float(st.session_state.df[column].max()),
            ),
            key="filter_value",
        )
    elif filter_type in ["ä¸ºç©º", "éç©º"]:
        return None
    else:
        return st.number_input(
            "è¾“å…¥å€¼",
            value=float(st.session_state.df[column].mean()),
            key="filter_value",
        )


def display_current_filters():
    """
    æ˜¾ç¤ºå½“å‰çš„ç­›é€‰æ¡ä»¶ã€‚
    """
    if st.session_state.filters:
        with st.expander("å½“å‰ç­›é€‰æ¡ä»¶", expanded=True):
            for i, (col, type_, val) in enumerate(st.session_state.filters):
                col1, col2 = st.columns([5, 1])
                with col1:
                    if val is None:
                        st.write(f"{i + 1}. {col} {type_}")
                    else:
                        st.write(f"{i + 1}. {col} {type_} {val}")
                with col2:
                    if st.button("åˆ é™¤", key=f"delete_{i}"):
                        st.session_state.filters.pop(i)
                        apply_filters()
                        st.rerun()


def apply_filters():
    """
    åº”ç”¨æ‰€æœ‰ç­›é€‰æ¡ä»¶åˆ°æ•°æ®æ¡†ã€‚
    """
    if st.button("æ¸…é™¤æ‰€æœ‰ç­›é€‰æ¡ä»¶"):
        st.session_state.filters = []
        st.session_state.filtered_df = st.session_state.df
        reset_selected_columns()
        st.rerun()

    if st.session_state.filters:
        filters = {col: (type_, val) for col, type_, val in st.session_state.filters}
        st.session_state.filtered_df = filter_dataframe(st.session_state.df, filters)
        st.write(f"ç­›é€‰åçš„æ•°æ®é›†åŒ…å« {len(st.session_state.filtered_df)} è¡Œ")
        st.write(st.session_state.filtered_df.head())
    else:
        st.session_state.filtered_df = st.session_state.df


def apply_filter(column, filter_type, filter_value):
    """
    åº”ç”¨å•ä¸ªç­›é€‰æ¡ä»¶åˆ°æ•°æ®æ¡†ã€‚

    Args:
        column (str): åˆ—åã€‚
        filter_type (str): ç­›é€‰ç±»å‹ã€‚
        filter_value: ç­›é€‰å€¼ã€‚
    """
    filters = {column: (filter_type, filter_value)}
    st.session_state.filtered_df = filter_dataframe(
        st.session_state.filtered_df, filters
    )
    update_selected_columns()


def reset_selected_columns():
    """
    é‡ç½®é€‰ä¸­çš„åˆ—ä¸ºæ‰€æœ‰æ•°å€¼åˆ—ã€‚
    """
    numeric_columns = st.session_state.df.select_dtypes(
        include=[np.number]
    ).columns.tolist()
    st.session_state.selected_columns = numeric_columns


def update_selected_columns():
    """
    æ›´æ–°é€‰ä¸­çš„åˆ—ï¼Œç§»é™¤ç­›é€‰åä¸å­˜åœ¨çš„åˆ—ã€‚
    """
    if (
        "selected_columns" in st.session_state
        and st.session_state.selected_columns is not None
    ):
        st.session_state.selected_columns = [
            col
            for col in st.session_state.selected_columns
            if col in st.session_state.filtered_df.columns
        ]
    else:
        reset_selected_columns()


def display_column_selection_and_preprocessing():
    """
    æ˜¾ç¤ºåˆ—é€‰æ‹©å’Œé¢„å¤„ç†é€‰é¡¹ã€‚
    """
    if st.session_state.filtered_df is None:
        return

    st.markdown(
        '<h2 class="section-title">é€‰æ‹©åˆ†æåˆ—å’Œé¢„å¤„ç†</h2>', unsafe_allow_html=True
    )
    with st.container(border=True):
        handle_categorical_encoding()
        select_analysis_columns()


def handle_categorical_encoding():
    """
    å¤„ç†åˆ†ç±»å˜é‡çš„ç¼–ç ã€‚
    """
    categorical_columns = st.session_state.filtered_df.select_dtypes(
        include=["object"]
    ).columns.tolist()
    if categorical_columns:
        encode_categorical = st.checkbox("å¯¹ç¦»æ•£å˜é‡è¿›è¡Œç¼–ç ")
        if encode_categorical:
            selected_categorical = st.multiselect(
                "é€‰æ‹©è¦ç¼–ç çš„ç¦»æ•£å˜é‡", categorical_columns
            )
            if selected_categorical:
                st.session_state.filtered_df = encode_categorical_variables(
                    st.session_state.filtered_df, selected_categorical
                )
                st.success("ç¦»æ•£å˜é‡ç¼–ç å®Œæˆï¼")


def select_analysis_columns():
    """
    é€‰æ‹©è¦åˆ†æçš„åˆ—ã€‚
    """
    numeric_columns = st.session_state.filtered_df.select_dtypes(
        include=[np.number]
    ).columns.tolist()
    columns_without_none = [
        col
        for col in numeric_columns
        if not st.session_state.filtered_df[col].isnull().any()
    ]

    if (
        "selected_columns" not in st.session_state
        or st.session_state.selected_columns is None
    ):
        st.session_state.selected_columns = columns_without_none
    else:
        st.session_state.selected_columns = [
            col
            for col in st.session_state.selected_columns
            if col in columns_without_none
        ]

    selected_columns = st.multiselect(
        "é€‰æ‹©è¦åˆ†æçš„åˆ—", numeric_columns, default=st.session_state.selected_columns
    )

    handle_columns_with_none(selected_columns)

    st.session_state.selected_columns = selected_columns

    if len(st.session_state.selected_columns) < 2:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸¤åˆ—è¿›è¡Œåˆ†æã€‚")


def handle_columns_with_none(selected_columns):
    """
    å¤„ç†åŒ…å«Noneå€¼çš„åˆ—ã€‚

    Args:
        selected_columns (list): é€‰ä¸­çš„åˆ—ååˆ—è¡¨ã€‚
    """
    columns_with_none = [
        col
        for col in selected_columns
        if st.session_state.filtered_df[col].isnull().any()
    ]

    if columns_with_none:
        rows_before = len(st.session_state.filtered_df)
        st.session_state.filtered_df = st.session_state.filtered_df.dropna(
            subset=selected_columns
        )
        rows_after = len(st.session_state.filtered_df)

        st.warning(
            f"ä»¥ä¸‹é€‰æ‹©çš„å­—æ®µåŒ…å«Noneå€¼ï¼š{', '.join(columns_with_none)}\n\n"
            f"å·²åˆ é™¤åŒ…å«Noneå€¼çš„{rows_before - rows_after}è¡Œæ•°æ®ã€‚"
        )


def display_correlation_heatmap():
    """
    æ˜¾ç¤ºç›¸å…³æ€§çƒ­å›¾ã€‚
    """
    if st.session_state.filtered_df is None or not st.session_state.selected_columns:
        return

    st.markdown('<h2 class="section-title">ç›¸å…³æ€§çƒ­å›¾</h2>', unsafe_allow_html=True)
    with st.container(border=True):
        corr_matrix = st.session_state.filtered_df[
            st.session_state.selected_columns
        ].corr()
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
        corr_matrix_low = corr_matrix.mask(mask)

        fig = go.Figure(
            data=go.Heatmap(
                z=corr_matrix_low.values,
                x=corr_matrix_low.columns,
                y=corr_matrix_low.index,
                colorscale="RdBu",
                zmin=-1,
                zmax=1,
            )
        )
        fig.update_layout(height=600, width=800)
        st.plotly_chart(fig)


def display_model_analysis():
    """
    æ˜¾ç¤ºæ¨¡å‹åˆ†æé€‰é¡¹å¹¶æ‰§è¡Œåˆ†æã€‚
    """
    if st.session_state.filtered_df is None or not st.session_state.selected_columns:
        return

    st.markdown('<h2 class="section-title">æ¨¡å‹åˆ†æä¸è§£é‡Š</h2>', unsafe_allow_html=True)
    with st.container(border=True):
        target_column = st.selectbox("é€‰æ‹©ç›®æ ‡åˆ—", st.session_state.selected_columns)
        feature_columns = [
            col for col in st.session_state.selected_columns if col != target_column
        ]

        analysis_method = st.radio("é€‰æ‹©åˆ†ææ–¹æ³•", ["çº¿æ€§å›å½’", "éšæœºæ£®æ—"])
        use_shap = st.checkbox("ä½¿ç”¨SHAPå€¼è§£é‡Šæ¨¡å‹")
        st.session_state.use_shap = use_shap

        X = st.session_state.filtered_df[feature_columns]
        y = st.session_state.filtered_df[target_column]

        use_optuna = False
        if analysis_method == "éšæœºæ£®æ—":
            use_optuna = st.checkbox("ä½¿ç”¨ Optuna ä¼˜åŒ–éšæœºæ£®æ—å‚æ•°")
            if use_optuna:
                display_advanced_settings()

        perform_model_analysis(
            analysis_method, use_optuna, X, y, target_column, feature_columns
        )


def display_advanced_settings():
    """
    æ˜¾ç¤ºé«˜çº§è®¾ç½®é€‰é¡¹ã€‚
    """
    with st.expander("é«˜çº§è®¾ç½®"):
        st.write("è‡ªå®šä¹‰å‚æ•°æœç´¢èŒƒå›´")
        n_estimators_range = st.slider(
            "n_estimators èŒƒå›´", 5, 300, st.session_state.param_ranges["n_estimators"]
        )
        max_depth_range = st.slider(
            "max_depth èŒƒå›´", 1, 100, st.session_state.param_ranges["max_depth"]
        )
        min_samples_split_range = st.slider(
            "min_samples_split èŒƒå›´",
            2,
            50,
            st.session_state.param_ranges["min_samples_split"],
        )
        min_samples_leaf_range = st.slider(
            "min_samples_leaf èŒƒå›´",
            1,
            50,
            st.session_state.param_ranges["min_samples_leaf"],
        )
        max_features_options = st.multiselect(
            "max_features é€‰é¡¹",
            ["sqrt", "log2", "auto"],
            default=st.session_state.param_ranges["max_features"],
        )

        if st.button("ç¡®è®¤å‚æ•°è®¾ç½®"):
            update_param_ranges(
                n_estimators_range,
                max_depth_range,
                min_samples_split_range,
                min_samples_leaf_range,
                max_features_options,
            )


def update_param_ranges(
    n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features
):
    """
    æ›´æ–°å‚æ•°èŒƒå›´è®¾ç½®ã€‚

    Args:
        n_estimators (tuple): n_estimators çš„èŒƒå›´ã€‚
        max_depth (tuple): max_depth çš„èŒƒå›´ã€‚
        min_samples_split (tuple): min_samples_split çš„èŒƒå›´ã€‚
        min_samples_leaf (tuple): min_samples_leaf çš„èŒƒå›´ã€‚
        max_features (list): max_features çš„é€‰é¡¹åˆ—è¡¨ã€‚
    """
    st.session_state.param_ranges["n_estimators"] = n_estimators
    st.session_state.param_ranges["max_depth"] = max_depth
    st.session_state.param_ranges["min_samples_split"] = min_samples_split
    st.session_state.param_ranges["min_samples_leaf"] = min_samples_leaf
    st.session_state.param_ranges["max_features"] = max_features
    st.success("å‚æ•°è®¾ç½®å·²æ›´æ–°")


def perform_model_analysis(
    analysis_method, use_optuna, X, y, target_column, feature_columns
):
    """
    æ‰§è¡Œæ¨¡å‹åˆ†æã€‚

    Args:
        analysis_method (str): åˆ†ææ–¹æ³•ï¼ˆ"çº¿æ€§å›å½’"æˆ–"éšæœºæ£®æ—"ï¼‰ã€‚
        use_optuna (bool): æ˜¯å¦ä½¿ç”¨Optunaä¼˜åŒ–å‚æ•°ã€‚
        X (pd.DataFrame): ç‰¹å¾æ•°æ®ã€‚
        y (pd.Series): ç›®æ ‡å˜é‡ã€‚
        target_column (str): ç›®æ ‡åˆ—åã€‚
        feature_columns (list): ç‰¹å¾åˆ—ååˆ—è¡¨ã€‚
    """
    new_model_hash = calculate_model_hash(
        analysis_method,
        use_optuna,
        st.session_state.param_ranges,
        target_column,
        feature_columns,
        st.session_state.filters,
    )

    if new_model_hash != st.session_state.model_hash:
        st.session_state.model = None
        st.session_state.feature_importance = None
        st.session_state.shap_values = None
        st.session_state.model_hash = new_model_hash

    if st.session_state.model is None:
        with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹..."):
            if analysis_method == "çº¿æ€§å›å½’":
                st.session_state.model, st.session_state.feature_importance = (
                    linear_regression_analysis(X, y)
                )
            else:  # éšæœºæ£®æ—
                (
                    st.session_state.model,
                    st.session_state.feature_importance,
                    best_params,
                ) = random_forest_analysis(
                    X, y, use_optuna, st.session_state.param_ranges
                )
                if use_optuna and best_params:
                    with st.expander("æŸ¥çœ‹éšæœºæ£®æ—æœ€ä½³å‚æ•°"):
                        st.json(best_params)
        st.success("æ¨¡å‹è®­ç»ƒå®Œæˆï¼")


def display_feature_importance():
    """
    æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§å›¾è¡¨ã€‚
    """
    if st.session_state.feature_importance is None:
        return

    st.markdown('<h2 class="section-title">æ¨¡å‹ç‰¹å¾é‡è¦æ€§</h2>', unsafe_allow_html=True)
    with st.container(border=True):
        plot_impact(
            st.session_state.feature_importance,
            f"å„å› ç´ å¯¹ {st.session_state.selected_columns[0]} çš„å½±å“åº¦",
        )


def display_shap_analysis():
    """
    æ˜¾ç¤ºSHAPå€¼åˆ†æç»“æœã€‚
    """
    if not st.session_state.get("use_shap", False) or st.session_state.model is None:
        return

    st.markdown('<h2 class="section-title">SHAPå€¼åˆ†æ</h2>', unsafe_allow_html=True)
    with st.container(border=True):
        if st.session_state.shap_values is None:
            with st.spinner("æ­£åœ¨è®¡ç®—SHAPå€¼..."):
                X = st.session_state.filtered_df[st.session_state.selected_columns[1:]]
                st.session_state.shap_values = shap_analysis(st.session_state.model, X)

        if st.session_state.shap_values is not None:
            plot_impact(
                st.session_state.shap_values,
                f"å„å› ç´ å¯¹ {st.session_state.selected_columns[0]} çš„SHAPå€¼",
            )
            display_shap_dependence()
        else:
            st.error("æ— æ³•è®¡ç®—SHAPå€¼ã€‚è¯·ç¡®ä¿æ¨¡å‹å’Œæ•°æ®å·²æ­£ç¡®åŠ è½½ã€‚")


def display_shap_dependence():
    """
    æ˜¾ç¤ºSHAPä¾èµ–å›¾ã€‚
    """
    show_shap_dependence = st.checkbox("å±•ç¤ºSHAPä¾èµ–å›¾")
    if show_shap_dependence:
        st.markdown('<h3 class="section-title">SHAPä¾èµ–å›¾</h3>', unsafe_allow_html=True)

        plot_all = st.checkbox("ç»˜åˆ¶æ‰€æœ‰ç‰¹å¾çš„SHAPä¾èµ–å›¾", value=False)

        if plot_all:
            plot_all_shap_dependence()
        else:
            plot_single_shap_dependence()


def plot_single_shap_dependence():
    """
    ç»˜åˆ¶å•ä¸ªé€‰å®šç‰¹å¾çš„SHAPä¾èµ–å›¾ã€‚
    """
    selected_feature = st.selectbox(
        "é€‰æ‹©è¦å±•ç¤ºä¾èµ–å›¾çš„ç‰¹å¾", st.session_state.selected_columns[1:]
    )
    plot_shap_dependence(selected_feature)


def plot_all_shap_dependence():
    """
    ç»˜åˆ¶æ‰€æœ‰ç‰¹å¾çš„SHAPä¾èµ–å›¾ã€‚
    """
    with st.spinner("æ­£åœ¨ç”Ÿæˆæ‰€æœ‰ç‰¹å¾çš„SHAPä¾èµ–å›¾..."):
        for feature in st.session_state.selected_columns[1:]:
            plot_shap_dependence(feature)


def plot_shap_dependence(feature):
    """
    ç»˜åˆ¶æŒ‡å®šç‰¹å¾çš„SHAPä¾èµ–å›¾ã€‚

    Args:
        feature (str): è¦ç»˜åˆ¶ä¾èµ–å›¾çš„ç‰¹å¾åã€‚
    """
    with st.spinner(f"æ­£åœ¨ç”Ÿæˆ {feature} çš„SHAPä¾èµ–å›¾..."):
        feature_values, shap_values = calculate_shap_dependence(
            st.session_state.model,
            st.session_state.filtered_df[st.session_state.selected_columns[1:]],
            feature,
        )

        fig = go.Figure()
        fig.add_trace(
            go.Scatter(
                x=feature_values,
                y=shap_values,
                mode="markers",
                marker=dict(
                    size=8,
                    color=feature_values,
                    colorscale="RdBu",
                    colorbar=dict(title=feature),
                    showscale=True,
                ),
                text=feature_values,
                hoverinfo="text+y",
            )
        )

        fig.update_layout(
            title=f"SHAPä¾èµ–å›¾ - {feature}",
            xaxis_title=feature,
            yaxis_title="SHAPå€¼",
            height=600,
            width=800,
        )

        st.plotly_chart(fig)


def display_download_button():
    """
    æ˜¾ç¤ºä¸‹è½½åˆ†æç»“æœçš„æŒ‰é’®ã€‚
    """
    if st.session_state.filtered_df is None or not st.session_state.selected_columns:
        return

    corr_matrix = st.session_state.filtered_df[st.session_state.selected_columns].corr()
    feature_importance_df = pd.DataFrame(
        {"importance": st.session_state.feature_importance}
    )
    shap_values_df = (
        pd.DataFrame({"shap_value": st.session_state.shap_values})
        if st.session_state.get("use_shap")
        else None
    )

    excel_file = create_excel_download(
        corr_matrix, feature_importance_df, shap_values_df
    )

    st.download_button(
        label="ğŸ“¥ ä¸‹è½½åˆ†æç»“æœ (Excel)",
        data=excel_file,
        file_name="å½±å“å› ç´ åˆ†æç»“æœ.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
    st.caption(
        f"Excelæ–‡ä»¶åŒ…å«ï¼šç›¸å…³æ€§çƒ­å›¾ã€ç‰¹å¾é‡è¦æ€§{' å’ŒSHAPå€¼' if st.session_state.get('use_shap') else ''}ã€‚"
    )


if __name__ == "__main__":
    main()
