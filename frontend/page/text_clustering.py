import streamlit as st
import pandas as pd
import sys
import os
import uuid
import io

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(project_root)

from backend.text_processing.clustering.clustering_workflow import (
    generate_categories,
    classify_texts,
)
from frontend.ui_components import show_sidebar, show_footer, apply_common_styles

st.query_params.role = st.session_state.role

# åº”ç”¨è‡ªå®šä¹‰æ ·å¼
apply_common_styles()

# æ˜¾ç¤ºä¾§è¾¹æ 
show_sidebar()


def initialize_session_state():
    """
    åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡
    """
    session_vars = [
        "df_preprocessed",
        "categories",
        "df_result",
        "text_column",
        "text_topic",
        "session_id",
        "clustering_params",
        "use_custom_categories",
    ]
    for var in session_vars:
        if var not in st.session_state:
            st.session_state[var] = None

    # ç¡®ä¿session_idæ€»æ˜¯æœ‰å€¼
    if st.session_state.session_id is None:
        st.session_state.session_id = str(uuid.uuid4())

    # åˆå§‹åŒ– clustering_params
    if st.session_state.clustering_params is None:
        st.session_state.clustering_params = {
            "min_categories": 10,
            "max_categories": 15,
            "batch_size": 100,
            "classification_batch_size": 20,
        }

    # åˆå§‹åŒ– use_custom_categories
    if st.session_state.use_custom_categories is None:
        st.session_state.use_custom_categories = False


def main():
    """
    ä¸»å‡½æ•°ï¼Œæ§åˆ¶é¡µé¢æµç¨‹å’Œå¸ƒå±€
    """
    initialize_session_state()

    st.title("ğŸ”¬ æ–‡æœ¬èšç±»åˆ†æ")
    st.markdown("---")

    display_info_message()
    display_workflow_introduction()

    handle_data_input_and_clustering()
    handle_custom_categories()
    review_clustering_results()
    display_classification_results()

    show_footer()


def display_info_message():
    """
    æ˜¾ç¤ºè¡¨æ ¼å¤„ç†åŠ©æ‰‹çš„ä¿¡æ¯æ¶ˆæ¯ã€‚
    """
    st.info(
        """
        æ–‡æœ¬èšç±»åˆ†æå·¥å…·åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œè‡ªåŠ¨åŒ–åœ°ä»å¤§é‡æ–‡æœ¬ä¸­è¯†åˆ«å’Œå½’ç±»ä¸»è¦ä¸»é¢˜ã€‚

        å·¥å…·é‡‡ç”¨åˆ†æ‰¹å¤„ç†å’Œå¤šé˜¶æ®µèšç±»ç­–ç•¥ï¼Œèƒ½å¤Ÿé«˜æ•ˆå¤„ç†å¤§è§„æ¨¡æ–‡æœ¬æ•°æ®ã€‚æ”¯æŒè‡ªå®šä¹‰ç±»åˆ«æ•°é‡èŒƒå›´ï¼Œå¹¶æä¾›äº¤äº’å¼çš„ç±»åˆ«å®¡æ ¸å’Œç¼–è¾‘åŠŸèƒ½ï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿæ ¹æ®å…·ä½“éœ€æ±‚ä¼˜åŒ–èšç±»ç»“æœã€‚
        
        é€‚ç”¨äºå„ç±»æ–‡æœ¬å†…å®¹åˆ†æåœºæ™¯ï¼Œå¦‚ç”¨æˆ·åé¦ˆå½’ç±»ã€è¯é¢˜è¶‹åŠ¿åˆ†æç­‰ã€‚

        ç°åœ¨è¿˜æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰ç±»åˆ«ï¼Œè·³è¿‡è‡ªåŠ¨èšç±»è¿‡ç¨‹ï¼Œç›´æ¥è¿›è¡Œæ–‡æœ¬åˆ†ç±»ã€‚
        """
    )


def display_workflow_introduction():
    with st.expander("ğŸ“‹ æŸ¥çœ‹æ–‡æœ¬èšç±»åˆ†æå·¥ä½œæµç¨‹", expanded=False):
        with st.container(border=True):
            st.markdown(
                """
            1. **æ•°æ®å‡†å¤‡ä¸å‚æ•°è®¾ç½®**

                ä¸Šä¼ CSVæ–‡ä»¶ï¼Œé€‰æ‹©æ–‡æœ¬åˆ—ï¼Œè¾“å…¥ä¸»é¢˜èƒŒæ™¯ï¼Œå¹¶è®¾ç½®èšç±»å‚æ•°ã€‚

            2. **é€‰æ‹©èšç±»æ–¹å¼**

                é€‰æ‹©ä½¿ç”¨è‡ªåŠ¨èšç±»æˆ–æä¾›è‡ªå®šä¹‰ç±»åˆ«ã€‚

            3a. **è‡ªåŠ¨èšç±»æµç¨‹**

                - åˆå§‹èšç±»ä¸ç±»åˆ«ä¼˜åŒ–ï¼šç³»ç»Ÿä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œåˆå§‹æ–‡æœ¬åˆ†ç±»ï¼Œç„¶ååˆå¹¶å’Œä¼˜åŒ–ç±»åˆ«ã€‚
                - äººå·¥å®¡æ ¸ä¸è°ƒæ•´ï¼šå±•ç¤ºå¹¶å…è®¸ç¼–è¾‘ç”Ÿæˆçš„ç±»åˆ«åˆ—è¡¨ï¼Œä¼˜åŒ–ç±»åˆ«åç§°å’Œæè¿°ã€‚

            3b. **è‡ªå®šä¹‰ç±»åˆ«æµç¨‹**

                - ä¸Šä¼ æˆ–è¾“å…¥è‡ªå®šä¹‰ç±»åˆ«ï¼šæä¾›åŒ…å«ç±»åˆ«åç§°å’Œæè¿°çš„CSVæ–‡ä»¶ï¼Œæˆ–ç›´æ¥åœ¨ç•Œé¢ä¸­è¾“å…¥ã€‚
                - å®¡æ ¸ä¸è°ƒæ•´ï¼šæŸ¥çœ‹å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹è‡ªå®šä¹‰ç±»åˆ«ã€‚

            4. **æ–‡æœ¬åˆ†ç±»ä¸ç»“æœç”Ÿæˆ**

                åŸºäºç¡®è®¤çš„ç±»åˆ«å¯¹æ‰€æœ‰æ–‡æœ¬è¿›è¡Œåˆ†ç±»ï¼Œç”Ÿæˆå¹¶å±•ç¤ºæœ€ç»ˆç»“æœã€‚

            5. **ç»“æœå¯¼å‡º**

                æä¾›åˆ†ç±»ç»“æœçš„CSVæ ¼å¼ä¸‹è½½é€‰é¡¹ã€‚
            """
            )


def handle_data_input_and_clustering():
    """
    å¤„ç†æ•°æ®è¾“å…¥å’Œåˆå§‹èšç±»è¿‡ç¨‹
    """
    st.markdown("## æ•°æ®è¾“å…¥å’Œèšç±»è®¾ç½®")

    with st.container(border=True):
        st.session_state.text_topic = st.text_input(
            "è¯·è¾“å…¥æ–‡æœ¬ä¸»é¢˜æˆ–èƒŒæ™¯",
            value=st.session_state.text_topic if st.session_state.text_topic else "",
            placeholder="ä¾‹å¦‚ï¼šå‘˜å·¥åé¦ˆã€äº§å“è¯„è®ºã€å®¢æˆ·æ„è§ç­‰",
        )

        uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type="csv")
        if uploaded_file is not None:
            df = pd.read_csv(uploaded_file)
            df['unique_id'] = [f"ID{i:06d}" for i in range(1, len(df) + 1)]
            st.session_state.df_preprocessed = df
            
            st.write("é¢„è§ˆä¸Šä¼ çš„æ•°æ®ï¼š")
            st.write(df.head())
            st.session_state.text_column = st.selectbox("é€‰æ‹©åŒ…å«æ–‡æœ¬çš„åˆ—", df.columns)

            st.session_state.use_custom_categories = st.radio(
                "é€‰æ‹©èšç±»æ–¹å¼",
                ["è‡ªåŠ¨èšç±»", "ä½¿ç”¨è‡ªå®šä¹‰ç±»åˆ«"],
                format_func=lambda x: "è‡ªåŠ¨èšç±»" if x == "è‡ªåŠ¨èšç±»" else "ä½¿ç”¨è‡ªå®šä¹‰ç±»åˆ«",
            ) == "ä½¿ç”¨è‡ªå®šä¹‰ç±»åˆ«"

            if not st.session_state.use_custom_categories:
                st.session_state.clustering_params = get_clustering_parameters()

                if st.button("å¼€å§‹åˆå§‹èšç±»"):
                    with st.spinner("æ­£åœ¨è¿›è¡Œåˆå§‹èšç±»..."):
                        result = generate_categories(
                            df=df,
                            text_column=st.session_state.text_column,
                            text_topic=st.session_state.text_topic,
                            initial_category_count=st.session_state.clustering_params[
                                "max_categories"
                            ],
                            min_categories=st.session_state.clustering_params[
                                "min_categories"
                            ],
                            max_categories=st.session_state.clustering_params[
                                "max_categories"
                            ],
                            batch_size=st.session_state.clustering_params["batch_size"],
                            session_id=st.session_state.session_id,
                        )

                    st.success("åˆå§‹èšç±»å®Œæˆï¼")

                    # ä¿å­˜ç»“æœåˆ° session state
                    st.session_state.df_preprocessed = result["preprocessed_df"]
                    st.session_state.categories = result["categories"]["categories"]

            st.session_state.df_preprocessed = df

        else:
            st.warning("è¯·ä¸Šä¼ CSVæ–‡ä»¶")


def get_clustering_parameters():
    """
    è·å–èšç±»å‚æ•°è®¾ç½®

    Returns:
        dict: åŒ…å«èšç±»å‚æ•°çš„å­—å…¸
    """
    with st.expander("èšç±»å‚æ•°è®¾ç½®"):
        min_categories = st.slider(
            "æœ€å°ç±»åˆ«æ•°é‡",
            5,
            15,
            st.session_state.clustering_params["min_categories"],
            key="min_categories_slider",
        )
        max_categories = st.slider(
            "æœ€å¤§ç±»åˆ«æ•°é‡",
            min_categories,
            20,
            st.session_state.clustering_params["max_categories"],
            key="max_categories_slider",
        )
        batch_size = st.slider(
            "èšç±»æ‰¹å¤„ç†å¤§å°",
            10,
            1000,
            st.session_state.clustering_params["batch_size"],
            key="batch_size_slider",
        )
        classification_batch_size = st.slider(
            "åˆ†ç±»æ‰¹å¤„ç†å¤§å°",
            10,
            100,
            st.session_state.clustering_params["classification_batch_size"],
            key="classification_batch_size_slider",
        )

    return {
        "min_categories": min_categories,
        "max_categories": max_categories,
        "batch_size": batch_size,
        "classification_batch_size": classification_batch_size,
    }


def handle_custom_categories():
    """
    å¤„ç†ç”¨æˆ·è‡ªå®šä¹‰ç±»åˆ«çš„è¾“å…¥
    """
    if st.session_state.use_custom_categories and st.session_state.df_preprocessed is not None:
        st.markdown("## è‡ªå®šä¹‰ç±»åˆ«è¾“å…¥")
        with st.container(border=True):
            custom_category_method = st.radio(
                "é€‰æ‹©è‡ªå®šä¹‰ç±»åˆ«çš„æ–¹å¼",
                ["ä¸Šä¼ CSVæ–‡ä»¶", "æ‰‹åŠ¨è¾“å…¥"],
                format_func=lambda x: "ä¸Šä¼ CSVæ–‡ä»¶" if x == "ä¸Šä¼ CSVæ–‡ä»¶" else "æ‰‹åŠ¨è¾“å…¥",
            )

            if custom_category_method == "ä¸Šä¼ CSVæ–‡ä»¶":
                uploaded_categories = st.file_uploader("ä¸Šä¼ åŒ…å«è‡ªå®šä¹‰ç±»åˆ«çš„CSVæ–‡ä»¶", type="csv")
                if uploaded_categories is not None:
                    categories_df = pd.read_csv(uploaded_categories)
                    st.session_state.categories = categories_df.to_dict("records")
                    st.success("è‡ªå®šä¹‰ç±»åˆ«å·²æˆåŠŸä¸Šä¼ ï¼")
            else:
                categories_text = st.text_area(
                    "è¯·è¾“å…¥è‡ªå®šä¹‰ç±»åˆ«ï¼ˆæ¯è¡Œä¸€ä¸ªç±»åˆ«ï¼Œæ ¼å¼ï¼šç±»åˆ«åç§°,ç±»åˆ«æè¿°ï¼‰",
                    height=200,
                    placeholder="å·¥ä½œç¯å¢ƒ,æè¿°å‘˜å·¥å¯¹å…¬å¸å·¥ä½œç¯å¢ƒçš„æ„Ÿå—ï¼ŒåŒ…æ‹¬èˆ’é€‚åº¦ã€è®¾å¤‡å’Œè½¯ä»¶çš„å…ˆè¿›æ€§ç­‰ã€‚\nè–ªèµ„ä¸ç¦åˆ©,è®¨è®ºå‘˜å·¥å¯¹è–ªèµ„æ°´å¹³å’Œç¦åˆ©å¾…é‡çš„çœ‹æ³•ï¼ŒåŒ…æ‹¬ä¸è¡Œä¸šæ°´å¹³çš„æ¯”è¾ƒã€æå‡ç©ºé—´å’Œå¥åº·ä¿é™©ç­‰ã€‚",
                )
                if categories_text:
                    categories_list = [line.split(",", 1) for line in categories_text.split("\n") if line.strip()]
                    categories_df = pd.DataFrame(categories_list, columns=["name", "description"])
                    st.session_state.categories = categories_df.to_dict("records")
                    st.success("è‡ªå®šä¹‰ç±»åˆ«å·²æˆåŠŸæ·»åŠ ï¼")


def review_clustering_results():
    """
    å®¡æ ¸èšç±»ç»“æœå¹¶å…è®¸ç”¨æˆ·ä¿®æ”¹
    """
    if st.session_state.categories is not None:
        st.markdown("---")
        st.markdown("## èšç±»ç»“æœå®¡æ ¸")

        with st.container(border=True):
            st.markdown("è¯·å®¡æ ¸å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹ã€æ·»åŠ æˆ–åˆ é™¤ç±»åˆ«ï¼š")

            # å°†ç±»åˆ«åˆ—è¡¨è½¬æ¢ä¸ºDataFrameä»¥ä¾¿ä½¿ç”¨st.data_editor
            categories_df = pd.DataFrame(st.session_state.categories)[
                ["name", "description"]
            ]

            # ä½¿ç”¨st.data_editoræ¥å±•ç¤ºå’Œç¼–è¾‘ç±»åˆ«
            edited_df = st.data_editor(
                categories_df,
                num_rows="dynamic",
                column_config={
                    "name": st.column_config.TextColumn(
                        "ç±»åˆ«åç§°",
                        help="ç®€æ´æ˜äº†çš„ç±»åˆ«æ ‡ç­¾",
                        max_chars=50,
                        required=True,
                    ),
                    "description": st.column_config.TextColumn(
                        "ç±»åˆ«æè¿°",
                        help="è¯¦ç»†æè¿°è¯¥ç±»åˆ«çš„ç‰¹å¾åŠä¸å…¶ä»–ç±»åˆ«çš„åŒºåˆ«",
                        max_chars=200,
                        required=True,
                    ),
                },
            )

            # å°†ç¼–è¾‘åçš„DataFrameè½¬æ¢å›ç±»åˆ«åˆ—è¡¨
            edited_categories = edited_df.to_dict("records")

            if st.button("ç¡®è®¤ç±»åˆ«å¹¶å¼€å§‹æ–‡æœ¬åˆ†ç±»"):
                with st.spinner("æ­£åœ¨è¿›è¡Œæ–‡æœ¬åˆ†ç±»..."):
                    df_result = classify_texts(
                        df=st.session_state.df_preprocessed,
                        text_column=st.session_state.text_column,
                        id_column="unique_id",
                        categories={"categories": edited_categories},
                        text_topic=st.session_state.text_topic,
                        session_id=st.session_state.session_id,
                        classification_batch_size=st.session_state.clustering_params[
                            "classification_batch_size"
                        ],
                    )

                st.session_state.df_result = df_result
                st.success("æ–‡æœ¬åˆ†ç±»å®Œæˆï¼")


def display_classification_results():
    """
    å±•ç¤ºåˆ†ç±»ç»“æœ
    """
    if st.session_state.df_result is not None:
        st.markdown("---")
        st.markdown("## åˆ†ç±»ç»“æœå±•ç¤º")

        with st.container(border=True):
            st.dataframe(st.session_state.df_result)

            # æä¾›ä¸‹è½½é€‰é¡¹
            csv = st.session_state.df_result.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="ä¸‹è½½åˆ†ç±»ç»“æœCSV",
                data=csv,
                file_name="classification_results.csv",
                mime="text/csv",
            )


main()