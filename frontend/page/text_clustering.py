import streamlit as st
import pandas as pd
import sys
import os
import uuid
import asyncio
from typing import Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(project_root)

from backend.text_processing.clustering.clustering_workflow import (
    generate_categories,
    classify_texts,
)
from frontend.ui_components import show_sidebar, show_footer, apply_common_styles

st.query_params.role = st.session_state.role

# åº”ç”¨è‡ªå®šä¹‰æ ·å¼
apply_common_styles()

# æ˜¾ç¤ºä¾§è¾¹æ 
show_sidebar()


def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡"""
    session_vars = [
        "df_preprocessed",
        "categories",
        "df_result",
        "text_column",
        "text_topic",
        "session_id",
        "clustering_params",
        "use_custom_categories",
        "additional_requirements",
    ]
    for var in session_vars:
        if var not in st.session_state:
            st.session_state[var] = None

    if st.session_state.session_id is None:
        st.session_state.session_id = str(uuid.uuid4())

    if st.session_state.clustering_params is None:
        st.session_state.clustering_params = {
            "min_categories": 10,
            "max_categories": 15,
            "batch_size": 100,
            "classification_batch_size": 20,
        }

    if st.session_state.use_custom_categories is None:
        st.session_state.use_custom_categories = False

    if st.session_state.additional_requirements is None:
        st.session_state.additional_requirements = None


def display_info_message():
    """æ˜¾ç¤ºæ–‡æœ¬èšç±»åˆ†æå·¥å…·çš„ä¿¡æ¯æ¶ˆæ¯"""
    st.info(
        """
        æ–‡æœ¬èšç±»åˆ†æå·¥å…·åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œè‡ªåŠ¨åŒ–åœ°ä»å¤§é‡æ–‡æœ¬ä¸­è¯†åˆ«å’Œå½’ç±»ä¸»è¦ä¸»é¢˜ã€‚
        
        é€‚ç”¨äºå„ç±»æ–‡æœ¬å†…å®¹åˆ†æåœºæ™¯ï¼Œå¦‚ç”¨æˆ·åé¦ˆå½’ç±»ã€è¯é¢˜è¶‹åŠ¿åˆ†æç­‰ã€‚
        """
    )


def display_workflow_introduction():
    """æ˜¾ç¤ºå·¥ä½œæµç¨‹è¯´æ˜"""
    with st.expander("ğŸ“‹ æŸ¥çœ‹æ–‡æœ¬èšç±»åˆ†æä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown(
            """
            1. ä¸Šä¼ æ•°æ®ï¼šå‡†å¤‡åŒ…å«æ–‡æœ¬æ•°æ®çš„CSVæ–‡ä»¶ï¼Œå¹¶ä¸Šä¼ åˆ°ç³»ç»Ÿã€‚
            2. è®¾ç½®å‚æ•°ï¼šé€‰æ‹©æ–‡æœ¬åˆ—ï¼Œè¾“å…¥ä¸»é¢˜èƒŒæ™¯ï¼Œè®¾ç½®èšç±»å‚æ•°ã€‚
            3. åˆå§‹èšç±»ï¼šç³»ç»Ÿè‡ªåŠ¨è¿›è¡Œåˆå§‹èšç±»ï¼Œç”Ÿæˆç±»åˆ«ã€‚
            4. å®¡æ ¸ç±»åˆ«ï¼šæŸ¥çœ‹å¹¶ç¼–è¾‘ç”Ÿæˆçš„ç±»åˆ«ï¼Œç¡®ä¿ç¬¦åˆéœ€æ±‚ã€‚
            5. æ–‡æœ¬åˆ†ç±»ï¼šå¯¹æ‰€æœ‰æ–‡æœ¬è¿›è¡Œåˆ†ç±»ã€‚
            6. æŸ¥çœ‹ç»“æœï¼šæµè§ˆåˆ†ç±»ç»“æœï¼Œä¸‹è½½åˆ†ææŠ¥å‘Šã€‚
            """
        )


def get_clustering_parameters():
    """è·å–å¹¶æ›´æ–°èšç±»å‚æ•°è®¾ç½®"""
    with st.expander("è‡ªåŠ¨èšç±»å‚æ•°è®¾ç½®"):
        st.session_state.clustering_params["min_categories"] = st.slider(
            "æœ€å°ç±»åˆ«æ•°é‡",
            5,
            15,
            st.session_state.clustering_params.get("min_categories", 10),
            key="min_categories_slider",
        )
        st.session_state.clustering_params["max_categories"] = st.slider(
            "æœ€å¤§ç±»åˆ«æ•°é‡",
            st.session_state.clustering_params["min_categories"],
            20,
            st.session_state.clustering_params.get("max_categories", 15),
            key="max_categories_slider",
        )
        st.session_state.clustering_params["batch_size"] = st.slider(
            "èšç±»æ‰¹å¤„ç†å¤§å°",
            10,
            1000,
            st.session_state.clustering_params.get("batch_size", 100),
            key="batch_size_slider",
        )
        st.session_state.clustering_params["classification_batch_size"] = st.slider(
            "åˆ†ç±»æ‰¹å¤„ç†å¤§å°",
            10,
            100,
            st.session_state.clustering_params.get("classification_batch_size", 20),
            key="classification_batch_size_slider",
        )


def get_custom_classification_parameters():
    """è·å–å¹¶æ›´æ–°è‡ªå®šä¹‰åˆ†ç±»å‚æ•°è®¾ç½®"""
    with st.expander("è‡ªå®šä¹‰ç±»åˆ«åˆ†ç±»å‚æ•°è®¾ç½®"):
        st.session_state.clustering_params["classification_batch_size"] = st.slider(
            "åˆ†ç±»æ‰¹å¤„ç†å¤§å°",
            10,
            100,
            st.session_state.clustering_params.get("classification_batch_size", 20),
            key="custom_classification_batch_size_slider",
        )


def handle_data_input_and_clustering():
    """å¤„ç†æ•°æ®è¾“å…¥å’Œåˆå§‹èšç±»è¿‡ç¨‹"""
    st.markdown("## æ•°æ®è¾“å…¥å’Œèšç±»è®¾ç½®")

    with st.container(border=True):
        st.session_state.text_topic = st.text_input(
            "è¯·è¾“å…¥æ–‡æœ¬ä¸»é¢˜æˆ–èƒŒæ™¯",
            value=st.session_state.text_topic if st.session_state.text_topic else "",
            placeholder="ä¾‹å¦‚ï¼šå‘˜å·¥åé¦ˆã€äº§å“è¯„è®ºã€å®¢æˆ·æ„è§ç­‰",
        )

        st.session_state.additional_requirements = st.text_area(
            "è¡¥å……è¦æ±‚ï¼ˆå¯é€‰ï¼‰",
            value=(
                st.session_state.additional_requirements
                if st.session_state.additional_requirements
                else ""
            ),
            placeholder="ä¾‹å¦‚ï¼šå¿½ç•¥å‘˜å·¥å¯¹äºè–ªé…¬ç¦åˆ©çš„æŠ±æ€¨",
        )

        uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type="csv")
        if uploaded_file is not None:
            df = pd.read_csv(uploaded_file)
            df["unique_id"] = [f"ID{i:06d}" for i in range(1, len(df) + 1)]
            st.session_state.df_preprocessed = df

            st.write("é¢„è§ˆä¸Šä¼ çš„æ•°æ®ï¼š")
            st.dataframe(df, height=250)
            st.session_state.text_column = st.selectbox("é€‰æ‹©åŒ…å«æ–‡æœ¬çš„åˆ—", df.columns)

            previous_use_custom_categories = st.session_state.get(
                "use_custom_categories", False
            )
            st.session_state.use_custom_categories = (
                st.radio(
                    "é€‰æ‹©èšç±»æ–¹å¼",
                    ["è‡ªåŠ¨èšç±»", "ä½¿ç”¨è‡ªå®šä¹‰ç±»åˆ«"],
                    format_func=lambda x: (
                        "è‡ªåŠ¨èšç±»" if x == "è‡ªåŠ¨èšç±»" else "ä½¿ç”¨è‡ªå®šä¹‰ç±»åˆ«"
                    ),
                )
                == "ä½¿ç”¨è‡ªå®šä¹‰ç±»åˆ«"
            )

            # æ£€æŸ¥æ˜¯å¦åˆ‡æ¢äº†èšç±»æ–¹å¼
            if st.session_state.use_custom_categories != previous_use_custom_categories:
                # é‡ç½®clustering_paramsä¸ºé»˜è®¤å€¼
                st.session_state.clustering_params = {
                    "min_categories": 10,
                    "max_categories": 15,
                    "batch_size": 100,
                    "classification_batch_size": 20,
                }

            if st.session_state.use_custom_categories:
                get_custom_classification_parameters()
            else:
                get_clustering_parameters()

            if st.session_state.use_custom_categories:
                st.info("è¯·åœ¨ä¸‹æ–¹è®¾ç½®è‡ªå®šä¹‰ç±»åˆ«")
            else:
                if st.button("å¼€å§‹åˆå§‹èšç±»"):
                    with st.spinner("æ­£åœ¨è¿›è¡Œåˆå§‹èšç±»..."):
                        try:
                            result = asyncio.run(
                                generate_categories(
                                    df=df,
                                    text_column=st.session_state.text_column,
                                    text_topic=st.session_state.text_topic,
                                    initial_category_count=st.session_state.clustering_params[
                                        "max_categories"
                                    ],
                                    min_categories=st.session_state.clustering_params[
                                        "min_categories"
                                    ],
                                    max_categories=st.session_state.clustering_params[
                                        "max_categories"
                                    ],
                                    batch_size=st.session_state.clustering_params[
                                        "batch_size"
                                    ],
                                    session_id=st.session_state.session_id,
                                    additional_requirements=(
                                        f"è¡¥å……è¦æ±‚ï¼š\n{st.session_state.additional_requirements}"
                                        if st.session_state.additional_requirements
                                        and st.session_state.additional_requirements.strip()
                                        else ""
                                    ),
                                )
                            )

                            st.success("åˆå§‹èšç±»å®Œæˆï¼")

                            # ä¿å­˜ç»“æœåˆ° session state
                            st.session_state.df_preprocessed = result["preprocessed_df"]
                            st.session_state.categories = result["categories"][
                                "categories"
                            ]
                        except Exception as e:
                            st.error(f"åˆå§‹èšç±»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")

            st.session_state.df_preprocessed = df

        else:
            st.warning("è¯·ä¸Šä¼ CSVæ–‡ä»¶")


def handle_custom_categories():
    """å¤„ç†ç”¨æˆ·è‡ªå®šä¹‰ç±»åˆ«çš„è¾“å…¥"""
    if (
        st.session_state.use_custom_categories
        and st.session_state.df_preprocessed is not None
    ):
        st.markdown("## è‡ªå®šä¹‰ç±»åˆ«è¾“å…¥")
        with st.container(border=True):
            custom_category_method = st.radio(
                "é€‰æ‹©è‡ªå®šä¹‰ç±»åˆ«çš„æ–¹å¼",
                ["ä¸Šä¼ CSVæ–‡ä»¶", "æ‰‹åŠ¨è¾“å…¥"],
                format_func=lambda x: (
                    "ä¸Šä¼ CSVæ–‡ä»¶" if x == "ä¸Šä¼ CSVæ–‡ä»¶" else "æ‰‹åŠ¨è¾“å…¥"
                ),
            )

            if custom_category_method == "ä¸Šä¼ CSVæ–‡ä»¶":
                uploaded_categories = st.file_uploader(
                    "ä¸Šä¼ åŒ…å«è‡ªå®šä¹‰ç±»åˆ«çš„CSVæ–‡ä»¶", type="csv"
                )
                if uploaded_categories is not None:
                    categories_df = pd.read_csv(uploaded_categories)
                    st.session_state.categories = categories_df.to_dict("records")
                    st.success("è‡ªå®šä¹‰ç±»åˆ«å·²æˆåŠŸä¸Šä¼ ï¼")
            else:
                categories_text = st.text_area(
                    "è¯·è¾“å…¥è‡ªå®šä¹‰ç±»åˆ«ï¼ˆæ¯è¡Œä¸€ä¸ªç±»åˆ«ï¼Œæ ¼å¼ï¼šç±»åˆ«åç§°,ç±»åˆ«æè¿°ï¼‰",
                    height=200,
                    placeholder="å·¥ä½œç¯å¢ƒ,æè¿°å‘˜å·¥å¯¹å…¬å¸å·¥ä½œç¯å¢ƒçš„æ„Ÿå—ï¼ŒåŒ…æ‹¬èˆ’é€‚åº¦ã€è®¾å¤‡å’Œè½¯ä»¶çš„å…ˆè¿›æ€§ç­‰ã€‚\n"
                    "è–ªèµ„ä¸ç¦åˆ©,è®¨è®ºå‘˜å·¥å¯¹è–ªèµ„æ°´å¹³å’Œç¦åˆ©å¾…é‡çš„çœ‹æ³•ï¼ŒåŒ…æ‹¬ä¸è¡Œä¸šæ°´å¹³çš„æ¯”è¾ƒã€æå‡ç©ºé—´å’Œå¥åº·ä¿é™©ç­‰ã€‚",
                )
                if categories_text:
                    categories_list = [
                        line.split(",", 1)
                        for line in categories_text.split("\n")
                        if line.strip()
                    ]
                    categories_df = pd.DataFrame(
                        categories_list, columns=["name", "description"]
                    )
                    st.session_state.categories = categories_df.to_dict("records")
                    st.success("è‡ªå®šä¹‰ç±»åˆ«å·²æˆåŠŸæ·»åŠ ï¼")


def review_clustering_results():
    """å®¡æ ¸èšç±»ç»“æœå¹¶å…è®¸ç”¨æˆ·ä¿®æ”¹"""
    if st.session_state.categories is not None:
        st.markdown("---")
        st.markdown("## èšç±»ç»“æœå®¡æ ¸")

        with st.container(border=True):
            st.markdown("è¯·å®¡æ ¸å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹ã€æ·»åŠ æˆ–åˆ é™¤ç±»åˆ«ï¼š")

            # å°†ç±»åˆ«åˆ—è¡¨è½¬æ¢ä¸ºDataFrameä»¥ä¾¿ä½¿ç”¨st.data_editor
            categories_df = pd.DataFrame(st.session_state.categories)[
                ["name", "description"]
            ]

            # ä½¿ç”¨st.data_editoræ¥å±•ç¤ºå’Œç¼–è¾‘ç±»åˆ«
            edited_df = st.data_editor(
                categories_df,
                num_rows="dynamic",
                column_config={
                    "name": st.column_config.TextColumn(
                        "ç±»åˆ«åç§°",
                        help="ç®€æ´æ˜äº†çš„ç±»åˆ«æ ‡ç­¾",
                        max_chars=50,
                        required=True,
                    ),
                    "description": st.column_config.TextColumn(
                        "ç±»åˆ«æè¿°",
                        help="è¯¦ç»†æè¿°è¯¥ç±»åˆ«çš„ç‰¹å¾åŠä¸å…¶ä»–ç±»åˆ«çš„åŒºåˆ«",
                        max_chars=200,
                        required=True,
                    ),
                },
            )

            # å°†ç¼–è¾‘åçš„DataFrameè½¬æ¢å›ç±»åˆ«åˆ—è¡¨
            edited_categories = edited_df.to_dict("records")

            if st.button("ç¡®è®¤ç±»åˆ«å¹¶å¼€å§‹æ–‡æœ¬åˆ†ç±»"):
                if st.session_state.clustering_params is None:
                    st.error("è¯·å…ˆè®¾ç½®èšç±»å‚æ•°")
                else:
                    with st.spinner("æ­£åœ¨è¿›è¡Œæ–‡æœ¬åˆ†ç±»..."):
                        try:
                            df_result = asyncio.run(
                                classify_texts(
                                    df=st.session_state.df_preprocessed,
                                    text_column=st.session_state.text_column,
                                    id_column="unique_id",
                                    categories={"categories": edited_categories},
                                    text_topic=st.session_state.text_topic,
                                    session_id=st.session_state.session_id,
                                    classification_batch_size=st.session_state.clustering_params[
                                        "classification_batch_size"
                                    ],
                                )
                            )

                            st.session_state.df_result = df_result
                            st.success("æ–‡æœ¬åˆ†ç±»å®Œæˆï¼")
                        except Exception as e:
                            st.error(f"æ–‡æœ¬åˆ†ç±»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")


def display_classification_results():
    """å±•ç¤ºåˆ†ç±»ç»“æœ"""
    if st.session_state.df_result is not None:
        st.markdown("---")
        st.markdown("## åˆ†ç±»ç»“æœå±•ç¤º")

        with st.container(border=True):
            st.dataframe(st.session_state.df_result)

            # æä¾›ä¸‹è½½é€‰é¡¹
            csv = st.session_state.df_result.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="ä¸‹è½½åˆ†ç±»ç»“æœCSV",
                data=csv,
                file_name="classification_results.csv",
                mime="text/csv",
            )


def main():
    """ä¸»å‡½æ•°ï¼šæ§åˆ¶æ•´ä¸ªåº”ç”¨çš„æµç¨‹"""
    initialize_session_state()

    st.title("ğŸ”¬ æ–‡æœ¬èšç±»åˆ†æ")
    st.markdown("---")

    display_info_message()
    display_workflow_introduction()

    handle_data_input_and_clustering()
    handle_custom_categories()
    review_clustering_results()
    display_classification_results()

    show_footer()


main()
