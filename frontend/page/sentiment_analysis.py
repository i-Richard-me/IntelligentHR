import streamlit as st
import pandas as pd
import numpy as np
import sys
import os
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(project_root)

from frontend.ui_components import show_sidebar, show_footer, apply_common_styles
from backend.text_processing.classification.classification_workflow import (
    TextClassificationWorkflow,
)
from backend.text_processing.classification.classification_core import (
    ClassificationInput,
    ClassificationResult,
)

import uuid

st.query_params.role = st.session_state.role

# åº”ç”¨è‡ªå®šä¹‰æ ·å¼
apply_common_styles()

# æ˜¾ç¤ºä¾§è¾¹æ 
show_sidebar()

# åˆå§‹åŒ–æ–‡æœ¬åˆ†ç±»å·¥ä½œæµ
workflow = TextClassificationWorkflow()

# è®¾ç½®æ‰¹å¤„ç†å¤§å°
BATCH_SIZE = 5


# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
def initialize_session_state():
    """åˆå§‹åŒ– Streamlit ä¼šè¯çŠ¶æ€ï¼Œè®¾ç½®é»˜è®¤å€¼ã€‚"""
    default_states = {
        "classification_results": None,
        "df": None,
        "filtered_df": None,
        "context": "",
        "labels": [],
        "current_batch_index": 0,
        "progress": 0,
        "total_rows": 0,
        "is_processing": False,
        "session_id": str(uuid.uuid4()),
    }
    for key, value in default_states.items():
        if key not in st.session_state:
            st.session_state[key] = value


initialize_session_state()


def display_classification_result(result: ClassificationResult):
    """å°†åˆ†ç±»ç»“æœæ˜¾ç¤ºä¸ºè¡¨æ ¼"""
    df = pd.DataFrame(
        {
            "æœ‰æ•ˆæ€§": [result.validity],
            "æƒ…æ„Ÿå€¾å‘": [result.sentiment_class],
            "æ˜¯å¦åŒ…å«æ•æ„Ÿä¿¡æ¯": [result.sensitive_info],
        }
    )
    st.table(df)


def batch_classify(texts: List[str], context: str) -> List[Dict[str, Any]]:
    results = workflow.batch_classify(texts, context, st.session_state.session_id)
    return [result.dict() for result in results]


def display_info_message():
    """æ˜¾ç¤ºæ–‡æœ¬åˆ†ç±»ä¸æ ‡æ³¨å·¥å…·çš„ä¿¡æ¯æ¶ˆæ¯ã€‚"""
    st.info(
        """
    æƒ…æ„Ÿåˆ†æä¸æ–‡æœ¬æ ‡æ³¨åŠŸèƒ½ä½¿ç”¨å…ˆè¿›çš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿåˆ†æå’Œåˆ†ç±»å¤§é‡æ–‡æœ¬æ•°æ®ã€‚
    
    ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
    - æ–‡æœ¬æœ‰æ•ˆæ€§åˆ¤æ–­
    - æƒ…æ„Ÿå€¾å‘åˆ†æ
    - æ˜¯å¦æ•æ„Ÿä¿¡æ¯è¯†åˆ«
    
    é€šè¿‡äº¤äº’å¼ç•Œé¢ï¼Œç”¨æˆ·å¯ä»¥è½»æ¾ä¸Šä¼ æ•°æ®ã€æŸ¥çœ‹åˆ†ç±»ç»“æœï¼Œå¹¶ä¸‹è½½åˆ†ææŠ¥å‘Šã€‚
    è¿™ä¸ªå·¥å…·é€‚ç”¨äºå„ç§éœ€è¦å¿«é€Ÿç†è§£å’Œåˆ†ç±»å¤§é‡æ–‡æœ¬æ•°æ®çš„åœºæ™¯ï¼Œå¦‚å®¢æˆ·åé¦ˆåˆ†æã€ç¤¾äº¤åª’ä½“ç›‘æ§ç­‰ã€‚
    """
    )


def display_workflow():
    """æ˜¾ç¤ºæ–‡æœ¬åˆ†ç±»ä¸æ ‡æ³¨çš„å·¥ä½œæµç¨‹ã€‚"""
    with st.expander("ğŸ“‹ æŸ¥çœ‹æ–‡æœ¬åˆ†ç±»ä¸æ ‡æ³¨å·¥ä½œæµç¨‹", expanded=False):

        with st.container(border=True):
            st.markdown(
                """
            1. **æ•°æ®å‡†å¤‡**: 
               - è¾“å…¥å•æ¡æ–‡æœ¬æˆ–ä¸Šä¼ CSVæ–‡ä»¶
               - æŒ‡å®šæ–‡æœ¬çš„ä¸Šä¸‹æ–‡æˆ–ä¸»é¢˜
               - å®šä¹‰åˆ†ç±»æ ‡ç­¾åˆ—è¡¨
            
            2. **æ–‡æœ¬åˆ†ç±»**:
               - ç³»ç»Ÿè‡ªåŠ¨åˆ¤æ–­æ–‡æœ¬æœ‰æ•ˆæ€§
               - åˆ†ææ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘
               - è¯†åˆ«å¯èƒ½çš„æ•æ„Ÿä¿¡æ¯
            
            3. **ç»“æœå±•ç¤º**:
               - æ˜¾ç¤ºæ¯æ¡æ–‡æœ¬çš„åˆ†ç±»ç»“æœ
               - å¯¹äºæ‰¹é‡å¤„ç†ï¼Œä»¥è¡¨æ ¼å½¢å¼å±•ç¤ºæ‰€æœ‰ç»“æœ
            
            4. **ç»“æœå¯¼å‡º**:
               - æä¾›åˆ†ç±»ç»“æœçš„CSVä¸‹è½½é€‰é¡¹
               - ä¾¿äºè¿›ä¸€æ­¥åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ
            
            5. **è¿­ä»£ä¼˜åŒ–**:
               - æ ¹æ®åˆ†ç±»ç»“æœè°ƒæ•´ä¸Šä¸‹æ–‡æˆ–æ ‡ç­¾
               - é‡æ–°è¿è¡Œåˆ†ç±»ä»¥æé«˜å‡†ç¡®æ€§
            """
            )


def main():
    st.title("ğŸ·ï¸ æ–‡æœ¬åˆ†ç±»ä¸æ ‡æ³¨")
    st.markdown("---")

    display_info_message()
    display_workflow()

    st.markdown("## æ–‡æœ¬åˆ†ç±»")
    with st.container(border=True):
        st.session_state.context = st.text_input(
            "è¯·è¾“å…¥æ–‡æœ¬ä¸Šä¸‹æ–‡æˆ–ä¸»é¢˜",
            value=st.session_state.context,
            placeholder="ä¾‹å¦‚ï¼šå‘˜å·¥è°ƒç ”",
        )

        tab1, tab2 = st.tabs(["ç›´æ¥è¾“å…¥", "ä¸Šä¼ CSVæ–‡ä»¶"])

        with tab1:
            with st.form("single_classification_form", border=False):
                text_to_classify = st.text_area("è¯·è¾“å…¥è¦åˆ†ç±»çš„æ–‡æœ¬", height=150)
                submit_button = st.form_submit_button("åˆ†ç±»")

                if submit_button:
                    if text_to_classify and st.session_state.context:
                        st.session_state.session_id = str(
                            uuid.uuid4()
                        )  # ä¸ºå•ä¸ªåˆ†ç±»ä»»åŠ¡ç”Ÿæˆæ–°çš„session_id
                        with st.spinner("æ­£åœ¨åˆ†ç±»..."):
                            input_data = ClassificationInput(
                                text=text_to_classify,
                                context=st.session_state.context,
                            )
                            result = workflow.classify_text(
                                input_data, st.session_state.session_id
                            )
                        st.session_state.classification_results = result
                    else:
                        st.warning("è¯·è¾“å…¥æ–‡æœ¬ã€ä¸Šä¸‹æ–‡å’Œæ ‡ç­¾")

        with tab2:
            uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type="csv")
            if uploaded_file is not None:
                try:
                    st.session_state.df = pd.read_csv(uploaded_file)
                    st.write("é¢„è§ˆä¸Šä¼ çš„æ•°æ®ï¼š")
                    st.dataframe(st.session_state.df.head())

                    text_column = st.selectbox(
                        "é€‰æ‹©åŒ…å«è¦åˆ†ç±»æ–‡æœ¬çš„åˆ—", st.session_state.df.columns
                    )

                    if st.button("å¼€å§‹æ‰¹é‡åˆ†ç±»"):
                        if st.session_state.context:
                            st.session_state.session_id = str(
                                uuid.uuid4()
                            )  # ä¸ºæ•´ä¸ªæ‰¹é‡ä»»åŠ¡ç”Ÿæˆæ–°çš„session_id
                            st.session_state.filtered_df = st.session_state.df[
                                [text_column]
                            ].copy()
                            st.session_state.current_batch_index = 0
                            st.session_state.total_rows = len(
                                st.session_state.filtered_df
                            )
                            st.session_state.progress = 0
                            st.session_state.is_processing = True
                            st.rerun()
                        else:
                            st.warning("è¯·è¾“å…¥ä¸Šä¸‹æ–‡")

                except Exception as e:
                    st.error(f"å¤„ç†CSVæ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}")

    if st.session_state.is_processing:
        st.markdown("## æ‰¹é‡åˆ†ç±»è¿›åº¦")
        with st.container(border=True):
            total_rows = st.session_state.total_rows
            start_index = st.session_state.current_batch_index * BATCH_SIZE
            end_index = min(start_index + BATCH_SIZE, total_rows)

            progress_text = (
                f"æ­£åœ¨å¤„ç† {start_index + 1} åˆ° {end_index} è¡Œï¼Œå…± {total_rows} è¡Œ"
            )
            my_bar = st.progress(st.session_state.progress, text=progress_text)

            current_batch = st.session_state.filtered_df.iloc[start_index:end_index]
            texts_to_classify = current_batch[text_column].tolist()

            with st.spinner("æ­£åœ¨æ‰¹é‡åˆ†ç±»..."):
                results = batch_classify(texts_to_classify, st.session_state.context)

            for i, result in enumerate(results):
                st.session_state.filtered_df.loc[start_index + i, "æœ‰æ•ˆæ€§"] = result[
                    "validity"
                ]
                st.session_state.filtered_df.loc[start_index + i, "æƒ…æ„Ÿå€¾å‘"] = result[
                    "sentiment_class"
                ]
                st.session_state.filtered_df.loc[
                    start_index + i, "æ˜¯å¦åŒ…å«æ•æ„Ÿä¿¡æ¯"
                ] = result["sensitive_info"]

            st.session_state.progress = end_index / total_rows
            my_bar.progress(st.session_state.progress, text=progress_text)

            if end_index < total_rows:
                st.session_state.current_batch_index += 1
                st.rerun()
            else:
                st.success("æ‰¹é‡åˆ†ç±»å®Œæˆï¼")
                st.session_state.classification_results = st.session_state.filtered_df
                st.session_state.is_processing = False

    # æ˜¾ç¤ºåˆ†ç±»ç»“æœ
    if st.session_state.classification_results is not None:
        st.markdown("## åˆ†ç±»ç»“æœ")
        with st.container(border=True):
            if isinstance(
                st.session_state.classification_results, ClassificationResult
            ):
                # å•ä¸ªæ–‡æœ¬åˆ†ç±»ç»“æœ
                display_classification_result(st.session_state.classification_results)
            elif isinstance(st.session_state.classification_results, pd.DataFrame):
                # æ‰¹é‡åˆ†ç±»ç»“æœ
                st.dataframe(st.session_state.classification_results)

                # æä¾›ä¸‹è½½é€‰é¡¹
                csv = st.session_state.classification_results.to_csv(
                    index=False
                ).encode("utf-8-sig")
                st.download_button(
                    label="ä¸‹è½½åˆ†ç±»ç»“æœCSV",
                    data=csv,
                    file_name="classification_results.csv",
                    mime="text/csv",
                )

    # é¡µè„š
    show_footer()


main()
