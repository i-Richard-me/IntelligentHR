import streamlit as st
import pandas as pd
import numpy as np
import sys
import os
from typing import List, Dict, Any
import asyncio

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(project_root)

from frontend.ui_components import show_sidebar, show_footer, apply_common_styles
from backend.text_processing.classification.classification_workflow import (
    TextClassificationWorkflow,
)
from backend.text_processing.classification.classification_core import (
    ClassificationInput,
    ClassificationResult,
)

import uuid

st.query_params.role = st.session_state.role

# åº”ç”¨è‡ªå®šä¹‰æ ·å¼
apply_common_styles()

# æ˜¾ç¤ºä¾§è¾¹æ 
show_sidebar()

# åˆå§‹åŒ–æ–‡æœ¬åˆ†ç±»å·¥ä½œæµ
workflow = TextClassificationWorkflow()


# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
def initialize_session_state():
    """åˆå§‹åŒ– Streamlit ä¼šè¯çŠ¶æ€ï¼Œè®¾ç½®é»˜è®¤å€¼ã€‚"""
    default_states = {
        "classification_results": None,
        "df": None,
        "filtered_df": None,
        "context": "",
        "session_id": str(uuid.uuid4()),
        "is_processing": False,
    }
    for key, value in default_states.items():
        if key not in st.session_state:
            st.session_state[key] = value


initialize_session_state()


def display_classification_result(result: ClassificationResult):
    """å°†åˆ†æç»“æœæ˜¾ç¤ºä¸ºè¡¨æ ¼"""
    df = pd.DataFrame(
        {
            "æœ‰æ•ˆæ€§": [result.validity],
            "æƒ…æ„Ÿå€¾å‘": [result.sentiment_class],
            "æ˜¯å¦åŒ…å«æ•æ„Ÿä¿¡æ¯": [result.sensitive_info],
        }
    )
    st.table(df)


async def batch_classify(texts: List[str], context: str, progress_bar, status_area):
    total_texts = len(texts)
    results = []
    for i, text in enumerate(texts):
        result = await workflow.async_classify_text(
            ClassificationInput(text=text, context=context), st.session_state.session_id
        )
        results.append(result.dict())

        # æ›´æ–°è¿›åº¦æ¡å’ŒçŠ¶æ€ä¿¡æ¯
        progress = (i + 1) / total_texts
        progress_bar.progress(progress)
        status_message = f"å·²å¤„ç†: {i + 1}/{total_texts}"
        status_area.info(status_message)

        # æ·»åŠ å°å»¶è¿Ÿä»¥å…è®¸UIæ›´æ–°
        await asyncio.sleep(0.05)

    return results


def display_info_message():
    """æ˜¾ç¤ºæƒ…æ„Ÿåˆ†æä¸æ ‡æ³¨å·¥å…·çš„ä¿¡æ¯æ¶ˆæ¯ã€‚"""
    st.info(
        """
    æƒ…æ„Ÿåˆ†æä¸æ ‡æ³¨åŠŸèƒ½ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹å¤„ç†æŠ€æœ¯ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿåˆ†æå’Œåˆ†ç±»å¤§é‡æ–‡æœ¬æ•°æ®ã€‚
    
    ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
    - æ–‡æœ¬æœ‰æ•ˆæ€§åˆ¤æ–­
    - æƒ…æ„Ÿå€¾å‘åˆ†æ
    - æ˜¯å¦æ•æ„Ÿä¿¡æ¯è¯†åˆ«
    
    é€‚ç”¨äºå„ç±»éœ€è¦å¿«é€Ÿç†è§£å’Œåˆ†ç±»å¤§é‡æ–‡æœ¬æ•°æ®çš„åœºæ™¯ï¼Œå¦‚å®¢æˆ·åé¦ˆåˆ†æã€ç¤¾äº¤åª’ä½“ç›‘æ§ç­‰ã€‚
    """
    )


def display_workflow():
    """æ˜¾ç¤ºæƒ…æ„Ÿåˆ†æä¸æ ‡æ³¨çš„å·¥ä½œæµç¨‹ã€‚"""
    with st.expander("ğŸ“‹ æŸ¥çœ‹æƒ…æ„Ÿåˆ†æä¸æ ‡æ³¨å·¥ä½œæµç¨‹", expanded=False):

        with st.container(border=True):
            st.markdown(
                """
            1. **æ•°æ®å‡†å¤‡**: 
               - è¾“å…¥å•æ¡æ–‡æœ¬æˆ–ä¸Šä¼ CSVæ–‡ä»¶
               - æŒ‡å®šæ–‡æœ¬çš„ä¸Šä¸‹æ–‡æˆ–ä¸»é¢˜
               - å®šä¹‰åˆ†ç±»æ ‡ç­¾åˆ—è¡¨
            
            2. **æ–‡æœ¬åˆ†ç±»**:
               - ç³»ç»Ÿè‡ªåŠ¨åˆ¤æ–­æ–‡æœ¬æœ‰æ•ˆæ€§
               - åˆ†ç±»æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘
               - è¯†åˆ«å¯èƒ½çš„æ•æ„Ÿä¿¡æ¯
            
            3. **ç»“æœå±•ç¤º**:
               - æ˜¾ç¤ºæ¯æ¡æ–‡æœ¬çš„åˆ†ç±»ç»“æœ
               - å¯¹äºæ‰¹é‡å¤„ç†ï¼Œä»¥è¡¨æ ¼å½¢å¼å±•ç¤ºæ‰€æœ‰ç»“æœ
            
            4. **ç»“æœå¯¼å‡º**:
               - æä¾›åˆ†ç±»ç»“æœçš„CSVä¸‹è½½é€‰é¡¹
               - ä¾¿äºè¿›ä¸€æ­¥åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ
            
            5. **è¿­ä»£ä¼˜åŒ–**:
               - æ ¹æ®åˆ†ç±»ç»“æœè°ƒæ•´ä¸Šä¸‹æ–‡æˆ–æ ‡ç­¾
               - é‡æ–°è¿è¡Œåˆ†ç±»ä»¥æé«˜å‡†ç¡®æ€§
            """
            )


def main():
    st.title("ğŸ·ï¸ æƒ…æ„Ÿåˆ†æä¸æ ‡æ³¨")
    st.markdown("---")

    display_info_message()
    display_workflow()

    st.markdown("## æƒ…æ„Ÿåˆ†æä¸æ ‡æ³¨")
    with st.container(border=True):
        st.session_state.context = st.text_input(
            "è¯·è¾“å…¥æ–‡æœ¬ä¸Šä¸‹æ–‡æˆ–ä¸»é¢˜",
            value=st.session_state.context,
            placeholder="ä¾‹å¦‚ï¼šå‘˜å·¥è°ƒç ”",
        )

        tab1, tab2 = st.tabs(["ç›´æ¥è¾“å…¥", "ä¸Šä¼ CSVæ–‡ä»¶"])

        with tab1:
            with st.form("single_classification_form", border=False):
                text_to_classify = st.text_area("è¯·è¾“å…¥è¦åˆ†æçš„æ–‡æœ¬", height=150)
                submit_button = st.form_submit_button("åˆ†æ")

                if submit_button:
                    if text_to_classify and st.session_state.context:
                        st.session_state.session_id = str(
                            uuid.uuid4()
                        )  # ä¸ºå•ä¸ªåˆ†ç±»ä»»åŠ¡ç”Ÿæˆæ–°çš„session_id
                        with st.spinner("æ­£åœ¨åˆ†æ..."):
                            input_data = ClassificationInput(
                                text=text_to_classify,
                                context=st.session_state.context,
                            )
                            result = workflow.classify_text(
                                input_data, st.session_state.session_id
                            )
                        st.session_state.classification_results = result
                    else:
                        st.warning("è¯·è¾“å…¥æ–‡æœ¬å’Œä¸Šä¸‹æ–‡")

        with tab2:
            uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ–‡ä»¶", type="csv")
            if uploaded_file is not None:
                try:
                    st.session_state.df = pd.read_csv(uploaded_file)
                    st.write("é¢„è§ˆä¸Šä¼ çš„æ•°æ®ï¼š")
                    st.dataframe(st.session_state.df.head())

                    text_column = st.selectbox(
                        "é€‰æ‹©åŒ…å«è¦åˆ†ææ–‡æœ¬çš„åˆ—", st.session_state.df.columns
                    )

                    if st.button("å¼€å§‹æ‰¹é‡åˆ†æ"):
                        if st.session_state.context:
                            st.session_state.session_id = str(
                                uuid.uuid4()
                            )  # ä¸ºæ•´ä¸ªæ‰¹é‡ä»»åŠ¡ç”Ÿæˆæ–°çš„session_id
                            st.session_state.filtered_df = st.session_state.df[
                                [text_column]
                            ].copy()
                            st.session_state.current_batch_index = 0
                            st.session_state.total_rows = len(
                                st.session_state.filtered_df
                            )
                            st.session_state.progress = 0
                            st.session_state.is_processing = True
                        else:
                            st.warning("è¯·è¾“å…¥ä¸Šä¸‹æ–‡")

                except Exception as e:
                    st.error(f"å¤„ç†CSVæ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}")

    if st.session_state.is_processing:
        st.markdown("## æ‰¹é‡åˆ†æè¿›åº¦")
        with st.container(border=True):
            total_rows = len(st.session_state.filtered_df)

            progress_bar = st.progress(0)
            status_area = st.empty()

            texts_to_classify = st.session_state.filtered_df[text_column].tolist()

            with st.spinner("æ­£åœ¨æ‰¹é‡åˆ†æ..."):
                results = asyncio.run(
                    batch_classify(
                        texts_to_classify,
                        st.session_state.context,
                        progress_bar,
                        status_area,
                    )
                )

            for i, result in enumerate(results):
                st.session_state.filtered_df.loc[i, "æœ‰æ•ˆæ€§"] = result["validity"]
                st.session_state.filtered_df.loc[i, "æƒ…æ„Ÿå€¾å‘"] = result[
                    "sentiment_class"
                ]
                st.session_state.filtered_df.loc[i, "æ˜¯å¦åŒ…å«æ•æ„Ÿä¿¡æ¯"] = result[
                    "sensitive_info"
                ]

            st.success("æ‰¹é‡åˆ†æå®Œæˆï¼")
            st.session_state.classification_results = st.session_state.filtered_df
            st.session_state.is_processing = False

    # æ˜¾ç¤ºåˆ†ç±»ç»“æœ
    if st.session_state.classification_results is not None:
        st.markdown("## åˆ†æç»“æœ")
        with st.container(border=True):
            if isinstance(
                st.session_state.classification_results, ClassificationResult
            ):
                # å•ä¸ªæ–‡æœ¬åˆ†ç±»ç»“æœ
                display_classification_result(st.session_state.classification_results)
            elif isinstance(st.session_state.classification_results, pd.DataFrame):
                # æ‰¹é‡åˆ†ç±»ç»“æœ
                st.dataframe(st.session_state.classification_results)

                # æä¾›ä¸‹è½½é€‰é¡¹
                csv = st.session_state.classification_results.to_csv(
                    index=False
                ).encode("utf-8-sig")
                st.download_button(
                    label="ä¸‹è½½åˆ†æç»“æœCSV",
                    data=csv,
                    file_name="sentiment_analysis_results.csv",
                    mime="text/csv",
                )

    # é¡µè„š
    show_footer()


main()
