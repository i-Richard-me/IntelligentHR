"""
ç®€å†è§£ææ¨¡å—

æœ¬æ¨¡å—åŒ…å«äº†ç®€å†è§£æçš„ä¸»è¦æµç¨‹å’Œ Streamlit å‰ç«¯ç•Œé¢ã€‚
å®ƒè´Ÿè´£å¤„ç†æ–‡ä»¶ä¸Šä¼ ã€URL è¾“å…¥ã€æ‰¹é‡å¤„ç†ç­‰åŠŸèƒ½ï¼Œå¹¶å±•ç¤ºè§£æç»“æœã€‚
"""

import sys
import os
import asyncio
from typing import List, Dict, Any
import uuid
import json

import streamlit as st
import pdfplumber
import pandas as pd
import aiohttp
from bs4 import BeautifulSoup
from mysql.connector import Error as MySQLError

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(project_root)

from frontend.ui_components import show_sidebar, show_footer, apply_common_styles
from backend.resume_management.extractor.resume_extraction_core import (
    process_resume,
    calculate_resume_hash,
    store_resume,
)
from backend.resume_management.storage.resume_sql_storage import get_full_resume

# å¸¸é‡å®šä¹‰
MAX_CONCURRENT_TASKS = 1

st.query_params.role = st.session_state.role

# åº”ç”¨è‡ªå®šä¹‰æ ·å¼
apply_common_styles()

# æ˜¾ç¤ºä¾§è¾¹æ 
show_sidebar()

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "resume_data" not in st.session_state:
    st.session_state.resume_data = None
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())
if "is_from_database" not in st.session_state:
    st.session_state.is_from_database = False


def clean_html(html_content: str) -> str:
    """
    æ¸…ç† HTML å†…å®¹ï¼Œç§»é™¤è„šæœ¬å’Œæ ·å¼ã€‚

    Args:
        html_content (str): åŸå§‹ HTML å†…å®¹ã€‚

    Returns:
        str: æ¸…ç†åçš„ HTML å†…å®¹ã€‚
    """
    soup = BeautifulSoup(html_content, "html.parser")
    for script in soup(["script", "style"]):
        script.decompose()
    return str(soup)


def extract_text_from_pdf(pdf_file) -> str:
    """
    ä» PDF æ–‡ä»¶ä¸­æå–æ–‡æœ¬ã€‚

    Args:
        pdf_file: PDF æ–‡ä»¶å¯¹è±¡ã€‚

    Returns:
        str: æå–çš„æ–‡æœ¬å†…å®¹ã€‚
    """
    text = ""
    with pdfplumber.open(pdf_file) as pdf:
        for page in pdf.pages:
            text += page.extract_text() or ""
    return text


async def extract_text_from_url(url: str, session: aiohttp.ClientSession) -> str:
    """
    ä» URL ä¸­å¼‚æ­¥æå–æ–‡æœ¬ã€‚

    Args:
        url (str): ç›®æ ‡ URLã€‚
        session (aiohttp.ClientSession): aiohttp ä¼šè¯å¯¹è±¡ã€‚

    Returns:
        str: æå–çš„æ–‡æœ¬å†…å®¹ã€‚

    Raises:
        Exception: å¦‚æœæ— æ³•ä» URL æå–å†…å®¹ã€‚
    """
    jina_url = f"https://r.jina.ai/{url}"
    async with session.get(jina_url, ssl=False) as response:
        if response.status == 200:
            return await response.text()
        else:
            raise Exception(f"æ— æ³•ä»URLæå–å†…å®¹: {url}")


async def extract_resume_info(
    file_content: str, resume_id: str, file_type: str, session_id: str, file_or_url: str
) -> Dict[str, Any]:
    """
    æå–ç®€å†ä¿¡æ¯ã€‚

    Args:
        file_content (str): æ–‡ä»¶å†…å®¹ã€‚
        resume_id (str): ç®€å† IDã€‚
        file_type (str): æ–‡ä»¶ç±»å‹ã€‚
        session_id (str): ä¼šè¯ IDã€‚
        file_or_url (str): æ–‡ä»¶è·¯å¾„æˆ– URLã€‚

    Returns:
        Dict[str, Any]: æå–çš„ç®€å†ä¿¡æ¯ã€‚
    """
    if file_type == "html":
        content = clean_html(file_content)
    elif file_type == "pdf":
        content = extract_text_from_pdf(file_content)
    elif file_type == "url":
        content = file_content
    else:
        raise ValueError("ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹")

    return await process_resume(content, resume_id, session_id, file_type, file_or_url)


async def process_single_resume(
    url: str,
    session_id: str,
    semaphore: asyncio.Semaphore,
    session: aiohttp.ClientSession,
) -> None:
    """
    å¤„ç†å•ä¸ªç®€å† URLã€‚

    Args:
        url (str): ç®€å† URLã€‚
        session_id (str): ä¼šè¯ IDã€‚
        semaphore (asyncio.Semaphore): ç”¨äºæ§åˆ¶å¹¶å‘çš„ä¿¡å·é‡ã€‚
        session (aiohttp.ClientSession): aiohttp ä¼šè¯å¯¹è±¡ã€‚
    """
    async with semaphore:
        try:
            resume_content = await extract_text_from_url(url, session)
            resume_id = calculate_resume_hash(resume_content)
            existing_resume = get_full_resume(resume_id)

            if existing_resume:
                st.warning(f"URL {url} çš„ç®€å†å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†ã€‚")
            else:
                resume_data = await process_resume(
                    resume_content, resume_id, session_id, "url", url
                )
                resume_data["resume_format"] = "url"
                resume_data["file_or_url"] = url
                try:
                    store_resume(resume_data)
                    st.success(f"æˆåŠŸå¤„ç† URL: {url}")
                except MySQLError as e:
                    st.error(f"å­˜å‚¨ç®€å†æ•°æ®å¤±è´¥: {url}. é”™è¯¯: {str(e)}")
        except Exception as e:
            st.error(f"å¤„ç† URL {url} æ—¶å‡ºé”™: {str(e)}")


async def process_batch_resumes(urls: List[str], session_id: str) -> None:
    """
    å¼‚æ­¥å¤„ç†æ‰¹é‡ç®€å†ï¼Œæ§åˆ¶å¹¶å‘æ•°ã€‚

    Args:
        urls (List[str]): ç®€å† URL åˆ—è¡¨ã€‚
        session_id (str): ä¼šè¯ IDã€‚
    """
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_TASKS)
    async with aiohttp.ClientSession() as session:
        tasks = [
            process_single_resume(url, session_id, semaphore, session) for url in urls
        ]
        await asyncio.gather(*tasks)


def display_info_message():
    """æ˜¾ç¤ºæ™ºèƒ½ç®€å†è§£æç³»ç»Ÿçš„åŠŸèƒ½ä»‹ç»ã€‚"""
    st.info(
        """
        æ™ºèƒ½ç®€å†è§£æç³»ç»Ÿåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼Œå®ç°å¯¹å¤šç§æ ¼å¼ç®€å†çš„é«˜æ•ˆè§£æã€‚
        
        ç³»ç»Ÿèƒ½è‡ªåŠ¨æå–å’Œç»“æ„åŒ–å…³é”®ä¿¡æ¯ï¼Œæœ‰æ•ˆå¤„ç†éæ ‡å‡†åŒ–è¡¨è¿°ï¼Œæé«˜è§£æå‡†ç¡®ç‡ã€‚
        ä¹Ÿä¸ºåç»­çš„ç®€å†æ¨èå’Œäººæ‰ç”»åƒç­‰åº”ç”¨æä¾›äº†æ›´å¯é çš„æ•°æ®åŸºç¡€ã€‚
        """
    )


def display_workflow():
    """æ˜¾ç¤ºæ™ºèƒ½ç®€å†è§£æç³»ç»Ÿçš„å·¥ä½œæµç¨‹ã€‚"""
    with st.expander("ğŸ“„ æŸ¥çœ‹æ™ºèƒ½ç®€å†è§£æå·¥ä½œæµç¨‹", expanded=False):
        col1, col2 = st.columns([1, 1])
        with col2:
            st.markdown(
                """
                <div class="workflow-container">
                    <div class="workflow-step">
                        <strong>1. æ–‡ä»¶å¤„ç†ä¸å†…å®¹æå–</strong>
                        - æ”¯æŒHTMLå’ŒPDFæ ¼å¼çš„ç®€å†æ–‡ä»¶
                    </div>
                    <div class="workflow-step">
                        <strong>2. ä¿¡æ¯è§£æä¸ç»“æ„åŒ–</strong>
                        - åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è§£æç®€å†å†…å®¹
                        - æå–ä¸ªäººä¿¡æ¯ã€æ•™è‚²èƒŒæ™¯ã€å·¥ä½œç»å†ç­‰å…³é”®ä¿¡æ¯
                    </div>
                    <div class="workflow-step">
                        <strong>3. ç®€å†æ¦‚è¿°ç”Ÿæˆ</strong>
                        - åŸºäºæå–çš„ä¿¡æ¯è‡ªåŠ¨ç”Ÿæˆç®€å†æ¦‚è¿°
                        - åŒ…æ‹¬å‘˜å·¥ç‰¹ç‚¹ã€å·¥ä½œå’Œé¡¹ç›®ç»å†ã€æŠ€èƒ½æ¦‚è§ˆç­‰
                    </div>
                    <div class="workflow-step">
                        <strong>4. ç»“æœå±•ç¤º</strong>
                        - ä»¥ç”¨æˆ·å‹å¥½çš„æ–¹å¼å¯è§†åŒ–å±•ç¤ºè§£æç»“æœ
                    </div>
                    <div class="workflow-step">
                        <strong>5. æ•°æ®å­˜å‚¨ï¼ˆå¯é€‰ï¼‰</strong>
                        - å°†è§£æåçš„æ•°æ®å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ä¸­
                        - ä¸ºåç»­çš„æ£€ç´¢å’Œåˆ†ææä¾›åŸºç¡€
                    </div>
                </div>
                """,
                unsafe_allow_html=True,
            )


def main():
    """ä¸»å‡½æ•°ï¼ŒåŒ…å« Streamlit åº”ç”¨çš„ä¸»è¦é€»è¾‘ã€‚"""
    st.title("ğŸ“„ æ™ºèƒ½ç®€å†è§£æ")
    st.markdown("---")

    display_info_message()
    display_workflow()

    st.markdown("## ç®€å†æå–")

    tab1, tab2 = st.tabs(["å•ä»½ç®€å†", "æ‰¹é‡è§£æ"])

    with tab1:
        handle_single_resume()

    with tab2:
        handle_batch_resumes()

    if st.session_state.resume_data is not None:
        display_resume_results()

    # é¡µè„š
    show_footer()


# æ¥ç»­ä¸Šä¸€éƒ¨åˆ†çš„ä»£ç 


async def handle_resume_processing(
    resume_id: str, file_type: str, file_content: str, file_or_url: str
) -> None:
    """
    å¤„ç†ç®€å†æå–å’Œå­˜å‚¨é€»è¾‘ã€‚

    Args:
        resume_id (str): ç®€å† IDã€‚
        file_type (str): æ–‡ä»¶ç±»å‹ã€‚
        file_content (str): æ–‡ä»¶å†…å®¹ã€‚
        file_or_url (str): æ–‡ä»¶è·¯å¾„æˆ– URLã€‚
    """
    existing_resume = get_full_resume(resume_id)
    if existing_resume:
        st.warning("æ£€æµ‹åˆ°é‡å¤çš„ç®€å†ã€‚æ­£åœ¨ä»æ•°æ®åº“ä¸­è·å–å·²è§£æçš„ä¿¡æ¯ã€‚")
        st.session_state.resume_data = existing_resume
        st.session_state.is_from_database = True
    else:
        st.session_state.is_from_database = False
        if st.button("æå–ä¿¡æ¯", key=file_type):
            with st.spinner("æ­£åœ¨æå–ç®€å†ä¿¡æ¯..."):
                try:
                    resume_data = await extract_resume_info(
                        file_content,
                        resume_id,
                        file_type,
                        st.session_state.session_id,
                        file_or_url,
                    )
                    resume_data["resume_format"] = file_type
                    resume_data["file_or_url"] = file_or_url
                    st.session_state.resume_data = resume_data
                    st.success("ç®€å†ä¿¡æ¯æå–æˆåŠŸï¼")
                except Exception as e:
                    st.error(f"æå–ç®€å†ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")


def handle_single_resume():
    """å¤„ç†å•ä»½ç®€å†ä¸Šä¼ å’Œ URL è¾“å…¥ã€‚"""
    with st.container(border=True):
        uploaded_file = st.file_uploader("ä¸Šä¼ ç®€å†æ–‡ä»¶", type=["html", "pdf"])
        url_input = st.text_input("æˆ–è¾“å…¥ç®€å† URL")

        if uploaded_file is not None:
            process_uploaded_file(uploaded_file)
        elif url_input:
            asyncio.run(process_url_input(url_input))


async def process_url_input(url_input: str):
    """
    å¤„ç†è¾“å…¥çš„ URLã€‚

    Args:
        url_input (str): è¾“å…¥çš„ URLã€‚
    """
    async with aiohttp.ClientSession() as session:
        try:
            file_content = await extract_text_from_url(url_input, session)
            resume_id = calculate_resume_hash(file_content)
            await handle_resume_processing(resume_id, "url", file_content, url_input)
        except Exception as e:
            st.error(f"å¤„ç† URL æ—¶å‡ºé”™: {str(e)}")


def process_uploaded_file(uploaded_file):
    """
    å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶ã€‚

    Args:
        uploaded_file: ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡ã€‚
    """
    file_type = uploaded_file.type.split("/")[-1]
    file_content = uploaded_file.read()
    resume_id = calculate_resume_hash(file_content.decode("utf-8", errors="ignore"))
    asyncio.run(
        handle_resume_processing(resume_id, file_type, file_content, uploaded_file.name)
    )


def handle_batch_resumes():
    """å¤„ç†æ‰¹é‡ç®€å†ä¸Šä¼ ã€‚"""
    with st.container(border=True):
        batch_file = st.file_uploader("ä¸Šä¼ åŒ…å« URL çš„è¡¨æ ¼æ–‡ä»¶", type=["csv", "xlsx"])
        if batch_file is not None:
            if st.button("å¼€å§‹æ‰¹é‡å¤„ç†"):
                df = (
                    pd.read_csv(batch_file)
                    if batch_file.name.endswith(".csv")
                    else pd.read_excel(batch_file)
                )
                urls = df["URL"].tolist()

                progress_bar = st.progress(0)
                status_text = st.empty()
                result_area = st.empty()

                async def process_with_progress():
                    total = len(urls)
                    completed = 0
                    results = []
                    semaphore = asyncio.Semaphore(MAX_CONCURRENT_TASKS)
                    async with aiohttp.ClientSession() as session:
                        tasks = [
                            process_single_resume(
                                url, st.session_state.session_id, semaphore, session
                            )
                            for url in urls
                        ]
                        for task in asyncio.as_completed(tasks):
                            result = await task
                            results.append(result)
                            completed += 1
                            progress = completed / total
                            progress_bar.progress(progress)
                            status_text.text(f"å·²å¤„ç† {completed}/{total} ä¸ª URL")

                asyncio.run(process_with_progress())

                st.success(f"å·²å¤„ç† {len(urls)} ä¸ª URL çš„ç®€å†ã€‚")


def display_resume_results():
    """æ˜¾ç¤ºç®€å†è§£æç»“æœå’Œç›¸å…³æ“ä½œã€‚"""
    st.markdown("---")

    display_resume_info(st.session_state.resume_data)

    # æä¾›ä¸‹è½½é€‰é¡¹
    json_string = json.dumps(st.session_state.resume_data, ensure_ascii=False, indent=2)
    st.download_button(
        label="ä¸‹è½½ JSON ç»“æœ",
        data=json_string,
        file_name="resume_extracted_info.json",
        mime="application/json",
    )

    # åªæœ‰å½“ç®€å†ä¸æ˜¯ä»æ•°æ®åº“ä¸­æ£€ç´¢çš„æ—¶å€™ï¼Œæ‰æ˜¾ç¤º"å­˜å‚¨ç®€å†åˆ°æ•°æ®åº“"æŒ‰é’®
    if not st.session_state.is_from_database:
        if st.button("å­˜å‚¨ç®€å†åˆ°æ•°æ®åº“"):
            with st.spinner("æ­£åœ¨å­˜å‚¨ç®€å†æ•°æ®..."):
                try:
                    store_resume(st.session_state.resume_data)
                    st.success("ç®€å†æ•°æ®å·²æˆåŠŸå­˜å‚¨åˆ°æ•°æ®åº“")
                except MySQLError as e:
                    st.error(f"å­˜å‚¨ç®€å†æ•°æ®æ—¶å‡ºé”™: {str(e)}")


def display_resume_info(resume_data: Dict[str, Any]):
    """
    æ˜¾ç¤ºæå–çš„ç®€å†ä¿¡æ¯ã€‚

    Args:
        resume_data (Dict[str, Any]): æå–çš„ç®€å†æ•°æ®ã€‚
    """
    if not resume_data:
        return

    st.markdown("## æå–çš„ç®€å†ä¿¡æ¯")

    with st.container(border=True):
        display_resume_summary(resume_data)
        display_personal_info(resume_data.get("personal_info", {}))
        display_education(resume_data.get("education", []))
        display_work_experience(resume_data.get("work_experiences", []))
        display_project_experience(resume_data.get("project_experiences", []))


def display_resume_summary(resume_data: Dict[str, Any]):
    """
    æ˜¾ç¤ºç®€å†æ¦‚è¿°ã€‚

    Args:
        resume_data (Dict[str, Any]): ç®€å†æ•°æ®ã€‚
    """
    with st.container(border=True):
        st.markdown("#### ç®€å†æ¦‚è¿°")
        st.markdown(f"**ç‰¹ç‚¹**: {resume_data.get('characteristics', '')}")
        st.markdown(f"**ç»éªŒ**: {resume_data.get('experience_summary', '')}")
        st.markdown(f"**æŠ€èƒ½æ¦‚è§ˆ**: {resume_data.get('skills_overview', '')}")


def display_personal_info(personal_info: Dict[str, Any]):
    """
    æ˜¾ç¤ºä¸ªäººä¿¡æ¯ã€‚

    Args:
        personal_info (Dict[str, Any]): ä¸ªäººä¿¡æ¯æ•°æ®ã€‚
    """
    with st.container(border=True):
        st.markdown("#### ä¸ªäººä¿¡æ¯")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f"**å§“å:** {personal_info.get('name', 'N/A')}")
            st.markdown(f"**é‚®ç®±:** {personal_info.get('email', 'N/A')}")
        with col2:
            st.markdown(f"**ç”µè¯:** {personal_info.get('phone', 'N/A')}")
            st.markdown(f"**åœ°å€:** {personal_info.get('address', 'N/A')}")
        st.markdown(f"**ä¸ªäººç®€ä»‹:** {personal_info.get('summary', 'N/A')}")
        if personal_info.get("skills"):
            st.markdown("**æŠ€èƒ½:**")
            st.markdown(", ".join(personal_info["skills"]))


def display_education(education_list: List[Dict[str, Any]]):
    """
    æ˜¾ç¤ºæ•™è‚²èƒŒæ™¯ã€‚

    Args:
        education_list (List[Dict[str, Any]]): æ•™è‚²èƒŒæ™¯åˆ—è¡¨ã€‚
    """
    with st.container(border=True):
        st.markdown("#### æ•™è‚²èƒŒæ™¯")
        for edu in education_list:
            st.markdown(f"**{edu['institution']}** - {edu['degree']} in {edu['major']}")
            st.markdown(f"æ¯•ä¸šå¹´ä»½: {edu['graduation_year']}")
            st.markdown("---")


def display_work_experience(work_experiences: List[Dict[str, Any]]):
    """
    æ˜¾ç¤ºå·¥ä½œç»å†ã€‚

    Args:
        work_experiences (List[Dict[str, Any]]): å·¥ä½œç»å†åˆ—è¡¨ã€‚
    """
    with st.container(border=True):
        st.markdown("#### å·¥ä½œç»å†")
        for work in work_experiences:
            st.markdown(
                f"**{work['company']}** - {work['position']} ({work['experience_type']})"
            )
            st.markdown(f"{work['start_date']} to {work['end_date']}")
            st.markdown("èŒè´£:")
            for resp in work["responsibilities"]:
                st.markdown(f"- {resp}")
            st.markdown("---")


def display_project_experience(project_experiences: List[Dict[str, Any]]):
    """
    æ˜¾ç¤ºé¡¹ç›®ç»å†ã€‚

    Args:
        project_experiences (List[Dict[str, Any]]): é¡¹ç›®ç»å†åˆ—è¡¨ã€‚
    """
    if project_experiences:
        with st.container(border=True):
            st.markdown("#### é¡¹ç›®ç»å†")
            for proj in project_experiences:
                st.markdown(f"**{proj['name']}** - {proj['role']}")
                st.markdown(f"{proj['start_date']} to {proj['end_date']}")
                st.markdown("è¯¦æƒ…:")
                for detail in proj["details"]:
                    st.markdown(f"- {detail}")
                st.markdown("---")


main()
