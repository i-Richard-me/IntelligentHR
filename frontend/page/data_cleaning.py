import streamlit as st
from PIL import Image
import pandas as pd
import sys
import os
from typing import Dict, Any, List, Optional
from uuid import uuid4

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(project_root)

from frontend.ui_components import show_sidebar, show_footer, apply_common_styles
from backend.data_processing.data_cleaning.data_processor import (
    initialize_vector_store,
    get_entity_retriever,
)
from backend.data_processing.data_cleaning.verification_workflow import (
    EntityVerificationWorkflow,
    ProcessingStatus,
)

st.query_params.role = st.session_state.role

# åº”ç”¨è‡ªå®šä¹‰æ ·å¼
apply_common_styles()

# æ˜¾ç¤ºä¾§è¾¹æ 
show_sidebar()

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "batch_results" not in st.session_state:
    st.session_state.batch_results = None
if "processing_complete" not in st.session_state:
    st.session_state.processing_complete = False
if "batch_results_df" not in st.session_state:
    st.session_state.batch_results_df = None

# å®šä¹‰å®ä½“ç±»å‹é€‰é¡¹
ENTITY_TYPES = {
    "å…¬å¸åç§°": {
        "collection_name": "company_data",
        "original_field": "company_name",
        "standard_field": "standard_name",
        "validation_instructions": """
        è¯·ç‰¹åˆ«æ³¨æ„ï¼Œæœ‰æ•ˆçš„å…¬å¸åç§°åº”è¯¥æ˜¯å…·ä½“çš„ã€å¯è¯†åˆ«çš„ä¼ä¸šå®ä½“ã€‚
        ä¾‹å¦‚ï¼Œ"ç§‘æŠ€å…¬å¸"è¿™æ ·çš„æ³›ç§°åº”è¢«è§†ä¸ºæ— æ•ˆï¼Œè€Œ"é˜¿é‡Œå·´å·´"åˆ™æ˜¯æœ‰æ•ˆçš„ã€‚
        """,
        "analysis_instructions": """
        åœ¨åˆ†ææœç´¢ç»“æœæ—¶ï¼Œè¯·ç‰¹åˆ«æ³¨æ„è¯†åˆ«å…¬å¸çš„æ­£å¼åç§°ã€ç®€ç§°ã€æ›¾ç”¨åç­‰ã€‚
        éœ€è¦æ¨æ–­è¯¥å…¬å¸æ˜¯å¦æ˜¯æŸå®¶çŸ¥åå…¬å¸çš„åˆåŒä¸»ä½“å˜ä½“æˆ–å…¶å­å…¬å¸ã€‚
        å¦‚æœæ˜¯ï¼Œæœ€ç»ˆæä¾›çš„åº”è¯¥æ˜¯è¿™å®¶æ›´æ™®éå’ŒçŸ¥åçš„å…¬å¸åç§°ã€‚
        ä¾‹å¦‚ï¼Œå¦‚æœæœç´¢ç»“æœæ˜¾ç¤º"æ·˜å®ï¼ˆä¸­å›½ï¼‰è½¯ä»¶æœ‰é™å…¬å¸"æ˜¯é˜¿é‡Œå·´å·´é›†å›¢çš„å­å…¬å¸ï¼Œ
        é‚£ä¹ˆåº”è¯¥å°†"é˜¿é‡Œå·´å·´"è¯†åˆ«ä¸ºæ ‡å‡†åŒ–çš„å…¬å¸åç§°ã€‚
        """,
        "verification_instructions": """
        åœ¨éªŒè¯è¿‡ç¨‹ä¸­ï¼Œè¯·è€ƒè™‘å…¬å¸çš„å„ç§å¯èƒ½çš„åç§°å½¢å¼ï¼ŒåŒ…æ‹¬å…¨ç§°ã€ç®€ç§°ã€å“ç‰Œåç­‰ã€‚
        å³ä½¿åç§°è¡¨è¿°ä¸åŒï¼Œåªè¦æŒ‡å‘åŒä¸€ä¸ªæ¯å…¬å¸æˆ–é›†å›¢ï¼Œåº”è§†ä¸ºåŒ¹é…ã€‚
        ä¾‹å¦‚ï¼Œ"é˜¿é‡Œå·´å·´"å’Œ"é˜¿é‡Œå·´å·´é›†å›¢æ§è‚¡æœ‰é™å…¬å¸"åº”è¯¥è¢«è§†ä¸ºåŒ¹é…ã€‚
        ä½†å¯¹äºåç§°è¡¨è¿°ç›¸è¿‘ï¼Œä½†æŒ‡å‘ä¸åŒå…¬å¸çš„ï¼Œåº”è§†ä¸ºä¸åŒ¹é…ã€‚
        ä¾‹å¦‚ï¼Œ"æµ·èˆª"å’Œ"æµ·å°”"æ˜¯ä¸åŒçš„å…¬å¸ï¼Œåº”è¯¥è¢«è§†ä¸ºä¸åŒ¹é…ã€‚
        """,
    },
    "å­¦æ ¡åç§°": {
        "collection_name": "school_data",
        "original_field": "school_name",
        "standard_field": "standard_name",
        "validation_instructions": """
        æœ‰æ•ˆçš„å­¦æ ¡åç§°åº”è¯¥æ˜¯å…·ä½“çš„æ•™è‚²æœºæ„åç§°ã€‚
        ä¾‹å¦‚ï¼Œ"å¤§å­¦"è¿™æ ·çš„æ³›ç§°åº”è¢«è§†ä¸ºæ— æ•ˆï¼Œè€Œ"åŒ—äº¬å¤§å­¦"åˆ™æ˜¯æœ‰æ•ˆçš„ã€‚
        """,
        "analysis_instructions": """
        åˆ†ææ—¶æ³¨æ„è¯†åˆ«å­¦æ ¡çš„å®˜æ–¹åç§°ã€å¸¸ç”¨ç®€ç§°ç­‰ã€‚
        éœ€è¦è€ƒè™‘å­¦æ ¡å¯èƒ½çš„æ›´åå†å²å’Œåˆ†æ ¡æƒ…å†µã€‚
        ä¾‹å¦‚ï¼Œå¦‚æœæœç´¢ç»“æœæ˜¾ç¤º"æ¸…åå¤§å­¦æ·±åœ³ç ”ç©¶ç”Ÿé™¢"ï¼Œ
        åº”è¯¥å°†"æ¸…åå¤§å­¦"è¯†åˆ«ä¸ºæ ‡å‡†åŒ–çš„å­¦æ ¡åç§°ã€‚
        """,
        "verification_instructions": """
        éªŒè¯æ—¶è€ƒè™‘å­¦æ ¡çš„ä¸åŒç§°å‘¼ï¼ŒåŒ…æ‹¬å…¨ç§°ã€ç®€ç§°ã€ä¿—ç§°ç­‰ã€‚
        åªè¦æŒ‡å‘åŒä¸€æ‰€å­¦æ ¡ï¼Œå³ä½¿è¡¨è¿°ä¸åŒä¹Ÿåº”è§†ä¸ºåŒ¹é…ã€‚
        ä¾‹å¦‚ï¼Œ"åŒ—å¤§"å’Œ"åŒ—äº¬å¤§å­¦"åº”è¯¥è¢«è§†ä¸ºåŒ¹é…ã€‚
        """,
    },
}


def initialize_workflow(
    entity_type: str,
    skip_validation: bool,
    skip_search: bool,
    skip_retrieval: bool,
) -> EntityVerificationWorkflow:
    """
    åˆå§‹åŒ–å®ä½“éªŒè¯å·¥ä½œæµã€‚

    Args:
        entity_type (str): å®ä½“ç±»å‹ã€‚
        skip_validation (bool): æ˜¯å¦è·³è¿‡è¾“å…¥éªŒè¯ã€‚
        skip_search (bool): æ˜¯å¦è·³è¿‡ç½‘ç»œæœç´¢å’Œåˆ†æã€‚
        skip_retrieval (bool): æ˜¯å¦è·³è¿‡å‘é‡æ£€ç´¢å’ŒåŒ¹é…ã€‚

    Returns:
        EntityVerificationWorkflow: åˆå§‹åŒ–åçš„å·¥ä½œæµå¯¹è±¡ã€‚
    """
    entity_info = ENTITY_TYPES[entity_type]
    try:
        collection = initialize_vector_store(entity_info["collection_name"])
    except ValueError as e:
        st.error(f"åˆå§‹åŒ–å‘é‡å­˜å‚¨æ—¶å‡ºé”™ï¼š{str(e)}")
        st.error("è¯·ç¡®ä¿å·²é€šè¿‡æ•°æ®åº“ç®¡ç†ç•Œé¢åˆ›å»ºå¹¶å¯¼å…¥æ•°æ®åˆ°ç›¸åº”çš„é›†åˆã€‚")
        return None

    retriever = get_entity_retriever(collection, entity_type)
    return EntityVerificationWorkflow(
        retriever=retriever,
        entity_type=entity_type,
        original_field="original_name",
        standard_field="standard_name",
        validation_instructions=entity_info["validation_instructions"],
        analysis_instructions=entity_info["analysis_instructions"],
        verification_instructions=entity_info["verification_instructions"],
        skip_validation=skip_validation,
        skip_search=skip_search,
        skip_retrieval=skip_retrieval,
    )


def main():
    st.title("ğŸ¢ è‡ªåŠ¨åŒ–æ•°æ®æ¸…æ´—")
    st.markdown("---")

    # æ˜¾ç¤ºåŠŸèƒ½ä»‹ç»
    display_info_message()

    # æ˜¾ç¤ºå·¥ä½œæµç¨‹
    display_workflow()

    # ä»»åŠ¡è®¾ç½®éƒ¨åˆ†
    st.markdown("## ä»»åŠ¡è®¾ç½®")

    with st.container(border=True):
        st.markdown("##### æ•°æ®æ¸…æ´—è®¾ç½®")

        # ä½¿ç”¨æ›´å‹å¥½çš„ä¸šåŠ¡è¯­è¨€
        entity_type = st.radio(
            "é€‰æ‹©è¦æ¸…æ´—çš„æ•°æ®ç±»å‹",
            ["å…¬å¸åç§°", "å­¦æ ¡åç§°"],
            help="é€‰æ‹©æ‚¨éœ€è¦æ ‡å‡†åŒ–çš„æ•°æ®ç±»å‹ã€‚",
        )

        # å·¥ä½œæµç¨‹é€‰é¡¹
        st.markdown("##### æ¸…æ´—æµç¨‹è®¾ç½®")
        col1, col2, col3 = st.columns(3)
        with col1:
            skip_validation = st.checkbox(
                "è·³è¿‡è¾“å…¥éªŒè¯",
                value=False,
                help="å¦‚æœç¡®ä¿¡è¾“å…¥æ•°æ®æœ‰æ•ˆï¼Œå¯ä»¥è·³è¿‡éªŒè¯æ­¥éª¤ã€‚",
            )
        with col2:
            skip_search = st.checkbox(
                "è·³è¿‡ç½‘ç»œæœç´¢",
                value=False,
                help="å¯¹äºçŸ¥åå®ä½“ï¼Œå¯ä»¥ç›´æ¥è¿›è¡Œæ•°æ®åº“åŒ¹é…ï¼Œè·³è¿‡ç½‘ç»œæœç´¢æ­¥éª¤ã€‚",
            )
        with col3:
            skip_retrieval = st.checkbox(
                "è·³è¿‡æ•°æ®åº“åŒ¹é…",
                value=False,
                help="å¦‚æœå¤„ç†å…¨æ–°æ•°æ®ï¼Œå¯ä»¥è·³è¿‡ä¸å·²æœ‰æ•°æ®åº“çš„åŒ¹é…æ­¥éª¤ã€‚",
            )

    # åˆå§‹åŒ–å·¥ä½œæµ
    workflow = initialize_workflow(
        entity_type, skip_validation, skip_search, skip_retrieval
    )

    st.markdown("## æ•°æ®æ¸…æ´—")

    with st.container(border=True):
        tab1, tab2 = st.tabs(["å•ä¸ªæ ·æœ¬æµ‹è¯•", "æ‰¹é‡æ•°æ®æ¸…æ´—"])

        with tab1:
            single_entity_verification(workflow, entity_type)

        with tab2:
            batch_processing(workflow, entity_type)

    # é¡µè„š
    show_footer()


def display_info_message():
    """
    æ˜¾ç¤ºè‡ªåŠ¨åŒ–æ•°æ®æ¸…æ´—çš„åŠŸèƒ½ä»‹ç»ã€‚
    """
    st.info(
        """
    è‡ªåŠ¨åŒ–æ•°æ®æ¸…æ´—å·¥å…·é›†æˆäº†å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†å’Œå·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œå®ç°é«˜æ•ˆç²¾å‡†çš„æ•°æ®æ ‡å‡†åŒ–ã€‚

    ç³»ç»Ÿé€šè¿‡å¤šé˜¶æ®µéªŒè¯æµç¨‹ï¼Œæ™ºèƒ½è¯†åˆ«å’ŒéªŒè¯è¾“å…¥çš„å®ä½“åç§°ï¼Œå¹¶åˆ©ç”¨å‘é‡æ£€ç´¢æŠ€æœ¯åœ¨æ•°æ®åº“ä¸­è¿›è¡Œå¿«é€ŸåŒ¹é…ã€‚
    é€‚ç”¨äºéœ€è¦å¤§è§„æ¨¡æ ‡å‡†åŒ–å’ŒéªŒè¯å„ç±»å®ä½“åç§°çš„æ•°æ®å¤„ç†åœºæ™¯ã€‚
    """
    )


def display_workflow():
    """
    æ˜¾ç¤ºè‡ªåŠ¨åŒ–æ•°æ®æ¸…æ´—å·¥å…·çš„å·¥ä½œæµç¨‹ã€‚
    """
    with st.expander("ğŸ¢ æŸ¥çœ‹è‡ªåŠ¨åŒ–æ•°æ®æ¸…æ´—å·¥ä½œæµç¨‹", expanded=False):
        with st.container(border=True):
            col1, col2 = st.columns([1, 1])

            with col1:
                image = Image.open("frontend/assets/data_cleaning_workflow.png")
                st.image(image, caption="è‡ªåŠ¨åŒ–æ•°æ®æ¸…æ´—æµç¨‹å›¾", use_column_width=True)

            with col2:
                st.markdown(
                    """
                    <div class="workflow-container">
                        <div class="workflow-step">
                            <strong>1. æ™ºèƒ½æ•°æ®éªŒè¯</strong>: åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹çš„è‡ªç„¶è¯­è¨€ç†è§£èƒ½åŠ›ï¼Œæ™ºèƒ½è¯†åˆ«å’Œåˆæ­¥éªŒè¯è¾“å…¥çš„å®ä½“åç§°ã€‚
                        </div>
                        <div class="workflow-step">
                            <strong>2. å¤šæºç½‘ç»œæœç´¢</strong>: è°ƒç”¨å¤šä¸ªæœç´¢å¼•æ“APIï¼Œå…¨é¢æ”¶é›†å®ä½“ç›¸å…³ä¿¡æ¯ï¼Œä¸ºåç»­åˆ†ææä¾›ä¸°å¯Œæ•°æ®æ”¯æŒã€‚
                        </div>
                        <div class="workflow-step">
                            <strong>3. å¤§æ¨¡å‹æ¨ç†åˆ†æ</strong>: è¿ç”¨å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä»æœç´¢ç»“æœä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¦‚å®ä½“å…¨ç§°ã€ç®€ç§°ç­‰ã€‚
                        </div>
                        <div class="workflow-step">
                            <strong>4. å‘é‡æ£€ç´¢åŒ¹é…</strong>: å°†å¤„ç†åçš„å®ä½“ä¿¡æ¯è½¬åŒ–ä¸ºå‘é‡ï¼Œåœ¨é¢„æ„å»ºçš„å¤§è§„æ¨¡å®ä½“å‘é‡æ•°æ®åº“ä¸­è¿›è¡Œé«˜æ•ˆã€ç²¾å‡†çš„ç›¸ä¼¼åº¦åŒ¹é…ã€‚
                        </div>
                        <div class="workflow-step">
                            <strong>5. ç»“æœéªŒè¯ä¸è¾“å‡º</strong>: å¤§è¯­è¨€æ¨¡å‹å¯¹å¤šæºä¿¡æ¯å’ŒåŒ¹é…ç»“æœè¿›è¡Œç»¼åˆåˆ†æå’ŒéªŒè¯ï¼Œç”Ÿæˆæœ€ç»ˆçš„æ ‡å‡†åŒ–å®ä½“åç§°ã€‚
                        </div>
                    </div>
                    """,
                    unsafe_allow_html=True,
                )


def single_entity_verification(workflow: EntityVerificationWorkflow, entity_type: str):
    """
    å¤„ç†å•ä¸ªå®ä½“åç§°çš„æ ‡å‡†åŒ–ã€‚

    Args:
        workflow (EntityVerificationWorkflow): å®ä½“åç§°æ ‡å‡†åŒ–çš„å·¥ä½œæµå¯¹è±¡ã€‚
        entity_type (str): å®ä½“ç±»å‹ã€‚
    """
    with st.form(key="single_entity_form"):
        entity_name = st.text_input(
            f"è¾“å…¥{entity_type}",
            placeholder=f"ä¾‹å¦‚ï¼š{'é˜¿é‡Œå·´å·´' if entity_type == 'å…¬å¸åç§°' else 'åŒ—äº¬å¤§å­¦'}",
        )
        submit_button = st.form_submit_button("æ ‡å‡†åŒ–")
        if submit_button and entity_name:
            with st.spinner("æ­£åœ¨æ ‡å‡†åŒ–..."):
                session_id = str(uuid4())
                result = workflow.run(entity_name, session_id=session_id)
            display_single_result(result, entity_type)


def display_single_result(result: Dict[str, Any], entity_type: str):
    st.success("æ•°æ®å¤„ç†å®Œæˆï¼")
    col1, col2 = st.columns(2)
    with col1:
        st.metric(f"æœ€ç»ˆ{entity_type}", result["final_entity_name"])
    with col2:
        st.metric("æ ‡å‡†åŒ–çŠ¶æ€", result["status"].value)

    with st.expander("æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯"):
        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        st.subheader("åŸºæœ¬ä¿¡æ¯")
        display_info = {
            "åŸå§‹è¾“å…¥": result["original_input"],
            "æœ€ç»ˆå®ä½“åç§°": result["final_entity_name"],
            "æ ‡å‡†åŒ–çŠ¶æ€": result["status"].value,
            "æ˜¯å¦æœ‰æ•ˆè¾“å…¥": result["is_valid"],
            "è¯†åˆ«çš„å®ä½“åç§°": result.get("identified_entity_name"),
            "æ£€ç´¢çš„å®ä½“åç§°": result.get("retrieved_entity_name"),
        }
        st.json(display_info)

        # æ·»åŠ ä¸“é—¨çš„æœç´¢ç»“æœå±•ç¤ºåŒºåŸŸ
        st.subheader("ç½‘ç»œæœç´¢ç»“æœ")
        if result.get("search_results"):
            st.text_area(
                label="æœç´¢ç»“æœè¯¦æƒ…",
                value=result["search_results"],
                height=200,
                disabled=True,
                key="search_results",
            )
        elif result.get("search_results") is None:
            st.info("æœªè¿›è¡Œç½‘ç»œæœç´¢")
        else:
            st.info("ç½‘ç»œæœç´¢æœªè¿”å›ç»“æœ")

    if result["status"] == ProcessingStatus.INVALID_INPUT:
        st.error("è¾“å…¥è¢«åˆ¤å®šä¸ºæ— æ•ˆï¼Œè¯·æ£€æŸ¥å¹¶é‡æ–°è¾“å…¥ã€‚")
    elif result["status"] in [
        ProcessingStatus.UNIDENTIFIED,
        ProcessingStatus.UNVERIFIED,
    ]:
        st.warning("æ­¤ç»“æœå¯èƒ½éœ€è¦è¿›ä¸€æ­¥ç¡®è®¤ã€‚")
    elif result["status"] == ProcessingStatus.VALID_INPUT:
        st.info(
            "è¾“å…¥è¢«åˆ¤å®šä¸ºæœ‰æ•ˆï¼Œä½†æœªè¿›è¡Œè¿›ä¸€æ­¥å¤„ç†ã€‚å¦‚éœ€æ›´é«˜å‡†ç¡®åº¦ï¼Œè¯·è€ƒè™‘å¯ç”¨æœç´¢å’Œæ£€ç´¢æ­¥éª¤ã€‚"
        )


def batch_processing(workflow: EntityVerificationWorkflow, entity_type: str):
    """
    å¤„ç†æ‰¹é‡å®ä½“åç§°æ ‡å‡†åŒ–ã€‚

    Args:
        workflow (EntityVerificationWorkflow): å®ä½“åç§°æ ‡å‡†åŒ–å·¥ä½œæµå¯¹è±¡ã€‚
        entity_type (str): å®ä½“ç±»å‹ã€‚
    """
    uploaded_file = st.file_uploader(f"ä¸Šä¼ CSVæ–‡ä»¶ï¼ˆåŒ…å«{entity_type}åˆ—ï¼‰", type="csv")
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        st.write("é¢„è§ˆä¸Šä¼ çš„æ•°æ®ï¼š")
        st.dataframe(df.head())
        if st.button("å¼€å§‹æ‰¹é‡å¤„ç†"):
            process_batch(df, workflow, entity_type)

    # æ˜¾ç¤ºå¤„ç†ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
    if st.session_state.batch_results_df is not None:
        display_batch_results(st.session_state.batch_results_df, entity_type)


def process_batch(
    df: pd.DataFrame, workflow: EntityVerificationWorkflow, entity_type: str
):
    """
    å¤„ç†æ‰¹é‡å®ä½“æ•°æ®ã€‚

    Args:
        df (pd.DataFrame): åŒ…å«å®ä½“åç§°çš„DataFrameã€‚
        workflow (EntityVerificationWorkflow): å®ä½“åç§°æ ‡å‡†åŒ–å·¥ä½œæµå¯¹è±¡ã€‚
        entity_type (str): å®ä½“ç±»å‹ã€‚
    """
    results = []
    progress_bar = st.progress(0)
    status_area = st.empty()

    for i, entity_name in enumerate(df.iloc[:, 0]):
        with st.spinner(f"æ­£åœ¨å¤„ç†: {entity_name}"):
            session_id = str(uuid4())  # ä¸ºæ¯ä¸ªå®ä½“ç”Ÿæˆæ–°çš„ session_id
            result = workflow.run(entity_name, session_id=session_id)
            results.append(result)

        # æ›´æ–°è¿›åº¦æ¡
        progress = (i + 1) / len(df)
        progress_bar.progress(progress)

        # æ›´æ–°çŠ¶æ€ä¿¡æ¯
        status_message = (
            f"å·²å¤„ç†: {i+1}/{len(df)} - "
            f"æœ€æ–°: '{entity_name}' â†’ '{result['final_entity_name']}' "
            f"(çŠ¶æ€: {result['status'].value})"
        )
        status_area.info(status_message)

    result_df = pd.DataFrame(results)

    # æ·»åŠ åŸå§‹è¾“å…¥åˆ—
    result_df.insert(0, "åŸå§‹è¾“å…¥", df.iloc[:, 0])

    # æ›´æ–°ä¼šè¯çŠ¶æ€
    st.session_state.batch_results_df = result_df
    st.session_state.processing_complete = True

    # å¤„ç†å®Œæˆåçš„æç¤º
    status_area.success(f"æ‰¹é‡å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(df)} æ¡æ•°æ®ã€‚")


def display_batch_results(result_df: pd.DataFrame, entity_type: str):
    st.success("æ‰¹é‡å¤„ç†å®Œæˆï¼")

    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    status_counts = result_df["status"].value_counts()

    # æ˜¾ç¤ºç®€åŒ–çš„ç»“æœç»Ÿè®¡
    st.subheader("å¤„ç†ç»“æœç»Ÿè®¡")
    stats_df = pd.DataFrame(
        {
            "ç±»åˆ«": [status.value for status in ProcessingStatus],
            "æ•°é‡": [status_counts.get(status, 0) for status in ProcessingStatus],
        }
    )
    stats_df["å æ¯”"] = (stats_df["æ•°é‡"] / len(result_df) * 100).round(2).astype(
        str
    ) + "%"
    st.table(stats_df.set_index("ç±»åˆ«"))

    # æ˜¾ç¤ºç»“æœè¡¨æ ¼
    st.subheader("è¯¦ç»†ç»“æœ")
    display_columns = ["åŸå§‹è¾“å…¥", "final_entity_name", "status", "search_results"]
    st.dataframe(result_df[display_columns])

    # æä¾›å»ºè®®
    if (
        ProcessingStatus.UNVERIFIED in status_counts
        or ProcessingStatus.UNIDENTIFIED in status_counts
    ):
        st.warning(
            f"æœ‰ {status_counts.get(ProcessingStatus.UNVERIFIED, 0) + status_counts.get(ProcessingStatus.UNIDENTIFIED, 0)} ä¸ªå®ä½“æœªèƒ½å®Œå…¨éªŒè¯ã€‚å»ºè®®æ‰‹åŠ¨æ£€æŸ¥è¿™äº›ç»“æœã€‚"
        )
    if ProcessingStatus.VALID_INPUT in status_counts:
        st.info(
            f"æœ‰ {status_counts.get(ProcessingStatus.VALID_INPUT, 0)} ä¸ªå®ä½“ä»…è¿›è¡Œäº†è¾“å…¥éªŒè¯ã€‚å¦‚éœ€æ›´é«˜å‡†ç¡®åº¦ï¼Œè¯·è€ƒè™‘å¯ç”¨å®Œæ•´è¯†åˆ«æµç¨‹ã€‚"
        )

    # æä¾›ä¸‹è½½é€‰é¡¹
    csv = result_df.to_csv(index=False)
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½å¤„ç†ç»“æœ",
        data=csv.encode("utf-8-sig"),
        file_name=f"processed_{entity_type.lower().replace(' ', '_')}.csv",
        mime="text/csv",
    )


main()
