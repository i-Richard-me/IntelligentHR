import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import sys
import os
import joblib
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.append(project_root)

from frontend.ui_components import show_sidebar, show_footer, apply_common_styles
from backend.data_processing.analysis.ml_explanations import (
    ML_TOOL_INFO,
    CONFUSION_MATRIX_EXPLANATION,
    CLASSIFICATION_REPORT_EXPLANATION,
    FEATURE_IMPORTANCE_EXPLANATION,
    REGRESSION_METRICS_EXPLANATION,
)
from backend.data_processing.analysis.model_predictor import (
    ModelPredictor,
    list_available_models,
)
from backend.data_processing.analysis.model_utils import (
    train_model,
    save_model,
    add_model_record,
    initialize_session_state,
    evaluate_model,
    get_feature_importance,
)
from backend.data_processing.analysis.ml_components import (
    display_info_message,
    display_data_split_settings,
    display_random_forest_settings,
    display_decision_tree_settings,
    display_xgboost_settings,
    display_linear_regression_settings,
    display_model_selection,
)
from backend.data_processing.analysis.shap_analysis import (
    calculate_shap_values,
    create_shap_summary_plot,
    create_shap_importance_plot,
    create_shap_dependence_plot,
)

# åº”ç”¨è‡ªå®šä¹‰æ ·å¼
apply_common_styles()

# æ˜¾ç¤ºä¾§è¾¹æ 
show_sidebar()

if "initialized" not in st.session_state:
    st.session_state.update(initialize_session_state())
    st.session_state.initialized = True


def display_operation_settings():
    st.markdown("## æ“ä½œè®¾ç½®")
    with st.container(border=True):
        col1, col2 = st.columns(2)

        with col1:
            mode = st.radio(
                "é€‰æ‹©æ“ä½œæ¨¡å¼",
                options=["è®­ç»ƒæ–°æ¨¡å‹", "ä½¿ç”¨å·²ä¿å­˜æ¨¡å‹"],
                index=0 if st.session_state.mode == "train" else 1,
                key="mode_radio",
            )
            st.session_state.mode = "train" if mode == "è®­ç»ƒæ–°æ¨¡å‹" else "predict"

        with col2:
            problem_type = st.radio(
                "é€‰æ‹©é—®é¢˜ç±»å‹",
                options=["åˆ†ç±»é—®é¢˜", "å›å½’é—®é¢˜"],
                index=0 if st.session_state.problem_type == "classification" else 1,
                key="problem_type_radio",
            )
            st.session_state.problem_type = (
                "classification" if problem_type == "åˆ†ç±»é—®é¢˜" else "regression"
            )

    # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºç›¸åº”çš„æç¤ºä¿¡æ¯
    if st.session_state.mode == "train":
        st.info("æ‚¨é€‰æ‹©äº†è®­ç»ƒæ–°æ¨¡å‹ã€‚è¯·ä¸Šä¼ æ•°æ®å¹¶è®¾ç½®æ¨¡å‹å‚æ•°ã€‚")
    else:
        st.info(
            f"æ‚¨é€‰æ‹©äº†ä½¿ç”¨å·²ä¿å­˜çš„{'åˆ†ç±»' if st.session_state.problem_type == 'classification' else 'å›å½’'}æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚è¯·é€‰æ‹©æ¨¡å‹å¹¶ä¸Šä¼ é¢„æµ‹æ•°æ®ã€‚"
        )


def main():
    initialize_session_state()

    st.title("ğŸ¤– æœºå™¨å­¦ä¹ å»ºæ¨¡ä¸é¢„æµ‹")
    st.markdown("---")

    display_info_message()
    display_operation_settings()

    if st.session_state.mode == "train":
        display_data_upload_and_preview()
        if st.session_state.df is not None:
            display_column_selection()
            display_model_selection()
            display_model_training_and_advanced_settings()
            display_model_records()

        if st.session_state.model_results:
            display_results()

            do_model_interpretation = st.checkbox(
                "è¿›è¡Œæ¨¡å‹è§£é‡Š", value=st.session_state.do_model_interpretation
            )

            if do_model_interpretation != st.session_state.do_model_interpretation:
                st.session_state.do_model_interpretation = do_model_interpretation
                if not do_model_interpretation and "shap_results" in st.session_state:
                    del st.session_state.shap_results

            if st.session_state.do_model_interpretation:
                display_model_interpretation()
    else:
        display_saved_model_selection()
        display_data_upload_and_preview(for_prediction=True)
        if st.session_state.data_validated:
            display_prediction_execution()
            display_prediction_results()

    show_footer()


def display_data_upload_and_preview(for_prediction=False):
    st.markdown("## æ•°æ®ä¸Šä¼ ä¸é¢„è§ˆ")
    with st.container(border=True):
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ CSVæˆ–Excelæ–‡ä»¶", type=["csv", "xlsx", "xls"]
        )

        if uploaded_file is not None:
            try:
                if uploaded_file.name.endswith(".csv"):
                    data = pd.read_csv(uploaded_file)
                elif uploaded_file.name.endswith((".xls", ".xlsx")):
                    data = pd.read_excel(uploaded_file)
                else:
                    st.error("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚è¯·ä¸Šä¼ CSVæˆ–Excelæ–‡ä»¶ã€‚")
                    return

                st.session_state.data_validated = False

                if for_prediction:
                    if st.session_state.predictor.model is not None:
                        model_features = set(
                            st.session_state.predictor.original_features
                        )
                        data_features = set(data.columns)
                        missing_features = model_features - data_features
                        extra_features = data_features - model_features

                        if missing_features:
                            st.warning(
                                f"âš ï¸ ä¸Šä¼ çš„æ•°æ®ç¼ºå°‘ä»¥ä¸‹ç‰¹å¾ï¼š{', '.join(missing_features)}"
                            )
                            return

                        st.session_state.uploaded_data = data
                        st.session_state.data_validated = True
                        st.success("âœ… æ•°æ®ä¸Šä¼ æˆåŠŸï¼")

                        if extra_features:
                            st.info(f"â„¹ï¸ é¢å¤–çš„ç‰¹å¾: {', '.join(extra_features)}")
                    else:
                        st.warning("âš ï¸ è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ¨¡å‹ï¼Œç„¶åå†ä¸Šä¼ æ•°æ®ã€‚")
                        return
                else:
                    st.session_state.df = data
                    st.session_state.data_validated = True
                    st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")

                st.write(f"æ•°æ®é›†åŒ…å« {len(data)} è¡Œå’Œ {len(data.columns)} åˆ—")
                st.write(data.head())

                with st.expander("æŸ¥çœ‹æ•°æ®ç±»å‹ä¿¡æ¯", expanded=False):
                    st.write(data.dtypes)

            except Exception as e:
                st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}")


def display_column_selection():
    if st.session_state.df is not None:
        st.markdown("## å˜é‡é€‰æ‹©")
        with st.container(border=True):
            st.session_state.target_column = st.selectbox(
                "é€‰æ‹©ç›®æ ‡å˜é‡",
                options=st.session_state.df.columns,
                key="target_column_select",
            )
            with st.expander("é€‰æ‹©ç‰¹å¾å˜é‡", expanded=False):
                st.session_state.feature_columns = st.multiselect(
                    "é€‰æ‹©ç‰¹å¾å˜é‡",
                    options=[
                        col
                        for col in st.session_state.df.columns
                        if col != st.session_state.target_column
                    ],
                    default=[
                        col
                        for col in st.session_state.df.columns
                        if col != st.session_state.target_column
                    ],
                    key="feature_columns_select",
                )

            # éªŒè¯é—®é¢˜ç±»å‹
            if st.session_state.problem_type == "classification":
                if st.session_state.df[st.session_state.target_column].dtype in [
                    "int64",
                    "float64",
                ]:
                    unique_values = st.session_state.df[
                        st.session_state.target_column
                    ].nunique()
                    if unique_values > 10:
                        st.warning(
                            "ç›®æ ‡å˜é‡çœ‹èµ·æ¥åƒæ˜¯è¿ç»­å€¼ã€‚æ‚¨å¯èƒ½éœ€è¦é€‰æ‹©å›å½’é—®é¢˜è€Œä¸æ˜¯åˆ†ç±»é—®é¢˜ã€‚"
                        )
            else:  # regression
                if st.session_state.df[st.session_state.target_column].dtype not in [
                    "int64",
                    "float64",
                ]:
                    st.warning("ç›®æ ‡å˜é‡ä¸æ˜¯æ•°å€¼ç±»å‹ã€‚å›å½’é—®é¢˜éœ€è¦æ•°å€¼ç±»å‹çš„ç›®æ ‡å˜é‡ã€‚")


def display_model_training_and_advanced_settings():
    if (
        st.session_state.df is not None
        and st.session_state.target_column
        and st.session_state.feature_columns
    ):
        st.markdown("## æ¨¡å‹è®­ç»ƒ")
        with st.container(border=True):
            display_data_split_settings()

            if st.button("å¼€å§‹è®­ç»ƒæ¨¡å‹"):
                with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹ï¼Œè¯·ç¨å€™..."):
                    try:
                        # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ç›¸åº”çš„å‚æ•°ç©ºé—´
                        if st.session_state.model_type == "éšæœºæ£®æ—":
                            param_ranges = st.session_state.rf_param_grid
                            n_trials = st.session_state.rf_n_trials
                        elif st.session_state.model_type == "å†³ç­–æ ‘":
                            param_ranges = st.session_state.dt_param_grid
                            n_trials = None  # å†³ç­–æ ‘ä½¿ç”¨ç½‘æ ¼æœç´¢ï¼Œä¸éœ€è¦n_trials
                        elif st.session_state.model_type == "XGBoost":
                            param_ranges = st.session_state.xgb_param_ranges
                            n_trials = st.session_state.xgb_n_trials
                        elif st.session_state.model_type == "çº¿æ€§å›å½’":
                            param_ranges = None  # çº¿æ€§å›å½’ä¸éœ€è¦å‚æ•°ä¼˜åŒ–
                            n_trials = None
                        else:
                            raise ValueError(
                                f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {st.session_state.model_type}"
                            )

                        st.session_state.model_results = train_model(
                            st.session_state.df,
                            st.session_state.target_column,
                            st.session_state.feature_columns,
                            st.session_state.model_type,
                            st.session_state.problem_type,
                            st.session_state.test_size,
                            param_ranges=param_ranges,
                            n_trials=n_trials,
                        )
                        st.session_state.model_records = add_model_record(
                            st.session_state.model_records,
                            st.session_state.model_type,
                            st.session_state.problem_type,
                            st.session_state.model_results,
                        )
                        success_message = "æ¨¡å‹è®­ç»ƒå®Œæˆï¼"
                        if "best_trial" in st.session_state.model_results:
                            success_message += f" æœ€ä½³å‚æ•°åœ¨ç¬¬ {st.session_state.model_results['best_trial']} è½®è·å¾—ã€‚"
                        st.success(success_message)

                        if st.session_state.do_model_interpretation:
                            with st.spinner("æ­£åœ¨è®¡ç®—æ¨¡å‹è§£é‡Š..."):
                                calculate_and_store_shap_values()
                                st.success("æ¨¡å‹è§£é‡Šè®¡ç®—å®Œæˆï¼")

                    except Exception as e:
                        st.error(f"æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™ï¼š{str(e)}")


def display_model_records():
    if not st.session_state.model_records.empty:
        st.markdown("## æ¨¡å‹è®°å½•")
        with st.container(border=True):
            columns_order = [
                "æ¨¡å‹ID",
                "æ¨¡å‹ç±»å‹",
                "é—®é¢˜ç±»å‹",
                "äº¤å‰éªŒè¯åˆ†æ•°",
                "æµ‹è¯•é›†åˆ†æ•°",
                "æœ€ä½³æ¨¡å‹",
                "ä¿å­˜",
                "è®­ç»ƒæ—¶é—´",
                "å‚æ•°",
            ]
            temp_df = st.session_state.model_records.reindex(columns=columns_order)
            temp_df["ä¿å­˜"] = False
            temp_df["æœ€ä½³æ¨¡å‹"] = False

            # æ ¹æ®é—®é¢˜ç±»å‹é€‰æ‹©æœ€ä½³æ¨¡å‹
            if st.session_state.problem_type == "classification":
                best_model_index = temp_df["äº¤å‰éªŒè¯åˆ†æ•°"].idxmax()
            else:  # regression
                best_model_index = temp_df["æµ‹è¯•é›†åˆ†æ•°"].idxmin()  # ä½¿ç”¨ MSEï¼Œè¶Šä½è¶Šå¥½

            temp_df.loc[best_model_index, "æœ€ä½³æ¨¡å‹"] = True

            edited_df = st.data_editor(
                temp_df,
                column_config={
                    "ä¿å­˜": st.column_config.CheckboxColumn(
                        "ä¿å­˜",
                        help="é€‰æ‹©è¦ä¿å­˜çš„æ¨¡å‹",
                        default=False,
                    ),
                    "æœ€ä½³æ¨¡å‹": st.column_config.CheckboxColumn(
                        "æœ€ä½³æ¨¡å‹",
                        help="è¡¨ç°æœ€å¥½çš„æ¨¡å‹",
                        default=False,
                    ),
                    "äº¤å‰éªŒè¯åˆ†æ•°": st.column_config.NumberColumn(
                        "äº¤å‰éªŒè¯åˆ†æ•°",
                        format="%.4f",
                        help="å¯¹äºçº¿æ€§å›å½’æ¨¡å‹ä¸ä½¿ç”¨äº¤å‰éªŒè¯æ—¶ï¼Œæ­¤å€¼ä¸ºè®­ç»ƒé›† MSEã€‚",
                    ),
                    "æµ‹è¯•é›†åˆ†æ•°": st.column_config.NumberColumn(
                        "æµ‹è¯•é›†åˆ†æ•°",
                        format="%.4f",
                    ),
                },
                disabled=[
                    "æ¨¡å‹ID",
                    "æ¨¡å‹ç±»å‹",
                    "é—®é¢˜ç±»å‹",
                    "è®­ç»ƒæ—¶é—´",
                    "å‚æ•°",
                    "äº¤å‰éªŒè¯åˆ†æ•°",
                    "æµ‹è¯•é›†åˆ†æ•°",
                    "æœ€ä½³æ¨¡å‹",
                ],
                hide_index=True,
                column_order=columns_order,
                use_container_width=True,
            )

            save_selected_models(edited_df)


def save_selected_models(edited_df):
    models_to_save = edited_df[edited_df["ä¿å­˜"]]
    if not models_to_save.empty:
        for _, row in models_to_save.iterrows():
            model_type = row["æ¨¡å‹ç±»å‹"]
            problem_type = (
                "classification" if row["é—®é¢˜ç±»å‹"] == "åˆ†ç±»" else "regression"
            )
            timestamp = datetime.strptime(row["è®­ç»ƒæ—¶é—´"], "%Y-%m-%d %H:%M:%S")
            if (
                st.session_state.model_results
                and st.session_state.model_results["model"]
            ):
                file_path = save_model(
                    st.session_state.model_results["model"],
                    model_type,
                    problem_type,
                    timestamp,
                )
                st.success(
                    f"æ¨¡å‹ {model_type} ({problem_type}) å·²æˆåŠŸä¿å­˜åˆ° {file_path}"
                )
            else:
                st.warning(f"æ— æ³•ä¿å­˜æ¨¡å‹ {model_type}ï¼Œæ¨¡å‹å¯¹è±¡ä¸å­˜åœ¨ã€‚")


def display_results():
    if st.session_state.model_results:
        st.markdown("## æ¨¡å‹ç»“æœ")

        with st.container(border=True):
            if st.session_state.problem_type == "classification":
                tab1, tab2, tab3 = st.tabs(["æ¨¡å‹æ€§èƒ½æ¦‚è§ˆ", "æ··æ·†çŸ©é˜µ", "åˆ†ç±»æŠ¥å‘Š"])
            else:
                tab1, tab2 = st.tabs(["æ¨¡å‹æ€§èƒ½æ¦‚è§ˆ", "æ®‹å·®å›¾"])

            with tab1:
                display_model_performance_overview()

            if st.session_state.problem_type == "classification":
                with tab2:
                    display_confusion_matrix()
                with tab3:
                    display_classification_report()
            else:
                with tab2:
                    display_residual_plot()


def display_model_performance_overview():
    st.markdown("### æ¨¡å‹æ€§èƒ½æ¦‚è§ˆ")
    col1, col2 = st.columns(2)
    with col1:
        if st.session_state.problem_type == "classification":
            st.metric(
                label="äº¤å‰éªŒè¯å¹³å‡ ROC AUC",
                value=f"{st.session_state.model_results['cv_mean_score']:.4f}",
            )
        else:
            st.metric(
                label="äº¤å‰éªŒè¯å¹³å‡ MSE",
                value=f"{st.session_state.model_results['cv_mean_score']:.4f}",
                help="å¯¹äºçº¿æ€§å›å½’æ¨¡å‹ä¸ä½¿ç”¨äº¤å‰éªŒè¯æ—¶ï¼Œæ­¤å€¼ä¸ºè®­ç»ƒé›† MSEã€‚",
            )
    with col2:
        if st.session_state.problem_type == "classification":
            st.metric(
                label="æµ‹è¯•é›† ROC AUC",
                value=f"{st.session_state.model_results['test_roc_auc']:.4f}",
            )
        else:
            st.metric(
                label="æµ‹è¯•é›† MSE",
                value=f"{st.session_state.model_results['test_mse']:.4f}",
            )

    # ä¸ºçº¿æ€§å›å½’æ¨¡å‹æ·»åŠ  RÂ² æ˜¾ç¤º
    if (
        st.session_state.problem_type == "regression"
        and st.session_state.model_type == "çº¿æ€§å›å½’"
    ):
        col3, col4 = st.columns(2)
        with col3:
            st.metric(
                label="è®­ç»ƒé›† RÂ²",
                value=f"{st.session_state.model_results['train_r2']:.4f}",
            )
        with col4:
            st.metric(
                label="æµ‹è¯•é›† RÂ²",
                value=f"{st.session_state.model_results['test_r2']:.4f}",
            )


def display_confusion_matrix():
    st.markdown("### æ··æ·†çŸ©é˜µ")
    cm = st.session_state.model_results["test_confusion_matrix"]
    cm_sum = np.sum(cm)
    cm_percentages = cm / cm_sum * 100

    fig = go.Figure(
        data=go.Heatmap(
            z=cm_percentages,
            x=["é¢„æµ‹: 0", "é¢„æµ‹: 1"],
            y=["å®é™…: 0", "å®é™…: 1"],
            hoverongaps=False,
            colorscale="Blues",
            text=[
                [f"{v:.1f}%<br>({cm[i][j]})" for j, v in enumerate(row)]
                for i, row in enumerate(cm_percentages)
            ],
            texttemplate="%{text}",
            textfont={"size": 14},
        )
    )
    fig.update_layout(
        xaxis_title="é¢„æµ‹ç±»åˆ«",
        yaxis_title="å®é™…ç±»åˆ«",
        width=400,
        height=400,
        margin=dict(t=40),
    )
    st.plotly_chart(fig)

    with st.expander("æ··æ·†çŸ©é˜µè§£è¯»", expanded=False):
        st.caption(CONFUSION_MATRIX_EXPLANATION)


def display_classification_report():
    st.markdown("### åˆ†ç±»æŠ¥å‘Š")
    st.text(st.session_state.model_results["test_classification_report"])

    with st.expander("åˆ†ç±»æŠ¥å‘Šè§£è¯»", expanded=False):
        st.caption(CLASSIFICATION_REPORT_EXPLANATION)


def display_residual_plot():
    st.markdown("### æ®‹å·®å›¾")
    y_test = st.session_state.model_results["y_test"]
    y_pred = st.session_state.model_results["y_pred"]
    residuals = y_test - y_pred

    fig = go.Figure()
    fig.add_trace(go.Scatter(x=y_pred, y=residuals, mode="markers"))
    fig.update_layout(
        title="æ®‹å·®å›¾", xaxis_title="é¢„æµ‹å€¼", yaxis_title="æ®‹å·®", width=600, height=400
    )
    st.plotly_chart(fig)

    with st.expander("æ®‹å·®å›¾è§£è¯»", expanded=False):
        st.caption(REGRESSION_METRICS_EXPLANATION)


def display_xgboost_label_encoding():
    label_encoding = st.session_state.model_results.get("label_encoding")
    if label_encoding:
        with st.expander("æŸ¥çœ‹ç›®æ ‡å˜é‡ç¼–ç ä¿¡æ¯", expanded=False):
            st.caption(
                """
                ### ç›®æ ‡å˜é‡ç¼–ç å¯¹ç…§è¡¨

                åœ¨ XGBoost æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬å¯¹ç›®æ ‡å˜é‡è¿›è¡Œäº†ç¼–ç å¤„ç†ã€‚è¿™æ˜¯å› ä¸º XGBoost è¦æ±‚è¾“å…¥çš„ç›®æ ‡å˜é‡ä¸ºæ•°å€¼å‹ã€‚
                ä¸‹è¡¨å±•ç¤ºäº†åŸå§‹ç±»åˆ«ä¸å…¶å¯¹åº”çš„ç¼–ç å€¼ï¼š
                """
            )

            encoding_df = pd.DataFrame(
                list(label_encoding.items()), columns=["åŸå§‹ç±»åˆ«", "ç¼–ç å€¼"]
            )
            st.table(encoding_df)

            st.caption(
                """
                #### æ³¨æ„äº‹é¡¹ï¼š
                - åœ¨è§£é‡Šæ¨¡å‹è¾“å‡ºæ—¶ï¼Œè¯·å‚è€ƒæ­¤å¯¹ç…§è¡¨å°†æ•°å€¼ç»“æœè½¬æ¢å›åŸå§‹ç±»åˆ«ã€‚
                - ç¼–ç å€¼çš„å¤§å°å¹¶ä¸ä»£è¡¨ç±»åˆ«çš„ä¼˜åŠ£æˆ–é‡è¦æ€§ã€‚
                - å¦‚æœæ‚¨è®¡åˆ’ä½¿ç”¨æ­¤æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œè¯·ç¡®ä¿ä½¿ç”¨ç›¸åŒçš„ç¼–ç æ–¹å¼å¤„ç†æ–°æ•°æ®ã€‚
                """
            )


def display_model_interpretation():
    if (
        st.session_state.model_results
        and "feature_importance" in st.session_state.model_results
    ):
        st.markdown("## æ¨¡å‹è§£é‡Š")

        with st.container(border=True):
            tab1, tab2, tab3 = st.tabs(["ç‰¹å¾é‡è¦æ€§", "SHAPåˆ†æ", "SHAPä¾èµ–å›¾"])

            with tab1:
                st.markdown("### æ¨¡å‹ç‰¹å¾é‡è¦æ€§")
                display_feature_importance()

            with tab2:
                st.markdown("### SHAPç‰¹å¾é‡è¦æ€§åˆ†æ")
                if "shap_results" not in st.session_state:
                    calculate_and_store_shap_values()

                if "shap_results" in st.session_state:
                    fig = create_shap_importance_plot(
                        st.session_state.shap_results["feature_importance"]
                    )
                    st.plotly_chart(fig, use_container_width=True)

                    with st.expander("SHAPç‰¹å¾é‡è¦æ€§è§£é‡Š", expanded=False):
                        st.markdown(
                            """
                        SHAP (SHapley Additive exPlanations) ç‰¹å¾é‡è¦æ€§å›¾å±•ç¤ºäº†æ¯ä¸ªç‰¹å¾å¯¹æ¨¡å‹é¢„æµ‹çš„å¹³å‡ç»å¯¹è´¡çŒ®ã€‚

                        - æ¯ä¸ªæ¡å½¢ä»£è¡¨ä¸€ä¸ªç‰¹å¾ã€‚
                        - æ¡å½¢çš„é•¿åº¦è¡¨ç¤ºè¯¥ç‰¹å¾çš„å¹³å‡ç»å¯¹SHAPå€¼ï¼Œå³è¯¥ç‰¹å¾å¯¹æ¨¡å‹é¢„æµ‹çš„å¹³å‡å½±å“ç¨‹åº¦ã€‚
                        - ç‰¹å¾æŒ‰é‡è¦æ€§ä»ä¸Šåˆ°ä¸‹æ’åºï¼Œæœ€ä¸Šé¢çš„ç‰¹å¾å¯¹æ¨¡å‹é¢„æµ‹çš„å½±å“æœ€å¤§ã€‚

                        é€šè¿‡è¿™ä¸ªå›¾ï¼Œæˆ‘ä»¬å¯ä»¥ç›´è§‚åœ°çœ‹å‡ºå“ªäº›ç‰¹å¾å¯¹æ¨¡å‹çš„é¢„æµ‹ç»“æœå½±å“æœ€å¤§ã€‚è¿™æœ‰åŠ©äºæˆ‘ä»¬ç†è§£æ¨¡å‹çš„å†³ç­–ä¾æ®ï¼Œ
                        å¹¶å¯èƒ½ä¸ºè¿›ä¸€æ­¥çš„ç‰¹å¾å·¥ç¨‹æˆ–æ¨¡å‹ä¼˜åŒ–æä¾›æŒ‡å¯¼ã€‚

                        å¯¹äºçº¿æ€§å›å½’æ¨¡å‹ï¼ŒSHAPå€¼ç›´æ¥å¯¹åº”äºç‰¹å¾çš„ç³»æ•°ï¼ˆè€ƒè™‘äº†ç‰¹å¾çš„å°ºåº¦ï¼‰ã€‚æ­£çš„SHAPå€¼è¡¨ç¤ºè¯¥ç‰¹å¾
                        å¢åŠ äº†é¢„æµ‹å€¼ï¼Œè€Œè´Ÿçš„SHAPå€¼è¡¨ç¤ºè¯¥ç‰¹å¾å‡å°‘äº†é¢„æµ‹å€¼ã€‚
                        """
                        )

            with tab3:
                st.markdown("### SHAPä¾èµ–å›¾")
                if "shap_results" in st.session_state:
                    processed_feature_names = st.session_state.shap_results[
                        "processed_feature_names"
                    ]
                    selected_feature = st.selectbox(
                        "é€‰æ‹©ç‰¹å¾", options=processed_feature_names
                    )

                    fig = create_shap_dependence_plot(
                        st.session_state.shap_results["shap_values"],
                        st.session_state.shap_results["X_processed"],
                        np.array(processed_feature_names),
                        selected_feature,
                    )
                    st.plotly_chart(fig, use_container_width=True)

                    with st.expander("SHAPä¾èµ–å›¾è§£é‡Š", expanded=False):
                        st.markdown(
                            """
                        SHAPä¾èµ–å›¾å±•ç¤ºäº†é€‰å®šç‰¹å¾çš„å€¼å¦‚ä½•å½±å“å…¶SHAPå€¼ï¼ˆå³å¯¹æ¨¡å‹é¢„æµ‹çš„å½±å“ï¼‰ã€‚

                        - Xè½´è¡¨ç¤ºç‰¹å¾çš„å®é™…å€¼ã€‚
                        - Yè½´è¡¨ç¤ºè¯¥ç‰¹å¾çš„SHAPå€¼ã€‚
                        - æ¯ä¸ªç‚¹ä»£è¡¨ä¸€ä¸ªæ ·æœ¬ã€‚
                        - ç‚¹çš„é¢œè‰²è¡¨ç¤ºç‰¹å¾å€¼çš„å¤§å°ï¼Œçº¢è‰²è¡¨ç¤ºè¾ƒå¤§çš„å€¼ï¼Œè“è‰²è¡¨ç¤ºè¾ƒå°çš„å€¼ã€‚

                        é€šè¿‡è¿™ä¸ªå›¾ï¼Œæˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°ï¼š
                        1. ç‰¹å¾å€¼ä¸SHAPå€¼ä¹‹é—´çš„å…³ç³»æ˜¯å¦çº¿æ€§ã€å•è°ƒæˆ–æ›´å¤æ‚ã€‚
                        2. ç‰¹å¾å€¼çš„å“ªäº›èŒƒå›´å¯¹é¢„æµ‹ç»“æœæœ‰æ­£é¢æˆ–è´Ÿé¢å½±å“ã€‚
                        3. æ˜¯å¦å­˜åœ¨ç‰¹å¾å€¼çš„ä¸´ç•Œç‚¹ï¼Œåœ¨è¯¥ç‚¹é™„è¿‘é¢„æµ‹ç»“æœå‘ç”Ÿæ˜¾è‘—å˜åŒ–ã€‚

                        å¯¹äºçº¿æ€§å›å½’æ¨¡å‹ï¼ŒSHAPä¾èµ–å›¾é€šå¸¸ä¼šæ˜¾ç¤ºä¸ºä¸€æ¡ç›´çº¿ï¼Œæ–œç‡å¯¹åº”äºè¯¥ç‰¹å¾çš„ç³»æ•°ã€‚
                        è¿™åæ˜ äº†çº¿æ€§å›å½’æ¨¡å‹ä¸­ç‰¹å¾ä¸ç›®æ ‡å˜é‡ä¹‹é—´çš„çº¿æ€§å…³ç³»ã€‚

                        è¿™æœ‰åŠ©äºæˆ‘ä»¬æ·±å…¥ç†è§£ç‰¹å®šç‰¹å¾æ˜¯å¦‚ä½•å½±å“æ¨¡å‹é¢„æµ‹çš„ï¼Œå¯¹æ¨¡å‹çš„è§£é‡Šå’Œæ”¹è¿›éƒ½å¾ˆæœ‰ä»·å€¼ã€‚
                        """
                        )


def calculate_and_store_shap_values():
    if "shap_results" in st.session_state:
        del st.session_state.shap_results

    with st.spinner("æ­£åœ¨è®¡ç®—SHAPå€¼ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´..."):
        try:
            model_step = (
                "regressor"
                if st.session_state.model_type == "çº¿æ€§å›å½’"
                else "classifier"
            )
            shap_results = calculate_shap_values(
                st.session_state.model_results["model"].named_steps[model_step],
                st.session_state.df[st.session_state.feature_columns],
                st.session_state.model_results["model"].named_steps["preprocessor"],
                st.session_state.feature_columns,
                st.session_state.problem_type,
            )
            st.session_state.shap_results = shap_results
        except Exception as e:
            st.error(f"è®¡ç®—SHAPå€¼æ—¶å‡ºé”™ï¼š{str(e)}")
            st.error("è¯·æ£€æŸ¥æ¨¡å‹ç±»å‹å’Œæ•°æ®æ˜¯å¦å…¼å®¹ï¼Œæˆ–å°è¯•ä½¿ç”¨å…¶ä»–è§£é‡Šæ–¹æ³•ã€‚")


def display_feature_importance():
    feature_importance = st.session_state.model_results[
        "feature_importance"
    ].sort_values(ascending=True)
    fig = go.Figure(
        data=[
            go.Bar(
                x=feature_importance.values,
                y=feature_importance.index,
                orientation="h",
            )
        ]
    )
    fig.update_layout(
        xaxis_title="é‡è¦æ€§å¾—åˆ†",
        yaxis_title="ç‰¹å¾",
        height=max(500, len(feature_importance) * 25),
        width=600,
        margin=dict(t=40),
    )
    st.plotly_chart(fig)

    with st.expander("ç‰¹å¾é‡è¦æ€§è§£é‡Š", expanded=False):
        if st.session_state.model_type == "çº¿æ€§å›å½’":
            st.caption(
                """
                å¯¹äºçº¿æ€§å›å½’æ¨¡å‹ï¼Œç‰¹å¾é‡è¦æ€§æ˜¯åŸºäºå„ä¸ªç‰¹å¾çš„ç³»æ•°çš„ç»å¯¹å€¼è®¡ç®—çš„ã€‚
                ç³»æ•°çš„ç»å¯¹å€¼è¶Šå¤§ï¼Œè¡¨ç¤ºè¯¥ç‰¹å¾å¯¹é¢„æµ‹ç»“æœçš„å½±å“è¶Šå¤§ã€‚
                è¯·æ³¨æ„ï¼Œè¿™ç§æ–¹æ³•æ²¡æœ‰è€ƒè™‘ç‰¹å¾çš„å°ºåº¦ï¼Œå› æ­¤åœ¨è§£é‡Šæ—¶åº”å½“ç»“åˆç‰¹å¾çš„å®é™…å«ä¹‰å’Œå°ºåº¦æ¥ç†è§£å…¶é‡è¦æ€§ã€‚
                """
            )
        else:
            st.caption(FEATURE_IMPORTANCE_EXPLANATION)


def display_saved_model_selection():
    st.markdown("## é€‰æ‹©å·²ä¿å­˜çš„æ¨¡å‹")
    with st.container(border=True):
        problem_type = (
            "classification"
            if st.session_state.problem_type == "classification"
            else "regression"
        )
        available_models = list_available_models(problem_type=problem_type)
        selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", available_models)

        if selected_model:
            try:
                st.session_state.predictor.load_model(selected_model, problem_type)
                st.success(f"æˆåŠŸåŠ è½½æ¨¡å‹: {selected_model}")

                model_info = st.session_state.predictor.get_model_info()
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æ¨¡å‹ç±»å‹", model_info["type"])
                with col2:
                    st.metric(
                        "é—®é¢˜ç±»å‹",
                        "åˆ†ç±»" if problem_type == "classification" else "å›å½’",
                    )
                with col3:
                    st.metric("æ‰€éœ€ç‰¹å¾æ•°é‡", len(model_info["features"]))

                with st.expander("æŸ¥çœ‹æ‰€éœ€ç‰¹å¾åˆ—è¡¨"):
                    features_df = pd.DataFrame(
                        model_info["features"], columns=["ç‰¹å¾åç§°"]
                    )
                    st.dataframe(features_df, use_container_width=True)

                # æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                if "performance" in model_info:
                    st.markdown("### æ¨¡å‹æ€§èƒ½")
                    performance = model_info["performance"]
                    if problem_type == "classification":
                        st.metric(
                            "æµ‹è¯•é›† ROC AUC", f"{performance['test_roc_auc']:.4f}"
                        )
                    else:
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("æµ‹è¯•é›† MSE", f"{performance['test_mse']:.4f}")
                        with col2:
                            if "test_r2" in performance:
                                st.metric("æµ‹è¯•é›† RÂ²", f"{performance['test_r2']:.4f}")

                # å¯ä»¥æ·»åŠ ä¸€ä¸ªæç¤ºï¼Œè¯´æ˜å½“å‰æ­£åœ¨ä½¿ç”¨çš„æ¨¡å‹ç±»å‹
                st.info(
                    f"å½“å‰ä½¿ç”¨çš„æ˜¯{'åˆ†ç±»' if problem_type == 'classification' else 'å›å½’'}æ¨¡å‹ã€‚"
                )

            except Exception as e:
                st.error(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
                st.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                st.error(f"æ¨¡å‹æ–‡ä»¶: {selected_model}")
                st.error(f"é—®é¢˜ç±»å‹: {problem_type}")
                st.warning(
                    "è¿™å¯èƒ½æ˜¯å› ä¸ºé€‰æ‹©çš„æ¨¡å‹ä¸å½“å‰ç‰ˆæœ¬ä¸å…¼å®¹ï¼Œæˆ–æ¨¡å‹æ–‡ä»¶å·²æŸåã€‚è¯·å°è¯•é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚"
                )


def display_prediction_execution():
    if st.session_state.data_validated:
        st.markdown("## æ‰§è¡Œé¢„æµ‹")
        with st.container(border=True):
            if st.button("æ‰§è¡Œé¢„æµ‹", type="primary"):
                with st.spinner("æ­£åœ¨æ‰§è¡Œé¢„æµ‹..."):
                    try:
                        predictions = st.session_state.predictor.predict(
                            st.session_state.uploaded_data
                        )
                        st.session_state.predictions = predictions
                        if st.session_state.predictor.problem_type == "classification":
                            probabilities = st.session_state.predictor.predict_proba(
                                st.session_state.uploaded_data
                            )
                            st.session_state.probabilities = probabilities
                        st.success("âœ… é¢„æµ‹å®Œæˆï¼")
                    except Exception as e:
                        st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")


def display_prediction_results():
    if st.session_state.predictions is not None:
        st.markdown("## é¢„æµ‹ç»“æœ")

        with st.container(border=True):
            if st.session_state.predictor.problem_type == "classification":
                # é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ
                st.markdown("### é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ")
                fig = go.Figure(data=[go.Histogram(x=st.session_state.predictions)])
                fig.update_layout(
                    xaxis_title="é¢„æµ‹ç±»åˆ«",
                    yaxis_title="æ•°é‡",
                    height=400,
                    margin=dict(t=40),
                )
                st.plotly_chart(fig, use_container_width=True)

                # é¢„æµ‹ç»“æœé¢„è§ˆ
                st.markdown("### é¢„æµ‹ç»“æœé¢„è§ˆ")
                results_df = pd.DataFrame(
                    {
                        "é¢„æµ‹ç±»åˆ«": st.session_state.predictions,
                        "é¢„æµ‹æ¦‚ç‡": np.max(st.session_state.probabilities, axis=1),
                    }
                )
            else:
                # å›å½’é—®é¢˜çš„é¢„æµ‹åˆ†å¸ƒ
                st.markdown("### é¢„æµ‹å€¼åˆ†å¸ƒ")
                fig = go.Figure(data=[go.Histogram(x=st.session_state.predictions)])
                fig.update_layout(
                    xaxis_title="é¢„æµ‹å€¼",
                    yaxis_title="æ•°é‡",
                    height=400,
                    margin=dict(t=40),
                )
                st.plotly_chart(fig, use_container_width=True)

                # é¢„æµ‹ç»“æœé¢„è§ˆ
                st.markdown("### é¢„æµ‹ç»“æœé¢„è§ˆ")
                results_df = pd.DataFrame(
                    {
                        "é¢„æµ‹å€¼": st.session_state.predictions,
                    }
                )

            st.dataframe(results_df, use_container_width=True)

            # æä¾›ä¸‹è½½é¢„æµ‹ç»“æœçš„é€‰é¡¹
            csv = results_df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ",
                data=csv,
                file_name="prediction_results.csv",
                mime="text/csv",
            )


main()
